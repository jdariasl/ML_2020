{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "lab2_parte2.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpQ5oaZCofFF",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jdariasl/ML_2020/blob/master/Labs/lab2/lab2_parte2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "**Recuerda que una vez abierto, Da clic en \"Copiar en Drive\", de lo contrario no podras alamancenar tu progreso**\n",
        "\n",
        "Nota: no olvide ir ejecutando las celdas de código de arriba hacia abajo para que no tenga errores de importación de librerías o por falta de definición de variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "QycC0GLqofFG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#configuración del laboratorio\n",
        "# Ejecuta esta celda!\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "# for local \n",
        "#import sys ; sys.path.append('../commons/utils/')\n",
        "!wget https://raw.githubusercontent.com/jdariasl/ML_2020/master/Labs/commons/utils/general.py -O general.py\n",
        "from general import configure_lab2\n",
        "configure_lab2()\n",
        "from lab2 import *\n",
        "GRADER, x, y = part_2()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M43P7dzhofFJ",
        "colab_type": "text"
      },
      "source": [
        "# Laboratorio 2 - Parte 2\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ajc7Wc5LofFJ",
        "colab_type": "text"
      },
      "source": [
        "## Ejercicio 1: Contextualización del problema\n",
        "\n",
        "Para el problema de regresion usaremos la base de datos 'The Boston Housing Dataset', cuya descripción [pueden encontrarla aqui](https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html). La información ya esta cargada dentro del notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXhySCFiofFJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"muestra de los 3 primeros renglones de x:\\n\", x[0:3, :])\n",
        "print(\"muestra de los 3 primeros renglones de y:\\n\", y[0:3])\n",
        "print (\"¿el resultado de esta instrucción que información nos brinda?\", x.shape[0])\n",
        "print (\"¿el resultado de esta instrucción que información nos brinda?\", x.shape[1])\n",
        "print (\"¿el resultado de esta instrucción que información nos brinda?\", len(np.unique(y)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OI7JJ-EofFL",
        "colab_type": "text"
      },
      "source": [
        "En los problemas de regresión, es muy util explorar la distribución de la variable objetivo. Nuestro primer ejercicio consiste en:\n",
        "1. visualizar un histograma de la variable y \n",
        "2. retornar los intervalo de datos mas frecuente.\n",
        "\n",
        "Pistas: \n",
        "1. explorar la documentación de [plt.hist](https://matplotlib.org/3.3.1/api/_as_gen/matplotlib.pyplot.hist.html). Maneje los valores por defecto. ¿como se puede usar la salida del histograma para retorna el intervalo de datos mas frecuente?\n",
        "2. ¿ `np.argsort(numpy_array)[::-1]` que efecto tiene?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbGGSk26ofFM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ejercicio de código\n",
        "def plot_hist_and_get_freq_int(Y):\n",
        "    \"\"\"función que grafica el histograma de la variable 'Y'\n",
        "        y retorna el intervalo donde ocurren con mas frecuencia los\n",
        "        valores de 'Y'\n",
        "        Y: numpy array con la variable a graficar\n",
        "        retorna: una tupla (int/float, int/float, int/float) \n",
        "            el primer elemento es al limite inferior del intervalo donde ocurren los valores\n",
        "            mas frecuentes\n",
        "            el segundo elemento es al limite superior del intervalo donde ocurren los valores\n",
        "            mas frecuentes\n",
        "            el tercer elemento es el la frecuencia del intervalo\n",
        "            va observar un cuarto elemento a retornar, el cual es usado para confirmar que\n",
        "            se realizo la grafica correctamente\n",
        "    \"\"\"\n",
        "    \n",
        "    plt.hist()\n",
        "    lim_inf = \n",
        "    lim_sup = \n",
        "    freqs =\n",
        "    \n",
        "    # el cuarto elemento debe dejarlo\n",
        "    return (lim_inf, lim_sup, freqs, plt.gcf())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HWrZsxpofFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## la funcion que prueba tu implementacion\n",
        "#ignora las graficas!!\n",
        "GRADER.run_test(\"ejercicio1\", plot_hist_and_get_freq_int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHpvs0gwofFP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ver el histograma!\n",
        "plot_hist_and_get_freq_int(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_f11sJfofFR",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown ¿evaluando **solo** el histograma, podria decirse que nuestra variable 'y' podria modelarse de manera **totalmente exacta** con una sola distribución de probabilidad gausiana? justifique su respuesta\n",
        "respuesta_1 = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pz3slpbKofFT",
        "colab_type": "text"
      },
      "source": [
        "## Ejercicio 2: Completar código de K-Vecinos para regresión.\n",
        "\n",
        "Vamos a implementar ahora KNN para un problema de regresión."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiWMzkDGofFV",
        "colab_type": "text"
      },
      "source": [
        "Las mismas pistas de nuestro laboratorio anterior son de utilidad para implementar el algoritmo.\n",
        "\n",
        "1. Para el cáculo de la distancia entre vectores existen varias opciones:\n",
        "    1. usar la función la distancia entre matrices `scipy.spatial.distance.cdist`([Ejemplo](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cdist.html#scipy.spatial.distance.cdist))--esta puede ser usada directamente como `cdist(...)`. Entiende la salida de esta función. Al usarla, se logra un rendimiento superior.\n",
        "    2. usar la función la distancia euclidiana `scipy.spatial.distance.euclidean`([Ejemplo](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.euclidean.html))--pueder acceder a ella directamente como `euclidean`. Aca debe pensar en un algoritmo elemento a elemento, por lo tanto menos eficiente.\n",
        "2. También serán de utilidad las funciones `np.sort` y `np.argsort`.\n",
        "3. ¿cual es la unica diferencia entre el knn para clasificación y regresión? en lugar de la moda, que metodo debemos usar?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfkzbm94ofFV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ejercicio de código\n",
        "def KNN_regresion(X_train, Y_train, X_test, k):\n",
        "    \"\"\" Funcion que implementa el modelo de K-Vecino mas cercanos\n",
        "        para regresión\n",
        "    X_train: es la matriz con las muestras de entrenamiento\n",
        "    Y_train: es un vector con los valores de salida pra cada una de las muestras de entrenamiento\n",
        "    X_test: es la matriz con las muestras de validación\n",
        "    k (int): valor de vecinos a usar\n",
        "    retorna: las estimaciones del modelo KNN para el conjunto X_test \n",
        "             esta matriz debe tener un shape de [row/muestras de X_test] \n",
        "             y las distancias de X_test respecto a X_train, estan matrix\n",
        "             debe tener un shape de [rows de X_test, rows X_train]\n",
        "             lo que es lo mismo [muestras de X_test, muestras de X_train]\n",
        "    \"\"\"\n",
        "    \n",
        "    if k > X_train.shape[0]:\n",
        "        print(\"k no puede ser menor que las muestras de entrenamiento\")\n",
        "        return(None)\n",
        "\n",
        "    distancias =  \n",
        "    Yest = np.zeros(X_test.shape[0])\n",
        "  \n",
        "        \n",
        "    return Yest, distancias"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvO5df8RofFX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## la funcion que prueba tu implementacion\n",
        "GRADER.run_test(\"ejercicio2\", KNN_regresion)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QC8-3Q0qofFY",
        "colab_type": "text"
      },
      "source": [
        "## Ejercicio 3: Experimentos con KNN\n",
        "\n",
        "Ahora vamos a probar nuestro algoritmo. Antes de ello, definos la función para calcular el error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YExvJ6zqofFZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def MAPE(Y_est,Y):\n",
        "    \"\"\"Mean Absolute Percentage Error para los problemas de regresión\n",
        "    Y_est: numpy array con los valores estimados\n",
        "    Y: numpy array con las etiquetas verdaderas\n",
        "    retorna: mape\n",
        "    \"\"\"\n",
        "    N = np.size(Y)\n",
        "    mape = np.sum(abs((Y_est.reshape(N,1) - Y.reshape(N,1))/Y.reshape(N,1)))/N\n",
        "    return mape "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RC5fF9WnofFa",
        "colab_type": "text"
      },
      "source": [
        "Y ahora, si, vamos a crear la función para experimentar.\n",
        "\n",
        "En el ejercicio de código, se puede observar que usamos nuevamente la funciónes de la libreria **sklearn**:\n",
        "\n",
        "1. [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) para normalizar.\n",
        "\n",
        "2. [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html). Para dividir el conjunto de datos. Entiende como estamos usando esta función."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_2YwTFsofFa",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown si bien, dentro del código es usada la función train_test_split, que metodologia de validación es implementada usando esta función? justifique\n",
        "respuesta_2 = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cftNVbm-ofFc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Ejercicio de código\n",
        "def experimentar (X, Y, ks):\n",
        "    \"\"\"Función que realiza los experimentos con knn usando\n",
        "       una estrategia de validacion entrenamiento y pruebas\n",
        "    X: matriz de numpy conjunto con muestras y caracteristicas\n",
        "    Y: vector de numpy con los valores a predecir\n",
        "    ks: List[int/float] lista con los valores de k-vecinos a usar\n",
        "    retorna: dataframe con los resultados, debe contener las siguientes columnas:\n",
        "        - los k-vecinos, el error-mape medio de prueba, la desviacion estandar del error-mape\n",
        "    \"\"\"\n",
        "    \n",
        "    resultados = pd.DataFrame()\n",
        "    idx = 0\n",
        "    # iteramos sobre la lista de k's\n",
        "    for k in ks:\n",
        "        # lista para almacenar los errores de cada iteración\n",
        "        # de la validación\n",
        "        error_temp = []\n",
        "        \n",
        "        # iteramos para validar\n",
        "        for j in range(3): \n",
        "            # dividimos usando la función\n",
        "            Xtrain, Xtest, Ytrain, Ytest = train_test_split(X,Y)\n",
        "            scaler = StandardScaler()\n",
        "            scaler.fit(Xtrain)\n",
        "            Xtrain= scaler.transform(Xtrain)\n",
        "            Xtest = scaler.transform(Xtest)\n",
        "\n",
        "            Yest, _ = KNN_regresion(...)\n",
        "            errorTest =\n",
        "            error_temp.append(errorTest)\n",
        "    \n",
        "        resultados.loc[idx,'k-vecinos'] = k \n",
        "        resultados.loc[idx,'error de prueba(media)'] =\n",
        "        resultados.loc[idx,'error de prueba(desviación estandar)'] =\n",
        "        idx+=1\n",
        "\n",
        "    return (resultados)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ce0cyutCofFe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## la funcion que prueba tu implementacion\n",
        "GRADER.run_test(\"ejercicio3\", experimentar)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgvhQRfWofFg",
        "colab_type": "text"
      },
      "source": [
        "Ahora ejecuta los experimentos con k = 2,3,4,5,6,7,10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-BTxFYwofFg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resultados = experimentar (x, y,[2,3,4,5,6,7,10])\n",
        "resultados"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEjPQXT4ofFi",
        "colab_type": "text"
      },
      "source": [
        "## Ejercicio 4: Ventana de Parzen y experimentos\n",
        "\n",
        "Ahora, igualmente, vamos aplicar ventana de parzen para resolver el problema de regresión.\n",
        "\n",
        "$$f({\\bf{x}}^*) = \\frac{1}{N h^d} \\sum_{i=1}^{N} K(u_i), \\;\\; u_i = \\frac{d({\\bf{x}}^*,{\\bf{x}}_i)}{h}$$\n",
        "\n",
        "En la siguiente celda se define la función para un $K(u_i)$ gaussiano y se realiza la sugerencia para estimar el termino $ \\sum_{i=1}^{N} K(u_i)$, siendo $\\;\\; u_i = \\frac{d({\\bf{x}}^*,{\\bf{x}}_i)}{h}$. \n",
        "\n",
        "Observa y entiende esta última función y sus argumentos. Recordando que para regresión, debemos usar la relación de **Nadaraya_Watson**.\n",
        "\n",
        "$$y^* = \\frac{\\sum_{i=1}^N K(u_i)y_i}{\\sum_{i=1}^N K(u_i)} $$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EX4aOnYqofFi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def kernel_gaussiano(x):\n",
        "    return (np.exp((-0.5)*x**2))\n",
        "\n",
        "def ParzenWindow(x,Data,h,Datay=None):\n",
        "    \"\"\"\"ventana de parzen\n",
        "    x: vector con representando una sola muestra\n",
        "    Data: vector de muestras de entrenamiento\n",
        "    h: ancho de la ventana de kernel\n",
        "    Datay: vector con los valores de salida (y), Si no se pasa como argumento, \n",
        "        se calcula un ventana de parzen sin multiplicar los valores de este vector.\n",
        "    retorna: el valor de ventana de parzen para una muestra\n",
        "    \"\"\"\n",
        "    h = h\n",
        "    Ns = Data.shape[0]\n",
        "    suma = 0\n",
        "    for k in range(Ns):\n",
        "        u = euclidean(x,Data[k,:])\n",
        "        if Datay is None:\n",
        "            suma += kernel_gaussiano(u/h)\n",
        "        else:\n",
        "            suma += kernel_gaussiano(u/h)*Datay[k]\n",
        "    return suma\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qO9mH5lofFk",
        "colab_type": "text"
      },
      "source": [
        "Usando las anteriores funciones, completa el código."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNiUQcL2ofFk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Ejercicio de código\n",
        "def Nadaraya_Watson(X_train, Y_train, X_test, h):\n",
        "    \"\"\" Funcion que implementa metodo de ventana de parzen para\n",
        "        para clasificación\n",
        "    X_train: es la matriz con las muestras de entrenamiento\n",
        "    Y_train: es un vector con los valores de salida pra cada una de las muestras de entrenamiento\n",
        "    X_test: es la matriz con las muestras de validación\n",
        "    h (float): ancho de h de la ventana\n",
        "    retorna: - las estimaciones del modelo parzen para el conjunto X_test \n",
        "              esta matriz debe tener un shape de [row/muestras de X_test]\n",
        "             - las probabilidades de la vetana [row/muestras de X_test, numero de clases]  \n",
        "    \"\"\"\n",
        "        \n",
        "    Yest = np.zeros(X_test.shape[0])\n",
        "    \n",
        "    \n",
        "    #Debe retornar un vector que contenga las predicciones para cada una de las muestras en X_val, en el mismo orden.  \n",
        "    return Yest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tA6a1t2EofFn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## la funcion que prueba tu implementacion\n",
        "GRADER.run_test(\"ejercicio4\", Nadaraya_Watson)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIUuf3KJofFp",
        "colab_type": "text"
      },
      "source": [
        "## Ejercicio 5: Experimentos con Parzen\n",
        "En el ejercicio de código, se puede observar que usamos nuevamente la funciónes de la libreria **sklearn**:\n",
        "\n",
        "1. [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) para normalizar.\n",
        "2. Y se debe usar la función [KFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html?highlight=kfold#sklearn.model_selection.KFold) para realizar la validación. Tener en cuenta la documentación para poder completar el código de manera correcta."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_uSnBaEofFp",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown ¿cual es la metodologia de validación usada en el experimento? ¿qué diferencia tiene respecto a la metodologia usada en el primer experimento?\n",
        "respuesta_3 = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wbPuUi3ofFr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def experimentarParzen (X, Y, hs):\n",
        "    \"\"\"Función que realiza los experimentos con knn usando\n",
        "       una estrategia de validacion entrenamiento y pruebas\n",
        "    X: matriz de numpy conjunto con muestras y caracteristicas\n",
        "    Y: vector de numpy con los valores de las etiquetas\n",
        "    ks: List[int/float] lista con los valores de k-vecinos a usar\n",
        "    retorna: dataframe con los resultados, debe contener las siguientes columnas:\n",
        "        - el ancho de ventana, \n",
        "        - el error medio de prueba\n",
        "        - la desviacion estandar del error\n",
        "        - número de promedio en el conjunto de prueba/validacion\n",
        "    \"\"\"\n",
        "    # se usa la función para implementar la estrategia de validación.\n",
        "    kfolds = KFold(n_splits=4)\n",
        "    resultados = pd.DataFrame()\n",
        "    idx = 0\n",
        "    # iteramos sobre los valores de hs\n",
        "    for h in hs:\n",
        "        # lista para almacenar los errores y numero de muestras\n",
        "        # de cada iteración\n",
        "        # de la validación\n",
        "        error_temp = []\n",
        "        numero_muestras = []\n",
        "        \n",
        "        for train, test in kfolds.split( ):\n",
        "\n",
        "            Xtrain = X[,:]\n",
        "            Ytrain = Y[]\n",
        "            Xtest = X[,:]\n",
        "            Ytest = Y[]\n",
        "            #normalizamos los datos\n",
        "            scaler = StandardScaler()\n",
        "            scaler.fit(Xtrain)\n",
        "            Xtrain = scaler.transform(Xtrain)\n",
        "            Xtest = scaler.transform(Xtest)\n",
        "            \n",
        "            Yest = Nadaraya_Watson(...)\n",
        "            errorTest = \n",
        "            error_temp.append(errorTest)\n",
        "            numero_muestras.append()\n",
        "    \n",
        "        resultados.loc[idx,'ancho de ventana'] = h \n",
        "        resultados.loc[idx,'error de prueba(media)'] = \n",
        "        resultados.loc[idx,'error de prueba(desviación estandar)'] =\n",
        "        resultados.loc[idx,'muestras en conjunto de pruebas (media)'] = \n",
        "        idx+=1\n",
        "    return (resultados)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZvm7rCmofFs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## la funcion que prueba tu implementacion\n",
        "GRADER.run_test(\"ejercicio5\", experimentarParzen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sp-8Jg8oofFt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ejecute para ver los experimentos\n",
        "hs = [1,1.5 ,2.5, 5, 10]\n",
        "experimentos_parzen = experimentarParzen(x,y, hs)\n",
        "experimentos_parzen"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-Fs-0FAofFv",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown ¿es normal que el la media de muestra en el cojunto de pruebas siempre es la misma? justifique\n",
        "respuesta_4 = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IxHJrBbofFw",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown ¿que metodo podria usarse para estimar el valor de h?\n",
        "respuesta_5 = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRvFgdGuofFx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "GRADER.check_tests()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhpgdXfXofFz",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Integrantes\n",
        "codigo_integrante_1 ='' #@param {type:\"string\"}\n",
        "codigo_integrante_2 = ''  #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28SF6j5UofF1",
        "colab_type": "text"
      },
      "source": [
        "----\n",
        "esta linea de codigo va fallar, es de uso exclusivo del los profesores\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nX4Xv45lofF1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "GRADER.grade()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}