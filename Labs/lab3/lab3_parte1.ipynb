{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab3_parte1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCTNsoLtkyaW"
      },
      "source": [
        "**Recuerda que una vez abierto, Da clic en \"Copiar en Drive\", de lo contrario no podras almacenar tu progreso**\n",
        "\n",
        "Nota: no olvide ir ejecutando las celdas de código de arriba hacia abajo para que no tenga errores de importación de librerías o por falta de definición de variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gx0QZd1tkyaX"
      },
      "source": [
        "#configuración del laboratorio\n",
        "# Ejecuta esta celda!\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "# for local \n",
        "# import sys ; sys.path.append('../commons/utils/')\n",
        "!wget https://raw.githubusercontent.com/jdariasl/ML_2020/master/Labs/commons/utils/general.py -O general.py --no-cache\n",
        "from general import configure_lab3\n",
        "configure_lab3()\n",
        "from lab3 import *\n",
        "GRADER = part_1()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fL3NUNjhkyaa"
      },
      "source": [
        "# Laboratorio 3 - Parte 1. Comparación de metodos de clusterización\n",
        "\n",
        "### Ejercicio 1: Contextualización del problema\n",
        "\n",
        "A continuación se leen los datos de un problema de clasificación. El problema corresponde a la clasificación de dígitos escritos a mano. Los datos fueron preprocesados para reducir el número de características y solo se van usar los digitos 0 al 4. La técnica usada será analizada más adelante en el curso. Al ejecutar la celda de código, tambien se podra visualizar una muestra de los datos usados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMq5O_h_kyaa"
      },
      "source": [
        "digits = load_digits(n_class=5)\n",
        "#--------- preprocesamiento--------------------\n",
        "pca = PCA(0.99, whiten=True)\n",
        "data = pca.fit_transform(digits.data)\n",
        "#---------- Datos a usar ----------------------\n",
        "x = data\n",
        "y = digits.target\n",
        "\n",
        "plot_digits(digits.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9oDeolgkyac"
      },
      "source": [
        "Vamos realizar algunas pruebas para determinar que metodologia de validación es más adecuada. En el ejercicio de código, vamos usar las librerias de scikit-learn:\n",
        "1. [StratifiedKFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html?highlight=stratifiedkfold#sklearn.model_selection.StratifiedKFold)\n",
        "2. [ShuffleSplit](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html)\n",
        "\n",
        "En la función debes seleccionar la función de sklearn adecuada para lograr el efecto deseado y completar el código donde es señalado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlubvnNCkyad"
      },
      "source": [
        "#ejercicio de código\n",
        "def get_muestras_by_cv (method, X, Y):\n",
        "    \"\"\"función que devuelve el numero de muestras promedios\n",
        "    dependiendo de la metodologia de validación (method).\n",
        "    los conjuntos de datos deben dividirse **3 veces**\n",
        "\n",
        "    method (int): solo puede tomar dos valores:\n",
        "        1: se debe usar el metodo de validación Bootstrapping\n",
        "        2: se debe usar el metodo valicacion cruzada estratificada\n",
        "    X: matriz numpy con los valores de las caracteristicas\n",
        "    Y: vector numpy con las etiquetas de con conjunto de caracteriticas X\n",
        "    retorna: dataframe con las siguientes columnas:\n",
        "        - etiqueta de clase\n",
        "        - fold\n",
        "        - # muestras en entrenamiento\n",
        "    \"\"\"\n",
        "    idx = 0\n",
        "    results = pd.DataFrame()\n",
        "    \n",
        "    if method == 1:\n",
        "        #completa el codigo con el metodo adecuado\n",
        "        cv = \n",
        "        for n, (train_index, test_index) in enumerate (cv.split()):\n",
        "            y_train, y_test = Y[train_index], Y[test_index]\n",
        "            \n",
        "            # iterar sobre las etiquetas\n",
        "            for label in np.unique(y_train):\n",
        "                results.loc[idx, 'etiqueta de clase'] = label\n",
        "                results.loc[idx, 'folds'] = n\n",
        "                results.loc[idx, 'numero de muestras entrenamiento'] = (y_train == label).sum()\n",
        "                idx = idx+1\n",
        "        \n",
        "    elif method == 2:\n",
        "        #completa el codigo con el metodo adecuado\n",
        "        cv = \n",
        "        for n, (train_index, test_index ) in enumerate (cv.split()):\n",
        "            y_train, y_test = Y[train_index], Y[test_index]\n",
        "            len(np.unique(y_train))\n",
        "            # iterar sobre las etiquetas\n",
        "            for label in np.unique(y_train):\n",
        "            \n",
        "                results.loc[idx, 'etiqueta de clase'] = label\n",
        "                results.loc[idx, 'folds'] = n             \n",
        "                results.loc[idx, 'numero de muestras entrenamiento'] = (y_train == label).sum()\n",
        "                idx = idx+1\n",
        "    else:\n",
        "        print(\"el metodo no es valido!\")\n",
        "        \n",
        "    return (results)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uZxurAMkyaf"
      },
      "source": [
        "## la funcion que prueba tu implementacion\n",
        "#ignora las graficas!!\n",
        "GRADER.run_test(\"ejercicio1\", get_muestras_by_cv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0kWyEC2bzzy"
      },
      "source": [
        "Aca vamos a crear un dataframe para observar el numero de muestras de entrenamiento logradas por cada uno de los metodos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlWWrmdCbzzz"
      },
      "source": [
        "cv1 = get_muestras_by_cv(1,x,y)\n",
        "cv1['validación'] = 'Bootstrapping'\n",
        "cv2 = get_muestras_by_cv(2,x,y)\n",
        "cv2['validación'] = 'Estratificada'\n",
        "cvs = pd.concat([cv1, cv2], ignore_index=True)\n",
        "cvs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WDTn2Pgkyah"
      },
      "source": [
        "En la tabla es dificil analizar que esta pasando. Para interpretar mejor los resultados vamos a usar una grafica llamada [PointPlot](https://interactivechaos.com/es/manual/tutorial-de-seaborn/point-plot). Esta grafica de la libreria [Seaborn](https://seaborn.pydata.org/generated/seaborn.pointplot.html) nos permite ver la diferencia entre los metodos.\n",
        "\n",
        "Debemos entender que representan los puntos y las barras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSntfgF0kyah"
      },
      "source": [
        "display(\"distribución de clases\")\n",
        "sns.catplot(data= cvs , x = 'etiqueta de clase', y='numero de muestras entrenamiento', kind='point', hue='validación')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DpbdZvg3518"
      },
      "source": [
        "En la grafica, las barras representan la variación del numero de muestras en cada fold/partición. Y el punto es el valor medio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmF2ffwdkyak",
        "cellView": "form"
      },
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown En sus palabras, usando el grafico anterior y su conocimiento, ¿por qué Boostrapping no es la metodologia más adecuada?\n",
        "respuesta_1 = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HMh3Ajskyam"
      },
      "source": [
        "### Ejercicio 2: Mezclas de gaussinas\n",
        "\n",
        "En la siguiente celda vamos a definir una función que tome como entradas una matriz $X$ y una matriz $Y$, entrene un modelo GMM  (Modelo de mezclas gaussianas) por cada clase y retorne el listado de modelos para cada clase. Debe consultar todo lo relacionado con la creación, entrenamiento y uso en predicción de este modelo usando la librería scikit-learn. Consultar aquí: http://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html\n",
        "\n",
        "En el notebook, ya se encuentra cargada la libreria que vamos a usar:\n",
        "\n",
        "```python\n",
        "from sklearn.mixture import GaussianMixture\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xj9H25Qkkyan"
      },
      "source": [
        "#ejercicio de código\n",
        "def GMMClassifierTrain(M,tipo,X,Y):\n",
        "    \"\"\"metodo para entrenar un modelo de mezclas de gausianas\n",
        "    M: Número de componentes\n",
        "    tipo (str): Tipo de matriz de covarianza (los parametros que se\n",
        "          aceptan son los nombres de la  misma libreria:\n",
        "          'full', 'tied', 'diag', 'spherical')\n",
        "    X: Matriz de caracteristicas\n",
        "    Y : Matriz con las clases\n",
        "   \n",
        "    retorna: diccionario de con la estructura:\n",
        "        {etiqueta_clase: modelo_gmm_entrenado}\n",
        "    \"\"\" \n",
        "    GMMs = {}\n",
        "    for cl in np.unique(Y):\n",
        "        xclass = X[Y==cl, :]\n",
        "        gmm  = \n",
        "        \n",
        "    #Debe retornar un objeto que contenga todos los modelos entrenados  \n",
        "    return GMMs \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zOl0rx_kyao"
      },
      "source": [
        "## la funcion que prueba tu implementacion\n",
        "GRADER.run_test(\"ejercicio2\", GMMClassifierTrain)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "49MTP2Az3519"
      },
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown En sus palabras, ¿por qué debemos entrenar un modelo por cada clase?\n",
        "respuesta_2 = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RW6KTAO5kyaq"
      },
      "source": [
        "Adicionalmente construya una función que use los modelos entrenados en la función anterior para hacer la clasificación de un conjunto nuevo de muestras.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrBGb_PFkyaq"
      },
      "source": [
        "#ejercicio de código\n",
        "def GMMClassfierVal(GMMs,Xtest):\n",
        "    \"\"\"funcion que recibe los modelos GMM entrenados\n",
        "        y realiza predicciones con base a cada salida\n",
        "    GMMs: diccionario de con la estructura:\n",
        "        {etiqueta_clase: modelo_gmm_entrenado}\n",
        "    Xtest: matriz numpy con el cojunto de datos\n",
        "        de las caracteristicas de prueba/test\n",
        "    retorna: \n",
        "    - un numpy array con las estimaciones de de clase de cada \n",
        "        una de las muestras de Xtest\n",
        "    - matriz las probabilidades(en log) de cada clase por cada\n",
        "      muestra debe tener un shape [numero de muestras, numero de clases]\n",
        "    \"\"\"\n",
        "    prob = np.zeros((Xtest.shape[0], len(GMMs)))\n",
        "    \n",
        "    #pista explora los metodos de la libreria, que metodo retorna probabilidades?\n",
        "    for k,v in GMMs.items():\n",
        "       \n",
        "    \n",
        "    # la etiqueta la asignas seleccionando le maximo de probabilidad\n",
        "    Yest= \n",
        "    \n",
        "    return Yest, prob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARKhErZCkyas"
      },
      "source": [
        "## la funcion que prueba tu implementacion\n",
        "#ignora las graficas!!\n",
        "GRADER.run_test(\"ejercicio3\", GMMClassfierVal)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOorjH6nkyau"
      },
      "source": [
        "### Ejercicio 3: Experimentos\n",
        "Con el código completado, vamos a realizar experimentos. Complete la siguiente función para poder obtener los resultados de los experimentos. Es necesario:\n",
        "1. retornar errores de entrenamiento y pruebas\n",
        "2. retornar intervalos de confianza (desviacion estandar) para cada una de la configuración de experimentos\n",
        "3. en el código, ya se sugiere la metodologia de validación (usando 3 folds) y se usa, como es usual el standard scaler para normalizar los datos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBLei4VPkyau"
      },
      "source": [
        "#ejercicio de código\n",
        "def experimentar(X, Y, covariance_types,num_components):\n",
        "    \"\"\"función que realiza experimentos del GMM\n",
        "    \n",
        "    X: matriz con las caractersiticas\n",
        "    Y: matriz de numpy con etiquetas\n",
        "    covariance_types: list[str] con las matrices de covarianza a probar\n",
        "    num_components: list[int] con el numero de componente a probar\n",
        "  \n",
        "    retorna: dataframe con:\n",
        "        - matriz de covarianza\n",
        "        - numero de componentes\n",
        "        - eficiencia de entrenamiento\n",
        "        - desviacion de estandar eficiencia de entrenamiento\n",
        "        - eficiencia de prueba\n",
        "        - desviacion estandar eficiencia de prueba\n",
        "    \"\"\"\n",
        "    # asignar los folds\n",
        "    folds = \n",
        "    skf = StratifiedKFold(n_splits=folds)\n",
        "    resultados = pd.DataFrame()\n",
        "    idx = 0\n",
        "\n",
        "    for cov_tipo in covariance_types:\n",
        "        for M in num_components:\n",
        "            ## para almacenar los errores intermedios\n",
        "            EficienciaTrain = []\n",
        "            EficienciaVal = []\n",
        "            for train, test in skf.split(X, Y):\n",
        "                Xtrain = X[train,:]\n",
        "                Ytrain = Y[train]\n",
        "                Xtest = X[test,:]\n",
        "                Ytest = Y[test]\n",
        "                #Normalizamos los datos\n",
        "                scaler = StandardScaler()\n",
        "                scaler.fit(Xtrain)\n",
        "                Xtrain= scaler.transform(Xtrain)\n",
        "                Xtest = scaler.transform(Xtest)\n",
        "                #Haga el llamado a la función para crear y entrenar el modelo usando los datos de entrenamiento\n",
        "                gmms = \n",
        "                #Validación se ignora la matriz de probabilidad\n",
        "                Ytrain_pred, _ =\n",
        "                Yest, _ = \n",
        "                #Evaluamos las predicciones del modelo con los datos de test\n",
        "                EficienciaTrain.append(np.mean(Ytrain_pred.ravel() == Ytrain.ravel()))\n",
        "                EficienciaVal.append(np.mean(Yest.ravel() == Ytest.ravel()))\n",
        "\n",
        "            resultados.loc[idx,'matriz de covarianza'] = cov_tipo\n",
        "            resultados.loc[idx,'numero de componentes'] = M\n",
        "            resultados.loc[idx,'eficiencia de entrenamiento'] = \n",
        "            resultados.loc[idx,'desviacion estandar entrenamiento'] =\n",
        "            resultados.loc[idx,'eficiencia de prueba'] =\n",
        "            resultados.loc[idx,'desviacion estandar prueba'] =\n",
        "            idx= idx +1\n",
        "            print(\"termina para\", cov_tipo, M)\n",
        "        \n",
        "    return (resultados)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shHrHnvykyaw"
      },
      "source": [
        "## la funcion que prueba tu implementacion\n",
        "# los prints del test los puedes ignorar (se hacen unos checks!)\n",
        "GRADER.run_test(\"ejercicio4\", experimentar)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXy56hwbkyax"
      },
      "source": [
        "Ahora vamos a ejecutar nuestros experimentos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhheSKcvkyay"
      },
      "source": [
        "matrices = ['full', 'tied', 'diag', 'spherical']\n",
        "componentes = [1,2,3]\n",
        "resultados = experimentar(x, y, matrices, componentes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uEfpgfGkyaz"
      },
      "source": [
        "# para ver la tabla\n",
        "resultados"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9E_LNaFpkya4",
        "cellView": "form"
      },
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown ¿a qué corresponde el parámetro init_params de la función GaussianMixture y cuál fue el valor usado en nuestros experimentos?\n",
        "respuesta_3 = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HcG_ejYkya5"
      },
      "source": [
        "### Ejercicio 4 Kmeans y experimentos\n",
        "\n",
        "\n",
        "Consultar todo lo relacionado al llamado del método KMeans de la librería scikit-learn en el siguiente enlace: http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html. \n",
        "\n",
        "En el notebook, ya se encuentra cargada la libreria:\n",
        "\n",
        "```python\n",
        "from sklearn.cluster import KMeans\n",
        "```\n",
        "\n",
        "Vamos a resolver el mismo problema anterior pero con el K-means. La libreria nos ofrece suficiente utilidad para ya poder comenzar a realizar experimentos con ella. \n",
        "\n",
        "Por ellos vamos a implementar la función para realizar los experimentos. [Debemos configurar la inicialización del algoritmo](https://scikit-learn.org/stable/modules/clustering.html#k-means) usando 'k-means++'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYFhQHutkya7"
      },
      "source": [
        "#ejercicio de código\n",
        "#Validamos el modelo\n",
        "def experimentar_kmeans(numero_clusters,X, Y):\n",
        "    \"\"\"función que realiza experimentos de Kmeans\n",
        "    numero_clusters: list[int] numero cluster para realizar experimentos\n",
        "    X: matriz con las caractersiticas\n",
        "    Y: matriz de numpy con etiquetas\n",
        "    retorna: dataframe con:\n",
        "        - numero_clusters\n",
        "        - el error de entrenamiento\n",
        "        - desviacion de estandar del error entrenamiento\n",
        "        - error de prueba\n",
        "        - desviacion estandar eror de prueba\n",
        "    \"\"\"\n",
        "    folds = 4\n",
        "    skf = StratifiedKFold(n_splits=folds)\n",
        "    resultados = pd.DataFrame()\n",
        "    idx = 0\n",
        "\n",
        "    for n_cluster in numero_clusters:\n",
        "        ## para almacenar los errores intermedios\n",
        "        EficienciaTrain = []\n",
        "        EficienciaVal = []\n",
        "        for train, test in skf.split(X, Y):\n",
        "            Xtrain = X[train,:]\n",
        "            Ytrain = Y[train]\n",
        "            Xtest = X[test,:]\n",
        "            Ytest = Y[test]\n",
        "            #Normalizamos los datos\n",
        "            scaler = StandardScaler()\n",
        "            scaler.fit(Xtrain)\n",
        "            Xtrain= scaler.transform(Xtrain)\n",
        "            Xtest = scaler.transform(Xtest)\n",
        "            #verifica como pasar n_cluster a KMeans\n",
        "            kmeans = \n",
        "            #¿que metodo debes llamar para entrenar kmeans?\n",
        "            kmeans\n",
        "            #predicciones en cada conjunto\n",
        "            # ¿que metodo debes llamar para realizar preddiciones con kmeans?\n",
        "            Ytrain_pred = kmeans\n",
        "            Yest  = kmeans\n",
        "            #Evaluamos las predicciones del modelo con los datos de test\n",
        "            EficienciaTrain.append(np.mean(Ytrain_pred.ravel() == Ytrain.ravel()))\n",
        "            EficienciaVal.append(np.mean(Yest.ravel() == Ytest.ravel()))\n",
        "\n",
        "        resultados.loc[idx,'numero de clusters'] = n_cluster\n",
        "        resultados.loc[idx,'eficiencia de entrenamiento'] = \n",
        "        resultados.loc[idx,'desviacion estandar entrenamiento'] =\n",
        "        resultados.loc[idx,'eficiencia de prueba'] = \n",
        "        resultados.loc[idx,'desviacion estandar prueba'] =\n",
        "        idx= idx +1\n",
        "        print(\"termina para\", n_cluster)\n",
        "        \n",
        "    return (resultados)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "M_ojP0hSkya9"
      },
      "source": [
        "#@title Default title text\n",
        "## la funcion que prueba tu implementacion\n",
        "#ignora las graficas!!\n",
        "GRADER.run_test(\"ejercicio5\", experimentar_kmeans)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CC0WGj4Zkya-"
      },
      "source": [
        "# ejecuta los experimentos y ve los resultados\n",
        "resultados_kmeans = experimentar_kmeans([3,5,6,8],x, y)\n",
        "resultados_kmeans"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Op_AHOAgkybA",
        "cellView": "form"
      },
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown ¿Qué es el método elbow y por qué en nuestro caso no es útil? Pista: tiene sentido buscar un número de grupos != 5 ?\n",
        "respuesta_4 = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zu7LsXk_kybB"
      },
      "source": [
        "tener presente que tipo de entrenamiento realiza el kmeans: ¿supervisado o no supervisado? \n",
        "\n",
        "Vamos a realizar una grafica usando un metodo que vamos a ver en futuros laboratorios.\n",
        "\n",
        "La grafica se pueden entender como una representación en 2 dimensiones de nuestra base de datos (que tiene 40 variables). \n",
        "\n",
        "Cada punto representa uno de nuestros ejemplos.\n",
        "\n",
        "**Recordar**: \n",
        "1. Completa el codigo, con el numero de clusters con la cual se obtuvo la mejor eficiencia en los experimentos.\n",
        "2. Completa el codigo con los mejores parametros para GMM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PxpuVWmkybC"
      },
      "source": [
        "# estandarizacion\n",
        "\n",
        "x_std = StandardScaler().fit_transform(x)\n",
        "\n",
        "## Kmeans\n",
        "numero_clusters = # aca el numero de cluster con la mejor eficiencia\n",
        "\n",
        "predict_kmeans = KMeans(n_clusters=numero_clusters, init = 'k-means++').fit_predict(x_std)\n",
        "\n",
        "## GMM. Reemplaza los valores de acuerdo a tus experimentos\n",
        "gmms = GMMClassifierTrain(X=x_std,Y=y,M=,tipo= )\n",
        "# ignoramos probabilidad\n",
        "predict_gmm, _ = GMMClassfierVal(gmms, x_std)\n",
        "\n",
        "#adicionamos etiquetas reales\n",
        "real = pd.DataFrame(x[:, 0:2], columns=['PC1', 'PC2'])\n",
        "real['clase'] = y\n",
        "real['tipo de etiqueta'] = 'Real'\n",
        "\n",
        "#adicionamos etiquetas de kmeans\n",
        "kmeans = pd.DataFrame(x[:, 0:2], columns=['PC1', 'PC2'])\n",
        "kmeans['clase'] = predict_kmeans\n",
        "kmeans['tipo de etiqueta'] = 'Asignada por Kmeans'\n",
        "\n",
        "#adicionamos etiquetas de gmms\n",
        "gmm_df = pd.DataFrame(x[:, 0:2], columns=['PC1', 'PC2'])\n",
        "gmm_df['clase'] = predict_gmm\n",
        "gmm_df['tipo de etiqueta'] = 'Asignada por gmm'\n",
        "\n",
        "# unimos y graficamos\n",
        "data_to_plot = pd.concat([real, kmeans, gmm_df], ignore_index=True)\n",
        "data_to_plot['clase'] = data_to_plot['clase'].astype('category')\n",
        "g = sns.relplot(data = data_to_plot, x = 'PC1', y='PC2', hue= 'clase', col='tipo de etiqueta', style= 'clase',   markers = ['$0$', '$1$', '$2$', '$3$', '$4$'], s = 400, height = 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_xcA2LTkybE",
        "cellView": "form"
      },
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown ¿con base a los resultados que modelo es el más adecuado entre el k-means y el GMM? justifique.\n",
        "respuesta_5 = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjN45dUAkybF"
      },
      "source": [
        "GRADER.check_tests()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "DrYzIcRJkybH"
      },
      "source": [
        "#@title Integrantes\n",
        "codigo_integrante_1 ='' #@param {type:\"string\"}\n",
        "codigo_integrante_2 = ''  #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guu6JrtRkybJ"
      },
      "source": [
        "----\n",
        "esta linea de codigo va fallar, es de uso exclusivo de los profesores\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcaIVi5CkybJ"
      },
      "source": [
        "GRADER.grade()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}