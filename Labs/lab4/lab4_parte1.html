
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Laboratorio 4 - Parte 1. Redes neuronales - perceptrón multicapa &#8212; 2020 Introducción al Machine Learning</title>
    
  <link rel="stylesheet" href="../../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Laboratorio 4 - Parte 2. Regularización de modelos." href="lab4_parte2.html" />
    <link rel="prev" title="Redes Neuronales Recurrentes" href="../../Clase%2014%20-%20Redes%20Neuronales%20Recurrentes.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../index.html">
  
  <img src="../../_static/fudea.jpg" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">2020 Introducción al Machine Learning</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../intro.html">
   Course information
  </a>
 </li>
</ul>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../titles/U0_IntroLabs.html">
   INTRODUCCIÓN A PYTHON, NUMPY Y OTRAS HERRAMIENTAS
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../Intro/Intro.html">
     Introdución para los laboratorios de Machine Learning
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../titles/U1_description.html">
   U1. INTRODUCCIÓN AL MACHINE LEARNING
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../Clase%2001%20-%20Introducci%C3%B3n%20al%20Machine%20Learning.html">
     Introducción al Machine Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Clase%2001%20-%20Introducci%C3%B3n%20al%20Machine%20Learning.html#modelos-a-partir-de-datos">
     Modelos a partir de datos
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Clase%2001%20-%20Introducci%C3%B3n%20al%20Machine%20Learning.html#tipos-de-problemas-supervisados">
     Tipos de problemas supervisados
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Clase%2002%20-%20Regresi%C3%B3n%20lineal%20y%20regresi%C3%B3n%20log%C3%ADstica.html">
     <font color="blue">
      Modelos básicos de aprendizaje
     </font>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Clase%2002%20-%20Regresi%C3%B3n%20lineal%20y%20regresi%C3%B3n%20log%C3%ADstica.html#font-color-blue-pensemos-ahora-en-el-problema-de-clasificacion-font">
     <font color="blue">
      Pensemos ahora en el problema de clasificación
     </font>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Clase%2003%20-%20Funciones%20discriminantes%20Gausianas.html">
     Modelos de clasificación empleando funciones de densidad Gausianas
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lab1/lab1_parte1.html">
     Laboratorio 1 - Parte 1 Regresión polinomial múltiple
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lab1/lab1_parte2.html">
     Laboratorio 1 - Parte 2. Regresión logística
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../titles/U2_description.html">
   U2. MODELOS NO PARÁMETRICOS
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../Clase%2004%20-%20Modelos%20no%20Param%C3%A9tricos.html">
     Modelos no parámetricos
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lab2/lab2_parte1.html">
     Laboratorio 2 - Parte 1. KNN para un problema de clasificación
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lab2/lab2_parte2.html">
     Laboratorio 2 - Parte 2. KNN para un problema de regresión
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../titles/U3_description.html">
   U3. COMPLEJIDAD DE MODELOS Y VALIDACIÓN
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../Clase%2005%20-%20M%C3%A9tricas%20de%20error.html">
     <font color="blue">
      Métricas de evaluación
     </font>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Clase%2006%20-%20Complejidad%20de%20modelos%2C%20sobreajuste%20y%20metodolog%C3%ADas%20de%20validaci%C3%B3n.html">
     <font color="blue">
      Complejidad de modelos
     </font>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Clase%2006%20-%20Complejidad%20de%20modelos%2C%20sobreajuste%20y%20metodolog%C3%ADas%20de%20validaci%C3%B3n.html#font-color-blue-metodologias-de-validacion-font">
     <font color="blue">
      Metodologías de validación
     </font>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Clase%2006%20-%20Complejidad%20de%20modelos%2C%20sobreajuste%20y%20metodolog%C3%ADas%20de%20validaci%C3%B3n.html#font-color-blue-curva-de-aprendizaje-font">
     <font color="blue">
      Curva de aprendizaje
     </font>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Clase%2007%20-%20Regularizaci%C3%B3n.html">
     Sobreajuste y Regularización
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../titles/U4_description.html">
   U4. APRENDIZAJE NO SUPERVISADO
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../Clase%2008%20-%20Modelos%20de%20Mezclas%20de%20Gausianas.html">
     Modelos de Mezcla de Funciones Gaussianas
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Clase%2009%20-%20Unsupervised%20Learning.html">
     Clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Clase%2009%20-%20Unsupervised%20Learning.html#referencias-generales">
     Referencias Generales
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Clase%2009%20-%20Unsupervised%20Learning.html#metodos-jerarquicos-aglomerativos">
     Métodos jerárquicos/aglomerativos
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Clase%2009%20-%20Unsupervised%20Learning.html#metodos-de-clustering">
     Métodos de clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lab3/lab3_parte1.html">
     Laboratorio 3 - Parte 1. Comparación de metodos de clusterización
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../titles/U5_description.html">
   U5. MODELOS DE ÁRBOLES Y ENSAMBLES
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../Clase%2010%20-%20%C3%81rboles%20de%20Decisi%C3%B3n%2C%20Voting%2C%20Bagging%2C%20Random%20Forest.html">
     Árboles de decisión
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Clase%2011%20-%20Boosting%2C%20Stacking.html">
     Boosting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lab3/lab3_parte2.html">
     Laboratorio 3 - Parte 2. Comparación de metodos basados en árboles
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 current active collapsible-parent">
  <a class="reference internal" href="../../titles/U6_description.html">
   U6. REDES NEURONALES ARTIFICIALES
  </a>
  <ul class="current collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../Clase%2012%20-%20Redes%20Neuronales%20Artificiales.html">
     Redes Neuronales Artificiales
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Clase%2013%20-%20Mapas%20Auto-Organizables.html">
     Mapas Auto-Organizables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Clase%2014%20-%20Redes%20Neuronales%20Recurrentes.html">
     Redes Neuronales Recurrentes
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Laboratorio 4 - Parte 1. Redes neuronales - perceptrón multicapa
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="lab4_parte2.html">
     Laboratorio 4 - Parte 2. Regularización de modelos.
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../titles/U7_description.html">
   U7. MÁQUINAS DE VECTORES DE SOPORTE
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../Clase%2015%20-%20M%C3%A1quinas%20de%20V%C3%A9ctores%20de%20Soporte.html">
     Máquinas de Soporte Vectorial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Clase%2015%20-%20M%C3%A1quinas%20de%20V%C3%A9ctores%20de%20Soporte.html#regresion-por-vectores-de-soporte">
     Regresión por vectores de soporte
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Clase%2016%20-%20Estrategias%20Multiclase%20basadas%20en%20clasificadores%20binarios.html">
     One vs all (one vs the rest)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Clase%2016%20-%20Estrategias%20Multiclase%20basadas%20en%20clasificadores%20binarios.html#one-vs-one-all-vs-all">
     One vs One (All vs All)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Clase%2016%20-%20Estrategias%20Multiclase%20basadas%20en%20clasificadores%20binarios.html#clasificacion-jerarquica">
     Clasificación jerárquica
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lab5/lab5_parte1.html">
     Laboratorio 5 - Parte 1. Redes recurrentes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lab5/lab5_parte2.html">
     Laboratorio 5 - Parte 2. Máquinas de Vectores de Soporte
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../titles/U8_description.html">
   U8. SELECCIÓN EXTRACCIÓN DE CARACTERÍSTICAS
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../Clase%2017%20-%20Selecci%C3%B3n%20de%20Caracter%C3%ADsticas.html">
     Selección de Características
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Clase%2018%20-%20Lasso%20y%20redes%20el%C3%A1sticas.html">
     LASSO (Least Absolute Shrinkage and Selection Operator)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Clase%2018%20-%20Lasso%20y%20redes%20el%C3%A1sticas.html#elastic-nets">
     Elastic Nets
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Clase%2019%20-%20An%C3%A1lisis%20de%20Componentes%20Principales.html">
     Reducción de dimensión: Análisis de Componentes Principales
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Clase%2020%20-%20An%C3%A1lisis%20Discriminante%20de%20Fisher.html">
     Reducción de dimensión: Análisis Discriminante de Fisher
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lab6/lab6_parte1.html">
     Laboratorio 6 - Parte 1: Reducción de dimensión y Selección de características
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lab6/lab6_parte2.html">
     Laboratorio 6 - Parte 2: Reducción de dimensión PCA y LDA
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../titles/U9_description.html">
   U9. SESIONES EXTRA DE LABORATORIO
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../Extra/Basic_Preprocessing_FeatureEngineering.html">
     Preprocesamiento e Ingeniería de características
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Extra/DespliegueModelos.html">
     Despliegue de modelos en ambientes productivos
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/Labs/lab4/lab4_parte1.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/jdariasl/ML_2020/blob/master/Labs/lab4/lab4_parte1.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ejercicio-1-experimentar-con-mlp-para-regresion">
   Ejercicio 1 - Experimentar con MLP para regresión
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ejercicio-2-experimentar-con-mlp-para-clasificacion">
   Ejercicio 2 Experimentar con MLP para clasificación
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <p><strong>Recuerda que una vez abierto, Da clic en “Copiar en Drive”, de lo contrario no podras almacenar tu progreso</strong></p>
<p>Nota: no olvide ir ejecutando las celdas de código de arriba hacia abajo para que no tenga errores de importación de librerías o por falta de definición de variables.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#configuración del laboratorio</span>
<span class="c1"># Ejecuta esta celda!</span>
<span class="o">%</span><span class="k">load_ext</span> autoreload
<span class="o">%</span><span class="k">autoreload</span> 2
<span class="c1">#for local </span>
<span class="c1">#import sys ; sys.path.append(&#39;../commons/utils/&#39;)</span>
<span class="o">!</span>wget https://raw.githubusercontent.com/jdariasl/ML_2020/master/Labs/commons/utils/general.py -O general.py --no-cache
<span class="kn">from</span> <span class="nn">general</span> <span class="kn">import</span> <span class="n">configure_lab4</span>
<span class="n">configure_lab4</span><span class="p">()</span>
<span class="kn">from</span> <span class="nn">lab4</span> <span class="kn">import</span> <span class="o">*</span>
<span class="n">GRADER</span> <span class="o">=</span> <span class="n">part_1</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="laboratorio-4-parte-1-redes-neuronales-perceptron-multicapa">
<h1>Laboratorio 4 - Parte 1. Redes neuronales - perceptrón multicapa<a class="headerlink" href="#laboratorio-4-parte-1-redes-neuronales-perceptron-multicapa" title="Permalink to this headline">¶</a></h1>
<p>Este ejercicio tiene como objetivo implementar una red neuronal artificial de tipo perceptrón multicapa (MLP) para resolver un problema de regresión. Usaremos la librería sklearn. Consulte todo lo relacionado con la definición de hiperparámetros, los métodos para el entrenamiento y la predicción de nuevas muestras en el siguiente enlace: <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor">http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor</a></p>
<p>Para este ejercicio usaremos la base de datos sobre calidad del aire, que ha sido usada en laboratorios previos, pero en este caso trataremos de predecir dos variables en lugar de una, es decir, abordaremos <strong>un problema de múltiples salidas</strong>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#cargamos la bd que está en un archivo .data y ahora la podemos manejar de forma matricial</span>
<span class="n">db</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">loadtxt</span><span class="p">(</span><span class="s1">&#39;AirQuality.data&#39;</span><span class="p">,</span><span class="n">delimiter</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">)</span>  <span class="c1"># Assuming tab-delimiter</span>

<span class="c1">#Esta es la base de datos AirQuality del UCI Machine Learning Repository. En la siguiente URL se encuentra toda</span>
<span class="c1">#la descripción de la base de datos y la contextualización del problema.</span>
<span class="c1">#https://archive.ics.uci.edu/ml/datasets/Air+Quality#</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">db</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="mi">11</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">db</span><span class="p">[:,</span><span class="mi">11</span><span class="p">:</span><span class="mi">13</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Para calcular los errores, vamos a explorar y usar la el <a class="reference external" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics">modulo de metricas den sklearn</a>. Podemos observar que el modulo tiene metricas para regresión y clasificación.</p>
<div class="section" id="ejercicio-1-experimentar-con-mlp-para-regresion">
<h2>Ejercicio 1 - Experimentar con MLP para regresión<a class="headerlink" href="#ejercicio-1-experimentar-con-mlp-para-regresion" title="Permalink to this headline">¶</a></h2>
<p>Para porder implementar nuestra función, lo primero que debemos entender es la estrucutra de la red. Como mencionamos, vamos a solucionar un problema de multiples salidas. Estas salidas con valores continuos. Por lo tanto debemos garantizar que la capa de salida del nuestra red tenga la capacidad de modelar. este tipo de datos.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Pregunta Abierta</span>
<span class="c1">#@markdown ¿De acuerdo al problema planteado, que función de activación debe usar el MLP para un problema de regresión?</span>
<span class="n">respuesta_1</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span> <span class="c1">#@param {type:&quot;string&quot;}</span>
</pre></div>
</div>
</div>
</div>
<p>Una caracteristica de los modelos de sklearn, es que ciertos tipos de atributos, solo pueden ser accedidos cuanto se entrena el modelo. Vamos a realizar un pequeña función para comprobar cual es la capa de activación de los modelos MLP para regresión de sklearn.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># ejercicio de código</span>
<span class="k">def</span> <span class="nf">output_activation</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;funcion que entrena un modelo</span>
<span class="sd">    con data aleatoria para confirmar la funcion</span>
<span class="sd">    de activacion de la ultima capa</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">mlp</span> <span class="o">=</span> <span class="n">MLPRegressor</span><span class="p">()</span>
    <span class="c1"># fit with some random data</span>
    <span class="n">xrandom</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">yrandom</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
    <span class="c1"># llamar el metodo adecuado para entrenar</span>
    <span class="c1"># el mlp con los x y &#39;y&#39; random</span>
    <span class="n">mlp</span><span class="o">.</span><span class="n">fit</span><span class="p">(,</span> <span class="p">)</span>
    <span class="c1"># retornar el atributo de mlp adecuado</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">mlp</span><span class="o">.</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## la funcion que prueba tu implementacion</span>
<span class="c1">#ignora las graficas!!</span>
<span class="n">GRADER</span><span class="o">.</span><span class="n">run_test</span><span class="p">(</span><span class="s2">&quot;ejercicio1&quot;</span><span class="p">,</span> <span class="n">output_activation</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;la función de activación para un problema de regresion es:&quot;</span><span class="p">,</span> <span class="n">output_activation</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<p>Una vez comprobado que sklearn usa la función de activación correcta, vamos crear la función para realizar los experimentos.</p>
<p>Vamos completar la función con el código necesario para usar una red neuronal tipo MLP para solucionar el problema de regresión propuesto.</p>
<ol class="simple">
<li><p>Como función de activación en las capas ocultas use la función ‘tanh’.</p></li>
<li><p>Ajuste el número máximo de épocas a 400.</p></li>
<li><p>Dejamos como variables el número de capas ocultas y el número de neuronas por capa</p></li>
<li><p>Selecciones la función adecuada del <a class="reference external" href="https://scikit-learn.org/stable/modules/classes.html?highlight=metrics#module-sklearn.metrics">modulo de sklearn para calcular el error absoluto medio</a>. Tener en cuenta que parametros usar.</p></li>
<li><p>Debemos usar los nombres explicitos, por ejemplo si para el MLP es necesario usar el parametro <code class="docutils literal notranslate"><span class="pre">activation</span></code>, debe ser llamado: <code class="docutils literal notranslate"><span class="pre">MLPRegressor(activation=...)</span></code></p></li>
<li><p>Explorar que hace la siguiente linea de codigo <code class="docutils literal notranslate"><span class="pre">tuple(2*[100])</span></code></p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># ejercicio de código</span>

<span class="k">def</span> <span class="nf">experimetar_mlp</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">,</span> <span class="n">num_hidden_layers</span><span class="p">,</span> <span class="n">num_neurons</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; función para realizar experimentos con el MLP</span>
<span class="sd">    x: matriz de numpy con caracteristicas</span>
<span class="sd">    y: vector numpy con las variables a predecir</span>
<span class="sd">    num_hidden_layers: list de enteros con el numero de capdas</span>
<span class="sd">        ocultas a usar</span>
<span class="sd">    num_neurons: list de enteros con el numero de neuronas a usar</span>
<span class="sd">    </span>
<span class="sd">    Retorna: dataframe con 6 columnas:</span>
<span class="sd">        - numero de capas, numero de neuronas</span>
<span class="sd">        - promedio de error prueba variable 1 y desviación estandar</span>
<span class="sd">        - promedio de error prueba variable 2 y desviación estandar</span>
<span class="sd">        </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1">#Validamos el modelo</span>
    <span class="n">Folds</span> <span class="o">=</span> <span class="mi">4</span>
    <span class="n">ss</span> <span class="o">=</span> <span class="n">ShuffleSplit</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="n">Folds</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
    <span class="n">resultados</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">hidden_layers</span> <span class="ow">in</span> <span class="n">num_hidden_layers</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">neurons</span> <span class="ow">in</span> <span class="n">num_neurons</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">ss</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">)):</span>
                <span class="c1"># para almacenar errores intermedios</span>
                <span class="n">ErrorY1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">Folds</span><span class="p">)</span>
                <span class="n">ErrorY2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">Folds</span><span class="p">)</span>
                <span class="n">Xtrain</span><span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">train</span><span class="p">,:]</span>
                <span class="n">Ytrain</span> <span class="o">=</span> <span class="n">Y</span><span class="p">[</span><span class="n">train</span><span class="p">,:]</span>
                <span class="n">Xtest</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">test</span><span class="p">,:]</span>
                <span class="n">Ytest</span> <span class="o">=</span> <span class="n">Y</span><span class="p">[</span><span class="n">test</span><span class="p">,:]</span>
                <span class="c1">#Normalizamos los datos</span>
                <span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="o">=</span> <span class="n">Xtrain</span><span class="p">)</span>       
                <span class="n">Xtrain</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">Xtrain</span><span class="p">)</span>
                <span class="n">Xtest</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">Xtest</span><span class="p">)</span>
                <span class="c1">#Haga el llamado a la función para crear y entrenar el modelo usando los datos de entrenamiento</span>
                <span class="c1"># prestar atención a los parametros, correctos.</span>
                <span class="n">hidden_layer_sizes</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">()</span>
                <span class="n">mlp</span> <span class="o">=</span> <span class="n">MLPRegressor</span><span class="p">(</span><span class="n">hidden_layer_sizes</span><span class="o">=</span> <span class="n">hidden_layer_sizes</span><span class="p">)</span>
                <span class="c1"># entrena el MLP</span>
                <span class="n">mlp</span>
                <span class="c1">#Use para el modelo para hacer predicciones sobre el conjunto Xtest</span>
                <span class="n">Yest</span> <span class="o">=</span> <span class="n">mlp</span>
                <span class="c1">#Mida el error absoluto medio para cada una de las dos salidas</span>
                <span class="c1">#Observe bien la documentación. recordar que esta resolviendo</span>
                <span class="c1"># un problema de multiples salidas</span>
                <span class="n">errors</span> <span class="o">=</span> <span class="p">(</span><span class="n">Ytest</span><span class="p">,</span> <span class="n">Yest</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
                <span class="n">ErrorY1</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="o">...</span>
                <span class="n">ErrorY2</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=...</span>
        
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;error para salida 1 = &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">ErrorY1</span><span class="p">))</span> <span class="o">+</span> <span class="s1">&#39;+-&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">ErrorY1</span><span class="p">)))</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;error para salida 2 = &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">ErrorY2</span><span class="p">))</span> <span class="o">+</span> <span class="s1">&#39;+-&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">ErrorY2</span><span class="p">)))</span>
        
            <span class="n">resultados</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span><span class="s1">&#39;capas ocultas&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">hidden_layers</span>
            <span class="n">resultados</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span><span class="s1">&#39;neuronas en capas ocultas&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">neurons</span> 
            <span class="n">resultados</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span><span class="s1">&#39;error de prueba y1(media)&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">ErrorY1</span><span class="p">)</span>
            <span class="n">resultados</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span><span class="s1">&#39;intervalo de confianza y1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">ErrorY1</span><span class="p">)</span>
            <span class="n">resultados</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span><span class="s1">&#39;error de prueba y2(media)&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">ErrorY2</span><span class="p">)</span>
            <span class="n">resultados</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span><span class="s1">&#39;intervalo de confianza y2&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">ErrorY2</span><span class="p">)</span>
            <span class="n">idx</span><span class="o">+=</span><span class="mi">1</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">resultados</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## la funcion que prueba tu implementacion</span>
<span class="c1"># ignorar los prints</span>
<span class="n">GRADER</span><span class="o">.</span><span class="n">run_test</span><span class="p">(</span><span class="s2">&quot;ejercicio2&quot;</span><span class="p">,</span> <span class="n">experimetar_mlp</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># tarda unos minutos!!</span>
<span class="n">resultados_mlpr</span> <span class="o">=</span> <span class="n">experimetar_mlp</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span><span class="mi">12</span><span class="p">,</span><span class="mi">16</span><span class="p">,</span><span class="mi">20</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># ver los resultados</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="n">sns</span><span class="o">.</span><span class="n">relplot</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">resultados_mlpr</span><span class="p">,</span>  <span class="n">x</span><span class="o">=</span><span class="s1">&#39;neuronas en capas ocultas&#39;</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="s1">&#39;intervalo de confianza y1&#39;</span><span class="p">,</span> <span class="n">style</span><span class="o">=</span> <span class="s1">&#39;capas ocultas&#39;</span><span class="p">,</span> <span class="n">kind</span> <span class="o">=</span> <span class="s1">&#39;line&#39;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">relplot</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">resultados_mlpr</span><span class="p">,</span>  <span class="n">x</span><span class="o">=</span><span class="s1">&#39;neuronas en capas ocultas&#39;</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="s1">&#39;intervalo de confianza y2&#39;</span><span class="p">,</span> <span class="n">style</span><span class="o">=</span> <span class="s1">&#39;capas ocultas&#39;</span><span class="p">,</span> <span class="n">kind</span> <span class="o">=</span> <span class="s1">&#39;line&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Pregunta Abierta</span>
<span class="c1">#@markdown  ¿como influencian los parametros de numero de capas y el numero de neuronas? explique de acuerdo a los resultados, recuerde concentrarse en los patrones no en valores especificos</span>
<span class="n">respuesta_2</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span> <span class="c1">#@param {type:&quot;string&quot;}</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="ejercicio-2-experimentar-con-mlp-para-clasificacion">
<h2>Ejercicio 2 Experimentar con MLP para clasificación<a class="headerlink" href="#ejercicio-2-experimentar-con-mlp-para-clasificacion" title="Permalink to this headline">¶</a></h2>
<p>A continuación se leen los datos de un problema de clasificación. El problema corresponde a la clasifiación de dígitos escritos a mano. Usaremos únicamente 4 de las 10 clases disponibles. Los datos fueron preprocesados para reducir el número de características. La técnica usada será analizada más adelante en el curso.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">digits</span> <span class="o">=</span> <span class="n">load_digits</span><span class="p">(</span><span class="n">n_class</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="c1">#--------- preprocesamiento--------------------</span>
<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="mf">0.99</span><span class="p">,</span> <span class="n">whiten</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">digits</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
<span class="c1">#---------- Datos a usar ----------------------</span>
<span class="n">Xd</span> <span class="o">=</span> <span class="n">data</span>
<span class="n">Yd</span> <span class="o">=</span> <span class="n">digits</span><span class="o">.</span><span class="n">target</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Pregunta Abierta</span>
<span class="c1">#@markdown  ¿Qué tipo de función de activación usa el modelo en la capa de salida para un problema de clasificación? </span>
<span class="n">respuesta_3</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span> <span class="c1">#@param {type:&quot;string&quot;}</span>
</pre></div>
</div>
</div>
</div>
<p>como lo hicmos antes, vamos a comprobar con la libreria la función de activación</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># ejercicio de código</span>
<span class="k">def</span> <span class="nf">output_activation_MPC</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;funcion que entrena un modelo</span>
<span class="sd">    con data aleatoria para confirmar la funcion</span>
<span class="sd">    de activacion de la ultima capa</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">mlp</span> <span class="o">=</span> <span class="n">MLPClassifier</span><span class="p">()</span>
    <span class="c1"># fit with some random data</span>
    <span class="n">xrandom</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">yrandom</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
    <span class="c1"># llamar el metodo adecuado para entrenar</span>
    <span class="c1"># el mlp con los x y &#39;y&#39; random</span>
    <span class="n">mlp</span><span class="o">.</span><span class="n">fit</span><span class="p">(,</span> <span class="p">)</span>
    <span class="c1"># retornar el atributo de mlp adecuado</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">mlp</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## la funcion que prueba tu implementacion</span>
<span class="n">GRADER</span><span class="o">.</span><span class="n">run_test</span><span class="p">(</span><span class="s2">&quot;ejercicio3&quot;</span><span class="p">,</span> <span class="n">output_activation_MPC</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;la función de activación para un problema de clasificación es:&quot;</span><span class="p">,</span> <span class="n">output_activation_MPC</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<p>Ahora en nuestro siguiente ejercicio vamos a implementar una red neuronal artificial de tipo perceptrón multicapa (MLP) para resolver un problema de clasificación. Usaremos la librería sklearn. Consulte todo lo relacionado con la definición de hiperparámetros, los métodos para el entrenamiento y la predicción de nuevas muestras en el siguiente enlace: <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier">http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier</a></p>
<p>Vamos completar la función con el código necesario para usar una red neuronal tipo MLP para solucionar el problema de regresión propuesto.</p>
<ol class="simple">
<li><p>Como función de activación en las capas ocultas use la función ‘tanh’.</p></li>
<li><p>Ajuste el número máximo de épocas a 400.</p></li>
<li><p>Dejamos como variables el número de capas ocultas y el número de neuronas por capa</p></li>
<li><p>Selecciones la función adecuada del <a class="reference external" href="https://scikit-learn.org/stable/modules/classes.html?highlight=metrics#module-sklearn.metrics">modulo de sklearn para calcular la exactitud del clasificador</a>. Tener en cuenta que parametros usar.</p></li>
<li><p>Debemos usar los nombres explicitos, por ejemplo si para el MLP es necesario usar el parametro <code class="docutils literal notranslate"><span class="pre">activation</span></code>, debe ser llamado: <code class="docutils literal notranslate"><span class="pre">MLPClassifier(activation=...)</span></code></p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># ejercicio de código</span>
<span class="k">def</span> <span class="nf">experimetar_mlpc</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">,</span> <span class="n">num_hidden_layers</span><span class="p">,</span> <span class="n">num_neurons</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; función para realizar experimentos con el MLP</span>
<span class="sd">    x: matriz de numpy con caracteristicas</span>
<span class="sd">    y: vector numpy con las variables a predecir</span>
<span class="sd">    num_hidden_layers: list de enteros con el numero de capdas</span>
<span class="sd">        ocultas a usar</span>
<span class="sd">    num_neurons: list de enteros con el numero de neuronas a usar</span>
<span class="sd">    </span>
<span class="sd">    Retorna: dataframe con 4 columnas:</span>
<span class="sd">        - numero de capas, numero de neuronas</span>
<span class="sd">        - promedio de error prueba (exactitud/eficiencia) de claisficacion y desviación estandar        </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1">#Validamos el modelo</span>
    <span class="n">Folds</span> <span class="o">=</span> <span class="mi">4</span>
    <span class="n">skf</span> <span class="o">=</span> <span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="n">Folds</span><span class="p">)</span>
    <span class="n">resultados</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">hidden_layers</span> <span class="ow">in</span> <span class="n">num_hidden_layers</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">neurons</span> <span class="ow">in</span> <span class="n">num_neurons</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">skf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)):</span>
                <span class="c1"># para almacenar errores intermedios</span>
                <span class="n">Error</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">Folds</span><span class="p">)</span>
                <span class="n">Xtrain</span><span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">train</span><span class="p">,:]</span>
                <span class="n">Ytrain</span> <span class="o">=</span> <span class="n">Y</span><span class="p">[</span><span class="n">train</span><span class="p">]</span>
                <span class="n">Xtest</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">test</span><span class="p">,</span> <span class="p">:]</span>
                <span class="n">Ytest</span> <span class="o">=</span> <span class="n">Y</span><span class="p">[</span><span class="n">test</span><span class="p">]</span>
                <span class="c1">#Normalizamos los datos</span>
                <span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="o">=</span> <span class="n">Xtrain</span><span class="p">)</span>       
                <span class="n">Xtrain</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">Xtrain</span><span class="p">)</span>
                <span class="n">Xtest</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">Xtest</span><span class="p">)</span>
                <span class="c1">#Haga el llamado a la función para crear y entrenar el modelo usando los datos de entrenamiento</span>
                <span class="c1"># prestar atención a los parametros, correctos.</span>
                <span class="n">hidden_layer_sizes</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
                <span class="c1">#print(hidden_layer_sizes)</span>
                <span class="n">mlp</span> <span class="o">=</span> <span class="n">MLPClassifier</span><span class="p">(</span><span class="n">hidden_layer_sizes</span> <span class="o">=</span> <span class="n">hidden_layer_sizes</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
                <span class="c1"># entrenar el MLP</span>
                <span class="n">mlp</span><span class="o">...</span>
                <span class="c1">#Use para el modelo para hacer predicciones sobre el conjunto Xtest</span>
                <span class="n">Yest</span> <span class="o">=</span> <span class="n">mlp</span><span class="o">.</span>
                <span class="c1">#Mida el error absoluto medio para cada una de las dos salidas</span>
                <span class="c1">#Observe bien la documentación. recordar que esta resolviendo</span>
                <span class="c1"># un problema de multiples salidas</span>
                <span class="n">Error</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="o">...</span><span class="p">(</span><span class="n">Ytest</span><span class="p">,</span> <span class="n">Yest</span><span class="p">)</span>
        
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;error para configuracion de params = &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">Error</span><span class="p">))</span> <span class="o">+</span> <span class="s1">&#39;+-&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">Error</span><span class="p">)))</span>
        
            <span class="n">resultados</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span><span class="s1">&#39;capas ocultas&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">hidden_layers</span>
            <span class="n">resultados</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span><span class="s1">&#39;neuronas en capas ocultas&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">neurons</span> 
            <span class="n">resultados</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span><span class="s1">&#39;error de prueba(media)&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">Error</span><span class="p">)</span>
            <span class="n">resultados</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span><span class="s1">&#39;intervalo de confianza&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">Error</span><span class="p">)</span>
            <span class="n">idx</span><span class="o">+=</span><span class="mi">1</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">resultados</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## la funcion que prueba tu implementacion</span>
<span class="n">GRADER</span><span class="o">.</span><span class="n">run_test</span><span class="p">(</span><span class="s2">&quot;ejercicio4&quot;</span><span class="p">,</span> <span class="n">experimetar_mlpc</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># tarda unos minutos!!</span>
<span class="n">resultados_mlpc</span> <span class="o">=</span> <span class="n">experimetar_mlpc</span><span class="p">(</span><span class="n">Xd</span><span class="p">,</span><span class="n">Yd</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">12</span><span class="p">,</span><span class="mi">16</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">24</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># ver los resultados</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="n">sns</span><span class="o">.</span><span class="n">relplot</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">resultados_mlpc</span><span class="p">,</span>  <span class="n">x</span><span class="o">=</span><span class="s1">&#39;neuronas en capas ocultas&#39;</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="s1">&#39;error de prueba(media)&#39;</span><span class="p">,</span> <span class="n">style</span><span class="o">=</span> <span class="s1">&#39;capas ocultas&#39;</span><span class="p">,</span> <span class="n">kind</span> <span class="o">=</span> <span class="s1">&#39;line&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Pregunta Abierta</span>
<span class="c1">#@markdown ¿Cuántas neuronas en la capa de salida tiene el modelo?¿Porqué debe tener ese número?</span>
<span class="n">respuesta_4</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span> <span class="c1">#@param {type:&quot;string&quot;}</span>
</pre></div>
</div>
</div>
</div>
<p><strong>nota rapida</strong> En la practica sklearn no es una la libreria indicada para desarollar redes neuronales, para practicas mas avanzadas y realizar modelos en el “mundo real” <a class="reference external" href="https://colab.research.google.com/github/lexfridman/mit-deep-learning/blob/master/tutorial_deep_learning_basics/deep_learning_basics.ipynb">se deben usar conceptos de deep learning y una libreria llamada Keras</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">GRADER</span><span class="o">.</span><span class="n">check_tests</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Integrantes</span>
<span class="n">codigo_integrante_1</span> <span class="o">=</span><span class="s1">&#39;&#39;</span> <span class="c1">#@param {type:&quot;string&quot;}</span>
<span class="n">codigo_integrante_2</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>  <span class="c1">#@param {type:&quot;string&quot;}</span>
</pre></div>
</div>
</div>
</div>
<hr class="docutils" />
<p>esta linea de codigo va fallar, es de uso exclusivo de los profesores</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">GRADER</span><span class="o">.</span><span class="n">grade</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./Labs/lab4"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="../../Clase%2014%20-%20Redes%20Neuronales%20Recurrentes.html" title="previous page">Redes Neuronales Recurrentes</a>
    <a class='right-next' id="next-link" href="lab4_parte2.html" title="next page">Laboratorio 4 - Parte 2. Regularización de modelos.</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By <b>Julián Arias</b>/ Universidad de Antioquia -- Labs por Germán E. Melo - Deiry Sofía Navas<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../../_static/js/index.d3f166471bb80abb5163.js"></script>


    
    <!-- Google Analytics -->
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-51547737-2', 'auto');
      ga('set', 'anonymizeIp', true);
      ga('send', 'pageview');
    </script>
    <script async src='https://www.google-analytics.com/analytics.js'></script>
    <!-- End Google Analytics -->
    
  </body>
</html>