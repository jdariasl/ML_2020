
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Laboratorio 5 - Parte 1. Redes recurrentes &#8212; 2021 Introducción al Machine Learning</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet">
  <link href="../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Laboratorio 5 - Parte 2. Máquinas de Vectores de Soporte" href="lab5_parte2.html" />
    <link rel="prev" title="One vs all (one vs the rest)" href="../../Clase%2016%20-%20Estrategias%20Multiclase%20basadas%20en%20clasificadores%20binarios.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
<script async="" src="https://www.google-analytics.com/analytics.js"></script>
<script>
                        window.ga = window.ga || function () {
                            (ga.q = ga.q || []).push(arguments) };
                        ga.l = +new Date;
                        ga('create', 'UA-51547737-2', 'auto');
                        ga('set', 'anonymizeIp', true);
                        ga('send', 'pageview');
                    </script>

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/fudea.jpg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">2021 Introducción al Machine Learning</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../intro.html">
   Course information
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../titles/U0_IntroLabs.html">
   INTRODUCCIÓN A PYTHON, NUMPY Y OTRAS HERRAMIENTAS
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Intro/Intro.html">
     Introdución para los laboratorios de Machine Learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../titles/U1_description.html">
   U1. INTRODUCCIÓN AL MACHINE LEARNING
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Clase%2001%20-%20Introducci%C3%B3n%20al%20Machine%20Learning.html">
     Introducción al Machine Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Clase%2002%20-%20Regresi%C3%B3n%20lineal%20y%20regresi%C3%B3n%20log%C3%ADstica.html">
     <font color="blue">
      Modelos básicos de aprendizaje
     </font>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Clase%2003%20-%20Funciones%20discriminantes%20Gausianas.html">
     Modelos de clasificación empleando funciones de densidad Gausianas
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lab1/lab1_parte1.html">
     Laboratorio 1 - Parte 1 Regresión polinomial múltiple
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lab1/lab1_parte2.html">
     Laboratorio 1 - Parte 2. Regresión logística
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../titles/U2_description.html">
   U2. MODELOS NO PARÁMETRICOS
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Clase%2004%20-%20Modelos%20no%20Param%C3%A9tricos.html">
     Modelos no parámetricos
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lab2/lab2_parte1.html">
     Laboratorio 2 - Parte 1. KNN para un problema de clasificación
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lab2/lab2_parte2.html">
     Laboratorio 2 - Parte 2. KNN para un problema de regresión
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../titles/U3_description.html">
   U3. COMPLEJIDAD DE MODELOS Y VALIDACIÓN
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Clase%2005%20-%20M%C3%A9tricas%20de%20error.html">
     <font color="blue">
      Métricas de evaluación
     </font>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Clase%2006%20-%20Complejidad%20de%20modelos%2C%20sobreajuste%20y%20metodolog%C3%ADas%20de%20validaci%C3%B3n.html">
     <font color="blue">
      Complejidad de modelos
     </font>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Clase%2007%20-%20Regularizaci%C3%B3n.html">
     Sobreajuste y Regularización
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../titles/U4_description.html">
   U4. APRENDIZAJE NO SUPERVISADO
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Clase%2008%20-%20Modelos%20de%20Mezclas%20de%20Gausianas.html">
     Modelos de Mezcla de Funciones Gaussianas
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Clase%2009%20-%20Unsupervised%20Learning.html">
     Clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lab3/lab3_parte1.html">
     Laboratorio 3 - Parte 1. Comparación de metodos de clusterización
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../titles/U5_description.html">
   U5. MODELOS DE ÁRBOLES Y ENSAMBLES
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Clase%2010%20-%20%C3%81rboles%20de%20Decisi%C3%B3n%2C%20Voting%2C%20Bagging%2C%20Random%20Forest.html">
     Árboles de decisión
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Clase%2011%20-%20Boosting%2C%20Stacking.html">
     Boosting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lab3/lab3_parte2.html">
     Laboratorio 3 - Parte 2. Comparación de metodos basados en árboles
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../titles/U6_description.html">
   U6. REDES NEURONALES ARTIFICIALES
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Clase%2012%20-%20Redes%20Neuronales%20Artificiales.html">
     Redes Neuronales Artificiales
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Clase%2013%20-%20Mapas%20Auto-Organizables.html">
     Mapas Auto-Organizables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Clase%2014%20-%20Redes%20Neuronales%20Recurrentes.html">
     Redes Neuronales Recurrentes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lab4/lab4_parte1.html">
     Laboratorio 4 - Parte 1. Redes neuronales - perceptrón multicapa
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lab4/lab4_parte2.html">
     Laboratorio 4 - Parte 2. Regularización de modelos.
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../../titles/U7_description.html">
   U7. MÁQUINAS DE VECTORES DE SOPORTE
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="../../Clase%2015%20-%20M%C3%A1quinas%20de%20V%C3%A9ctores%20de%20Soporte.html">
     Máquinas de Vectores de Soporte
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Clase%2016%20-%20Estrategias%20Multiclase%20basadas%20en%20clasificadores%20binarios.html">
     One vs all (one vs the rest)
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Laboratorio 5 - Parte 1. Redes recurrentes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="lab5_parte2.html">
     Laboratorio 5 - Parte 2. Máquinas de Vectores de Soporte
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../titles/U8_description.html">
   U8. SELECCIÓN EXTRACCIÓN DE CARACTERÍSTICAS
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Clase%2017%20-%20Selecci%C3%B3n%20de%20Caracter%C3%ADsticas.html">
     Selección de Características
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Clase%2018%20-%20Lasso%20y%20redes%20el%C3%A1sticas.html">
     LASSO (Least Absolute Shrinkage and Selection Operator)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Clase%2019%20-%20An%C3%A1lisis%20de%20Componentes%20Principales.html">
     Reducción de dimensión: Análisis de Componentes Principales
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Clase%2020%20-%20An%C3%A1lisis%20Discriminante%20de%20Fisher.html">
     Reducción de dimensión: Análisis Discriminante de Fisher
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lab6/lab6_parte1.html">
     Laboratorio 6 - Parte 1: Reducción de dimensión y Selección de características
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lab6/lab6_parte2.html">
     Laboratorio 6 - Parte 2: Reducción de dimensión PCA y LDA
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../titles/U9_description.html">
   A1. SESIONES EXTRA DE LABORATORIO
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Extra/Basic_Preprocessing_FeatureEngineering.html">
     Preprocesamiento e Ingeniería de características
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Extra/DespliegueModelos.html">
     Despliegue de modelos en ambientes productivos
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/Labs/lab5/lab5_parte1.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/jdariasl/ML_2020/blob/master/Labs/lab5/lab5_parte1.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ejercicio-1-exploracion-del-problema">
   Ejercicio 1 - Exploración del problema
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ejercicio-2-experimentar-con-rnn">
   Ejercicio 2 - Experimentar con RNN
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ejercicio-3-comparacion-con-mlp">
   Ejercicio 3 - Comparación con MLP
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ejercicio-4-comparacion-con-lstm">
   Ejercicio 4 - Comparación con LSTM
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <p><strong>Recuerda que una vez abierto, Da clic en “Copiar en Drive”, de lo contrario no podras almacenar tu progreso</strong></p>
<p>Nota: no olvide ir ejecutando las celdas de código de arriba hacia abajo para que no tenga errores de importación de librerías o por falta de definición de variables.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#configuración del laboratorio</span>
<span class="c1"># Ejecuta esta celda!</span>
<span class="o">%</span><span class="k">load_ext</span> autoreload
<span class="o">%</span><span class="k">autoreload</span> 2
<span class="c1">#for local </span>
<span class="c1">#import sys ; sys.path.append(&#39;../commons/utils/&#39;)</span>
<span class="o">!</span>wget https://raw.githubusercontent.com/jdariasl/ML_2020/master/Labs/commons/utils/general.py -O general.py --no-cache
<span class="kn">from</span> <span class="nn">general</span> <span class="kn">import</span> <span class="n">configure_lab5_1</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;TF_CPP_MIN_LOG_LEVEL&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;3&#39;</span> 
<span class="kn">from</span> <span class="nn">tensorflow.keras.utils</span> <span class="kn">import</span> <span class="n">plot_model</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">set_verbosity</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">ERROR</span><span class="p">)</span> 
<span class="n">configure_lab5_1</span><span class="p">()</span>
<span class="kn">from</span> <span class="nn">lab5</span> <span class="kn">import</span> <span class="o">*</span>
<span class="n">GRADER</span><span class="p">,</span> <span class="n">dataset</span> <span class="o">=</span> <span class="n">part_1</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="laboratorio-5-parte-1-redes-recurrentes">
<h1>Laboratorio 5 - Parte 1. Redes recurrentes<a class="headerlink" href="#laboratorio-5-parte-1-redes-recurrentes" title="Permalink to this headline">¶</a></h1>
<p>En este  laboratorio entrenaremos una Red Neuronal Recurrente para la predicción de una serie de tiempo.</p>
<p>Este problema corresponde a una configuración many-to-one.</p>
<p>En este caso usaremos una serie de tiempo que corresponde al número de pasajeros internacionales por mes, desde el año 1949 hasta el año 1960.</p>
<p>En la siguiente celda visualizamos los datos.</p>
<p>Debemos observar el aparente periodo que existe en nuestra variable. ¿cada cuantos meses parece repertirse el patrón de la serie?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># creamos una variable para</span>
<span class="c1"># el tiempo</span>
<span class="n">Time</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">date_range</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">datetime64</span><span class="p">(</span><span class="s1">&#39;1949-01&#39;</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">datetime64</span><span class="p">(</span><span class="s1">&#39;1961-01&#39;</span><span class="p">),</span> <span class="n">freq</span><span class="o">=</span><span class="s1">&#39;M&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;tenemos dispnible nuestra base de datos en el pandas DF &#39;dataset&#39; </span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">Time</span><span class="p">,</span><span class="n">dataset</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;International airline passengers&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Time (months)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span> <span class="n">pd</span><span class="o">.</span><span class="n">date_range</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">datetime64</span><span class="p">(</span><span class="s1">&#39;1949-01&#39;</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">datetime64</span><span class="p">(</span><span class="s1">&#39;1961-01&#39;</span><span class="p">),</span> <span class="n">freq</span><span class="o">=</span><span class="s1">&#39;3M&#39;</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>En nuestro primer ejercicio vamos a explorar, el patrón que observamos en la grafica anterior. Esto tambien nos puede decir que relación existe entre una muestra con las muestras inmediantamente pasadas.</p>
<p>La libreria statsmodel <a class="reference external" href="https://www.statsmodels.org/stable/generated/statsmodels.graphics.tsaplots.plot_acf.html">tiene una función que nos sirve para analizar esta relación</a>.</p>
<div class="section" id="ejercicio-1-exploracion-del-problema">
<h2>Ejercicio 1 - Exploración del problema<a class="headerlink" href="#ejercicio-1-exploracion-del-problema" title="Permalink to this headline">¶</a></h2>
<p>Este plot realiza una operación cuyos detalles son explicados en mayor profundidad en <a class="reference external" href="https://machinelearningmastery.com/gentle-introduction-autocorrelation-partial-autocorrelation/">esta buena entrada de blog</a>. Pero nuestro laboratorio lo que no interesa es entender:</p>
<ol class="simple">
<li><p>El valor varia entre 1.0 y -1.0.</p></li>
<li><p>Cuando el valor de la correlación es 1.0, corresponde el valor maximo indicando una relación positiva entre la variable y su correspondiente lag o retraso.</p></li>
<li><p>Cuando el valor de la correlación es -1.0, corresponde el valor mínimo indicando una relación negativa entre la variable y su correspondiente lag o retraso..</p></li>
<li><p>0.0 indica que los valores no están relacionados.</p></li>
<li><p>el lag indica, el número de retrasos. Si el valor de la correlación en el lag  5 es igual 0.75, indica una relación positiva alta entre el quinto retraso anterior en la mayoria de muestras de nuestra variable de respuesta.</p></li>
</ol>
<p>Ahora, grafiquemos la correlación para un maximo de 36 lags de nuestros datos. Esto significa que estamos analizando las relación de una muestras respecto a la 36 muestras pasdas.</p>
<p>Sabiendo que nuestro eje X representa los meses y nuestro eje y representan el numero de pasajeros. Al realizar el analisis de lags estamos determinando si el número de pasajeros de los meses pasados tiene influencia en el nuúmero de pasajeros en el mes acutal.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">statsmodels.graphics</span> <span class="kn">import</span> <span class="n">tsaplots</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">7</span><span class="p">))</span>
<span class="c1"># Display the autocorrelation plot of your time series</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">tsaplots</span><span class="o">.</span><span class="n">plot_acf</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">passengers</span><span class="p">,</span> <span class="n">lags</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">37</span><span class="p">),</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">37</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">37</span><span class="p">,</span><span class="mi">12</span><span class="p">),</span> <span class="mf">0.1</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span> <span class="n">c</span> <span class="o">=</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="s2">&quot;v&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>reforzando el entendimiento de lo anterior,en la grafica podemos ver lo siguiente:</p>
<ol class="simple">
<li><p>cuando hay un lag = 5 (es decir evaluar que tan relacionadas estas las 5 muestras anteriores), tenemos una autocorrelación <span class="math notranslate nohighlight">\(\approx\)</span> 0.75</p></li>
<li><p>cuando hay un lag = 25 (es decir evaluar que tan relacionadas estas las 25 muestras anteriores), tenemos una autocorrelación <span class="math notranslate nohighlight">\(\approx\)</span> 0.5</p></li>
<li><p>Presta atención al patrón que se resalta con las marcas rojas</p></li>
</ol>
<p>Vamos observar estas relaciones viendo como los picos de correlación se relacionan con los patrones que vemos. Graficamos los valores de autocorrelación con la grafica de los valores reales.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">7</span><span class="p">))</span>
<span class="c1"># Display the autocorrelation plot of your time series</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">tsaplots</span><span class="o">.</span><span class="n">plot_acf</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">passengers</span><span class="p">,</span> <span class="n">lags</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">37</span><span class="p">),</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">37</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Valor de correlación&quot;</span><span class="p">)</span>
<span class="n">ax2</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">twinx</span><span class="p">()</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Numero de pasajeros&quot;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">37</span><span class="p">],</span> <span class="n">c</span> <span class="o">=</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Ahora bien, para poder aplicar nuestra RNN, debemos transformar nuestros datos. Observa la figura, para entender como debemos transformar los datos.</p>
<p><img alt="rnn" src="https://raw.githubusercontent.com/jdariasl/ML_2020/master/Labs/commons/images/UDEA%20-%20RNN.jpg" /></p>
<p>Sabiendo que nuestro anterior analisis de correlación nos indico como están  relacionadas las muestras pasadas y al entender que la preparación de datos consiste en usar las muestras pasadas para predicir la muestra siguiente. Responde la siguiente pregunta.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Pregunta Abierta</span>
<span class="c1">#@markdown ¿Cual podria ser el numero maximo de muestras pasadas para transformar nuestros conjunto de datos?</span>
<span class="n">respuesta_1</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span> <span class="c1">#@param {type:&quot;string&quot;}</span>
</pre></div>
</div>
</div>
</div>
<p>Finalmente, se propone la siguiente función para realizar la transformación</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># convert an array of values into a dataset matrix</span>
<span class="k">def</span> <span class="nf">create_dataset</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">look_back</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;funcion que crea dataset apto para RNN</span>
<span class="sd">    </span>
<span class="sd">    dataset: pandas dataframe con una sola columna</span>
<span class="sd">    look_back: numero de retrasos con los cuales queremos construir</span>
<span class="sd">        las caracteristicas</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">dataX</span><span class="p">,</span> <span class="n">dataY</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span><span class="o">-</span><span class="n">look_back</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="n">i</span><span class="p">:(</span><span class="n">i</span><span class="o">+</span><span class="n">look_back</span><span class="p">),</span> <span class="mi">0</span><span class="p">]</span>
        <span class="n">dataX</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
        <span class="n">dataY</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="n">look_back</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
    
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dataX</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dataY</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataY</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># observemos el funcionamiento</span>
<span class="n">x_to_see</span><span class="p">,</span> <span class="n">y_to_see</span> <span class="o">=</span>  <span class="n">create_dataset</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="s2">&quot;primeras muestras de x&quot;</span><span class="p">,</span> <span class="n">x_to_see</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">])</span>
<span class="n">display</span><span class="p">(</span><span class="s2">&quot;primeras muestras de y&quot;</span><span class="p">,</span> <span class="n">y_to_see</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="ejercicio-2-experimentar-con-rnn">
<h2>Ejercicio 2 - Experimentar con RNN<a class="headerlink" href="#ejercicio-2-experimentar-con-rnn" title="Permalink to this headline">¶</a></h2>
<p>En este laboratorio vamos a explorar una libreria muy popular pero un poco más avanzada, para construir redes neuronales llamadas <a class="reference external" href="https://www.tensorflow.org/?hl=es-419">TensorFlow</a>.</p>
<p>En el siguiente ejercicio vamos a crear una función para construir una RNN usando la libreria mencionada.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># ejercicio de código </span>
<span class="c1"># usar solo estos objetos</span>
<span class="c1"># importados</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">SimpleRNN</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="k">def</span> <span class="nf">create_rnn_model</span><span class="p">(</span><span class="n">look_back</span><span class="p">,</span> <span class="n">num_hidden_neurons</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;funcion que crear modelo que usa mean_absolute_error</span>
<span class="sd">    como funcion de perdida</span>
<span class="sd">    RNN con base al número de lags y numero de neuronas</span>

<span class="sd">    </span>
<span class="sd">    parametros</span>
<span class="sd">    look_back (int): numero de retrasos a ejecutar</span>
<span class="sd">    num_hidden_neurons (int): numero neuronas en la capa oculta</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># se inicializa el modelo</span>
    <span class="c1"># podemos asginar un nombre</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;rnn&#39;</span><span class="p">)</span>
    <span class="c1"># adicionar una capa RNN</span>
    <span class="c1"># reemplace los valores</span>
    <span class="c1"># asigna el nombre de rnn_layer</span>
    <span class="n">rnn_layer</span> <span class="o">=</span> <span class="n">SimpleRNN</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">input_shape</span> <span class="o">=</span> <span class="o">...</span><span class="p">),</span> 
                          <span class="n">use_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="o">...</span><span class="p">)</span> 
    <span class="c1"># en tensorflow debemos adicionar la capa </span>
    <span class="c1"># al modelo</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
    <span class="c1"># la red termina con una capa Densa de una salida</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;dense_layer&quot;</span><span class="p">))</span>
    <span class="c1"># remplace la perdida por el parametro correcto</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=...</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">)</span>
    <span class="k">return</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">GRADER</span><span class="o">.</span><span class="n">run_test</span><span class="p">(</span><span class="s2">&quot;ejercicio1&quot;</span><span class="p">,</span> <span class="n">create_rnn_model</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># observa la diferencias de los modelos al</span>
<span class="c1"># cambiar los parametros</span>
<span class="c1"># observe los inputs y output</span>
<span class="c1"># Los None hacer referencia al numero de muestras de los conjuntos</span>
<span class="c1"># de datos</span>
<span class="n">display</span><span class="p">(</span><span class="s2">&quot;1 retraso, 2 neuronas ocultas&quot;</span><span class="p">,</span> <span class="n">plot_model</span><span class="p">(</span>
    <span class="n">create_rnn_model</span><span class="p">(</span><span class="n">look_back</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span><span class="n">num_hidden_neurons</span> <span class="o">=</span> <span class="mi">2</span><span class="p">),</span> 
    <span class="n">show_shapes</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>

<span class="n">display</span><span class="p">(</span><span class="s2">&quot;4 retraso, 1 neuronas ocultas&quot;</span><span class="p">,</span> <span class="n">plot_model</span><span class="p">(</span>
    <span class="n">create_rnn_model</span><span class="p">(</span><span class="n">look_back</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span><span class="n">num_hidden_neurons</span> <span class="o">=</span> <span class="mi">1</span><span class="p">),</span> 
    <span class="n">show_shapes</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>Con nuestra funcion que crea modelos, vamos experimentar variando los dos parametros:</p>
<ul class="simple">
<li><p>número de retrasos</p></li>
<li><p>número de neuronas en la capa oculta</p></li>
</ul>
<p>Otras condiciones:</p>
<ul class="simple">
<li><p>Vamos a dejar fijo el # de epocas 50.</p></li>
<li><p>Usaremos la metrica Error absoluto. Recordar que solo usamos la implementaciones de <a class="reference external" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics">sklearn</a></p></li>
<li><p>En la celda de codigo se propone la implementacion para cambiar las dimensiones de nuestras matrices. Este cambio es requerimiento de Tensorflow.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">datas_as_tensorflow</span><span class="p">(</span><span class="n">trainX</span><span class="p">,</span> <span class="n">testX</span><span class="p">):</span>
  <span class="c1"># adaptar para compatibilidad con tensorflow</span>
  <span class="c1"># la libreria necesita tener los cojuntos de datos de la manera</span>
  <span class="c1"># (# muestras, 1, # de caraceristicas)</span>
  <span class="n">trainX</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">trainX</span><span class="p">,</span> <span class="p">(</span><span class="n">trainX</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="n">trainX</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
  <span class="n">testX</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">testX</span><span class="p">,</span> <span class="p">(</span><span class="n">testX</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="n">testX</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
  <span class="k">return</span><span class="p">(</span><span class="n">trainX</span><span class="p">,</span> <span class="n">testX</span><span class="p">)</span>
  <span class="k">return</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">trainX</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">testX</span><span class="p">))</span>


<span class="c1">#ejercicio de código</span>
<span class="k">def</span> <span class="nf">experimentar_rnn</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">look_backs</span><span class="p">,</span> <span class="n">hidden_neurons</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;funcion que realiza experimentos para evaluar una RNN de elman usando</span>
<span class="sd">        el error absoluto medio como medida de error</span>
<span class="sd">    </span>
<span class="sd">    data: pd.Dataframe, dataset a usar</span>
<span class="sd">    look_back: List[int], lista con los numero de retrasos a evaluar</span>
<span class="sd">    hidden_neurons: List[int], list con el numero de neuronas en la capa oculta</span>
<span class="sd">    retorna: pd.Dataframe con las siguientes columnas:</span>
<span class="sd">        - lags</span>
<span class="sd">        - neuronas por capas</span>
<span class="sd">        - error de entrenamiento</span>
<span class="sd">        - error de prueba</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Normalizar</span>
    <span class="n">scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">(</span><span class="n">feature_range</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="c1"># realizar el split</span>
    <span class="n">train_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.7</span><span class="p">)</span>
    <span class="n">test_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span> <span class="o">-</span> <span class="n">train_size</span>
    <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">train_size</span><span class="p">,:],</span> <span class="n">dataset</span><span class="p">[</span><span class="n">train_size</span><span class="p">:</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">),:]</span>
    <span class="n">resultados</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">num_hidden_neurons</span> <span class="ow">in</span> <span class="n">hidden_neurons</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">look_back</span> <span class="ow">in</span> <span class="n">look_backs</span><span class="p">:</span>
            <span class="c1"># aplicar la transformacion</span>
            <span class="n">trainX</span><span class="p">,</span> <span class="n">trainY</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">look_back</span><span class="p">)</span>
            <span class="n">testX</span><span class="p">,</span> <span class="n">testY</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="n">test</span><span class="p">,</span> <span class="n">look_back</span><span class="p">)</span>
            <span class="n">trainX</span><span class="p">,</span> <span class="n">testX</span> <span class="o">=</span> <span class="n">datas_as_tensorflow</span><span class="p">(</span><span class="n">trainX</span><span class="p">,</span> <span class="n">testX</span><span class="p">)</span>
            <span class="c1"># creemos el modelo</span>
            <span class="n">model</span> <span class="o">=</span> <span class="o">....</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
            <span class="c1"># entrenemos el modelo</span>
            <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="o">....</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span> <span class="o">....</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
            <span class="c1"># predecimos en los conjuntos</span>
            <span class="n">trainYPred</span>  <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
            <span class="n">testYPred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
            <span class="n">errorPrueba</span> <span class="o">=</span> <span class="o">...</span><span class="p">(</span><span class="o">...</span><span class="p">,</span><span class="o">...</span><span class="p">)</span>
            <span class="n">errorEntrenamiento</span> <span class="o">=</span> <span class="o">...</span><span class="p">(</span><span class="o">....</span><span class="p">,</span> <span class="o">....</span><span class="p">)</span>
            <span class="n">resultados</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span><span class="s1">&#39;lags&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">look_back</span>
            <span class="n">resultados</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span><span class="s1">&#39;neuronas por capa&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">num_hidden_neurons</span>
            <span class="n">resultados</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span><span class="s1">&#39;error de entrenamiento&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="o">...</span>
            <span class="n">resultados</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span><span class="s1">&#39;error de prueba&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="o">...</span>
            <span class="n">idx</span><span class="o">+=</span><span class="mi">1</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;termina para&quot;</span><span class="p">,</span> <span class="n">look_back</span><span class="p">,</span> <span class="n">num_hidden_neurons</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="p">(</span><span class="n">resultados</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">GRADER</span><span class="o">.</span><span class="n">run_test</span><span class="p">(</span><span class="s2">&quot;ejercicio2&quot;</span><span class="p">,</span> <span class="n">experimentar_rnn</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Ahora vamos a ver los resultados del experimentos:</p>
<ol class="simple">
<li><p>variando los lags dejando las neuronas por capa fijas</p></li>
<li><p>variando las neuronas y dejando los retrasos fijos</p></li>
</ol>
<p>experimente con diferentes configuraciones. Por la inicialización aleatorias los resultados pueden cambiar. Preste a los patrones que se van presentando y no a los valores exactos.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># observa el comportamiento de los lags</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="n">resultadosRNN</span> <span class="o">=</span> <span class="n">experimentar_rnn</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">look_backs</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="mi">12</span><span class="p">,</span><span class="mi">24</span><span class="p">,</span><span class="mi">30</span><span class="p">,</span><span class="mi">36</span><span class="p">],</span> <span class="n">hidden_neurons</span><span class="o">=</span><span class="p">[</span><span class="mi">15</span><span class="p">])</span>
<span class="c1"># plot</span>
<span class="n">ax1</span>  <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">relplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span> <span class="n">resultadosRNN</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span> <span class="s1">&#39;lags&#39;</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="s1">&#39;error de prueba&#39;</span><span class="p">,</span> <span class="n">kind</span> <span class="o">=</span> <span class="s1">&#39;line&#39;</span><span class="p">,</span> <span class="n">aspect</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;efecto del # retrasos&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">resultadosRNN</span> <span class="o">=</span> <span class="n">experimentar_rnn</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">look_backs</span> <span class="o">=</span> <span class="p">[</span><span class="mi">9</span><span class="p">],</span> <span class="n">hidden_neurons</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">,</span><span class="mi">15</span><span class="p">,</span><span class="mi">30</span><span class="p">,</span><span class="mi">60</span><span class="p">])</span>
<span class="n">ax2</span>  <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">relplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span> <span class="n">resultadosRNN</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span> <span class="s1">&#39;neuronas por capa&#39;</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="s1">&#39;error de prueba&#39;</span><span class="p">,</span> <span class="n">kind</span> <span class="o">=</span> <span class="s1">&#39;line&#39;</span><span class="p">,</span> <span class="n">aspect</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;efecto del # neuronas&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Pregunta Abierta</span>
<span class="c1">#@markdown ¿Por qué seguir aumentando los tiempos de retardo no implica siempre una mejora en la predicción del modelo?</span>
<span class="n">respuesta_2</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span> <span class="c1">#@param {type:&quot;string&quot;}</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Pregunta Abierta</span>
<span class="c1">#@markdown ¿Entre el número de retrasos y de neuronas, que parámetro tiene una mayor influencia en el error de prueba?</span>
<span class="n">respuesta_3</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span> <span class="c1">#@param {type:&quot;string&quot;}</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="ejercicio-3-comparacion-con-mlp">
<h2>Ejercicio 3 - Comparación con MLP<a class="headerlink" href="#ejercicio-3-comparacion-con-mlp" title="Permalink to this headline">¶</a></h2>
<p>En este ejercicio vamos a realizar el mismo ejercicio, pero con un MLP. Con esto vamos a comparar los resultados obtenidos con la RNN.</p>
<p>Para ellos vamos a :</p>
<ol class="simple">
<li><p>variar los retrasos, que corresponden a las neuronas en la capa de entrada</p></li>
<li><p>vamos a dejar solo una capa oculta y vamos a variar el número de neuronas en esta capa</p></li>
<li><p>el número de epocas también va ser de 50</p></li>
<li><p>el valor por defecto sera usado para el resto de parámetros</p></li>
<li><p>utilizar como medida de error el error absoluto medio.  <a class="reference external" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics">recordar usar la implementación del modulo de metricas de sklearn</a></p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Pregunta Abierta</span>
<span class="c1">#@markdown ¿explique la principal diferencia entre un MLP y una red recurrente? justificar usando usando como contexto el problema que estamos resolviendo.</span>
<span class="n">respuesta_4</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span> <span class="c1">#@param {type:&quot;string&quot;}</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#ejercicio de código</span>
<span class="k">def</span> <span class="nf">experimentar_MLP</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">look_backs</span><span class="p">,</span> <span class="n">hidden_neurons</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;funcion que realiza experimentos para evaluar una MLPusando</span>
<span class="sd">        MAPE como medida de error</span>
<span class="sd">    </span>
<span class="sd">    data: pd.Dataframe, dataset a usar</span>
<span class="sd">    look_back: List[int], lista con los numero de retrasos a evaluar</span>
<span class="sd">    hidden_neurons: List[int], list con el numero de neuronas en la capa oculta</span>
<span class="sd">    retorna: pd.Dataframe con las siguientes columnas:</span>
<span class="sd">        - lags</span>
<span class="sd">        - neuronas por capas</span>
<span class="sd">        - error de prueba</span>
<span class="sd">        - tiempo de entrenamiento</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># we need to normalize the dataset before</span>
    <span class="c1">#</span>
    <span class="n">scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">(</span><span class="n">feature_range</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="c1"># split into train and test sets</span>
    <span class="n">train_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.7</span><span class="p">)</span>
    <span class="n">test_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span> <span class="o">-</span> <span class="n">train_size</span>
    <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">train_size</span><span class="p">,:],</span> <span class="n">dataset</span><span class="p">[</span><span class="n">train_size</span><span class="p">:</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">),:]</span>
    <span class="n">resultados</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">num_hidden_neurons</span> <span class="ow">in</span> <span class="n">hidden_neurons</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">look_back</span> <span class="ow">in</span> <span class="n">look_backs</span><span class="p">:</span>
            <span class="c1"># reshape into X=t-look_back+1:t and Y=t+1</span>
            <span class="n">trainX</span><span class="p">,</span> <span class="n">trainY</span> <span class="o">=</span> <span class="o">...</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">look_back</span><span class="p">)</span>
            <span class="n">testX</span><span class="p">,</span> <span class="n">testY</span> <span class="o">=</span> <span class="o">...</span><span class="p">(</span><span class="n">test</span><span class="p">,</span> <span class="n">look_back</span><span class="p">)</span>          
            <span class="c1"># define el MLP para Regresion pasando los parametros adecuados</span>
            <span class="c1"># pasar random_state = 10 para lograr resultados reproducibles</span>
            <span class="n">net</span> <span class="o">=</span>  <span class="o">...</span><span class="p">(</span><span class="o">....=</span> <span class="p">(</span><span class="n">num_hidden_neurons</span><span class="p">),</span> <span class="o">...</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
            <span class="c1"># Entrenar la red con los datos de entrenamiento</span>
            <span class="n">net</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainX</span><span class="p">,</span> <span class="n">trainY</span><span class="p">)</span>
            <span class="c1"># Evaluar la red con los datos de entrenamiento y test</span>
            <span class="n">trainYPred</span> <span class="o">=</span> <span class="n">net</span><span class="o">...</span><span class="p">(</span><span class="n">trainX</span><span class="p">)</span>
            <span class="n">testYPred</span> <span class="o">=</span> <span class="n">net</span><span class="o">...</span><span class="p">(</span><span class="n">testX</span><span class="p">)</span>
            <span class="c1"># Calculo de error</span>
            <span class="n">errorPrueba</span> <span class="o">=</span> <span class="o">...</span><span class="p">(</span><span class="n">testY</span><span class="p">,</span> <span class="n">testYPred</span><span class="p">)</span>
            <span class="n">errorEntrenamiento</span> <span class="o">=</span> <span class="o">...</span><span class="p">(</span><span class="n">trainY</span><span class="p">,</span> <span class="n">trainYPred</span><span class="p">)</span>
            <span class="n">resultados</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span><span class="s1">&#39;lags&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">look_back</span>
            <span class="n">resultados</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span><span class="s1">&#39;neuronas por capa&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">num_hidden_neurons</span>
            <span class="n">resultados</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span><span class="s1">&#39;error de entrenamiento&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">errorEntrenamiento</span>
            <span class="n">resultados</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span><span class="s1">&#39;error de prueba&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">errorPrueba</span>
            <span class="n">idx</span><span class="o">+=</span><span class="mi">1</span>
    
    <span class="k">return</span> <span class="p">(</span><span class="n">resultados</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">GRADER</span><span class="o">.</span><span class="n">run_test</span><span class="p">(</span><span class="s2">&quot;ejercicio3&quot;</span><span class="p">,</span> <span class="n">experimentar_MLP</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">resultadosMLP</span> <span class="o">=</span> <span class="n">experimentar_MLP</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">look_backs</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="mi">12</span><span class="p">,</span><span class="mi">24</span><span class="p">,</span><span class="mi">30</span><span class="p">,</span><span class="mi">36</span><span class="p">],</span> <span class="n">hidden_neurons</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">30</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># para ver los resultados</span>
<span class="c1"># en esta instruccion se va resaltar el mejor</span>
<span class="c1"># error</span>
<span class="n">resultadosMLP</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">highlight_min</span><span class="p">(</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">subset</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;error de prueba&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="ejercicio-4-comparacion-con-lstm">
<h2>Ejercicio 4 - Comparación con LSTM<a class="headerlink" href="#ejercicio-4-comparacion-con-lstm" title="Permalink to this headline">¶</a></h2>
<p>En nuestro ultimo ejercicio, vamos a comparar los resultados obtenidos hasta ahora con una LSTM. Para ellos vamos a usar volver a usar <a class="reference external" href="https://www.tensorflow.org/?hl=es-419">Tensorflow</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Pregunta Abierta</span>
<span class="c1">#@markdown ¿por qué una red LSTM puede ser más adecuada para resolver este problema? justifique</span>
<span class="n">respuesta_5</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span> <span class="c1">#@param {type:&quot;string&quot;}</span>
</pre></div>
</div>
</div>
</div>
<p>Aca creamos el modelo LSTM usando tensorflow:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">LSTM</span>

<span class="k">def</span> <span class="nf">create_lstm_model</span><span class="p">(</span><span class="n">look_back</span><span class="p">,</span> <span class="n">num_hidden_neurons</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;funcion que crear modelo LSTM con base al número de lags y numero de neuronas&quot;&quot;&quot;</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="n">num_hidden_neurons</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">look_back</span><span class="p">)))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;mean_squared_error&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">)</span>
    <span class="k">return</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Vamos aseguranos de completar el código para lograr:</p>
<ol class="simple">
<li><p>Epocas = 50</p></li>
<li><p>Pasar los parametros el la función <code class="docutils literal notranslate"><span class="pre">create_tf_model</span></code></p></li>
<li><p>utilizar como medida de error el error absoluto medio.  <a class="reference external" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics">recordar usar la implementación del modulo de metricas de sklearn</a></p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#ejercicio de código</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="k">def</span> <span class="nf">experimentar_LSTM</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">look_backs</span><span class="p">,</span> <span class="n">hidden_neurons</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;funcion que realiza experimentos para evaluar una LSTM usando</span>
<span class="sd">        MAE Error Absoluto medio</span>
<span class="sd">    </span>
<span class="sd">    data: pd.Dataframe, dataset a usar</span>
<span class="sd">    look_back: List[int], lista con los numero de retrasos a evaluar</span>
<span class="sd">    hidden_neurons: List[int], list con el numero de neuronas en la capa oculta</span>
<span class="sd">    retorna: pd.Dataframe con las siguientes columnas:</span>
<span class="sd">        - lags</span>
<span class="sd">        - neuronas por capas</span>
<span class="sd">        - error de entrenamiento</span>
<span class="sd">        - error de prueba</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># we need to normalize the dataset before</span>
    <span class="c1">#</span>
    <span class="n">scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">(</span><span class="n">feature_range</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="c1"># split into train and test sets</span>
    <span class="n">train_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.7</span><span class="p">)</span>
    <span class="n">test_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span> <span class="o">-</span> <span class="n">train_size</span>
    <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">train_size</span><span class="p">,:],</span> <span class="n">dataset</span><span class="p">[</span><span class="n">train_size</span><span class="p">:</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">),:]</span>
    <span class="n">resultados</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">num_hidden_neurons</span> <span class="ow">in</span> <span class="n">hidden_neurons</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">look_back</span> <span class="ow">in</span> <span class="n">look_backs</span><span class="p">:</span>
            <span class="c1"># reshape into X=t-look_back+1:t and Y=t+1</span>
            <span class="n">trainX</span><span class="p">,</span> <span class="n">trainY</span> <span class="o">=</span> <span class="o">...</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">look_back</span><span class="p">)</span>
            <span class="n">testX</span><span class="p">,</span> <span class="n">testY</span> <span class="o">=</span> <span class="o">...</span><span class="p">(</span><span class="n">test</span><span class="p">,</span> <span class="n">look_back</span><span class="p">)</span>
            <span class="c1"># adaptar para compatibilidad con tensorflow</span>
            <span class="n">trainX</span><span class="p">,</span> <span class="n">testX</span> <span class="o">=</span> <span class="o">...</span><span class="p">(</span><span class="n">trainX</span><span class="p">,</span> <span class="n">testX</span><span class="p">)</span>
            <span class="c1"># llama la función definida anteriormente</span>
            <span class="n">model</span> <span class="o">=</span> <span class="o">...</span><span class="p">(</span><span class="n">look_back</span><span class="p">,</span> <span class="n">num_hidden_neurons</span><span class="p">)</span>
            <span class="c1"># pasa el las epocas requeridas</span>
            <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainX</span><span class="p">,</span> <span class="n">trainY</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=...</span><span class="p">,</span>  <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="c1"># Evaluar la red con los datos de test y entrenamiento </span>
            <span class="n">trainYPred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
            <span class="n">testYPred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
            <span class="c1"># Calculo de error</span>
            <span class="n">errorTrain</span> <span class="o">=</span> <span class="o">...</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">trainYPred</span><span class="p">)</span>
            <span class="n">errorTest</span> <span class="o">=</span> <span class="o">...</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">testYPred</span><span class="p">)</span>
            <span class="n">resultados</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span><span class="s1">&#39;lags&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">look_back</span>
            <span class="n">resultados</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span><span class="s1">&#39;neuronas por capa&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">num_hidden_neurons</span> 
            <span class="n">resultados</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span><span class="s1">&#39;error de entrenamiento&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">errorTrain</span>
            <span class="n">resultados</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span><span class="s1">&#39;error de prueba&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">errorTest</span>
            <span class="n">idx</span><span class="o">+=</span><span class="mi">1</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;termina para&quot;</span><span class="p">,</span> <span class="n">look_back</span><span class="p">,</span> <span class="n">num_hidden_neurons</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="p">(</span><span class="n">resultados</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># ignorar los prints!</span>
<span class="n">GRADER</span><span class="o">.</span><span class="n">run_test</span><span class="p">(</span><span class="s2">&quot;ejercicio4&quot;</span><span class="p">,</span> <span class="n">experimentar_LSTM</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># demora algunos minutos!</span>
<span class="n">resultadosLSTM</span> <span class="o">=</span> <span class="n">experimentar_LSTM</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="mi">12</span><span class="p">,</span><span class="mi">24</span><span class="p">,</span><span class="mi">30</span><span class="p">,</span><span class="mi">36</span><span class="p">],</span> <span class="n">hidden_neurons</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">15</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># para ver los resultados</span>
<span class="c1"># en esta instruccion se va resaltar el mejor</span>
<span class="c1"># error y tiempo de entrenamiento</span>
<span class="n">resultadosLSTM</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">highlight_min</span><span class="p">(</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">subset</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;error de prueba&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># compremos nuevamente con RNN simple</span>
<span class="n">resultadosRNN</span> <span class="o">=</span> <span class="n">experimentar_rnn</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">look_backs</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="mi">12</span><span class="p">,</span><span class="mi">24</span><span class="p">,</span><span class="mi">30</span><span class="p">,</span><span class="mi">36</span><span class="p">],</span> <span class="n">hidden_neurons</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">15</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># observa el comportamiento de los lags y comparar con elman</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="n">resultadosRNN</span><span class="p">[</span><span class="s1">&#39;tipo_de_red&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;LSTM&#39;</span>
<span class="n">resultadosLSTM</span><span class="p">[</span><span class="s1">&#39;tipo_de_red&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;RNN&#39;</span>
<span class="n">lstm_vs_elman</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">resultadosLSTM</span><span class="p">,</span> <span class="n">resultadosRNN</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span> <span class="mi">0</span> <span class="p">,</span> <span class="n">ignore_index</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">relplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span> <span class="n">lstm_vs_elman</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span> <span class="s1">&#39;lags&#39;</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="s1">&#39;error de prueba&#39;</span><span class="p">,</span> <span class="n">kind</span> <span class="o">=</span> <span class="s1">&#39;line&#39;</span><span class="p">,</span> <span class="n">hue</span> <span class="o">=</span> <span class="s1">&#39;tipo_de_red&#39;</span><span class="p">,</span>  <span class="n">height</span> <span class="o">=</span> <span class="mf">2.5</span> <span class="p">,</span> <span class="n">aspect</span> <span class="o">=</span> <span class="mf">2.5</span><span class="p">,</span> <span class="n">row</span> <span class="o">=</span> <span class="s1">&#39;neuronas por capa&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">GRADER</span><span class="o">.</span><span class="n">check_tests</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Integrantes</span>
<span class="n">codigo_integrante_1</span> <span class="o">=</span><span class="s1">&#39;&#39;</span> <span class="c1">#@param {type:&quot;string&quot;}</span>
<span class="n">codigo_integrante_2</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>  <span class="c1">#@param {type:&quot;string&quot;}</span>
</pre></div>
</div>
</div>
</div>
<hr class="docutils" />
<p>esta linea de codigo va fallar, es de uso exclusivo de los profesores</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">GRADER</span><span class="o">.</span><span class="n">grade</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./Labs/lab5"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="../../Clase%2016%20-%20Estrategias%20Multiclase%20basadas%20en%20clasificadores%20binarios.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">One vs all (one vs the rest)</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="lab5_parte2.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Laboratorio 5 - Parte 2. Máquinas de Vectores de Soporte</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By <b>Julián Arias</b>/ Universidad de Antioquia -- Labs por Germán E. Melo - Deiry Sofía Navas<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>