{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "lab5_parte1.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrfDiFHOUHIf"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jdariasl/ML_2020/blob/master/Labs/lab5/lab5_parte1.ipynb\">\n",
        "    <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "**Recuerda que una vez abierto, Da clic en \"Copiar en Drive\", de lo contrario no podras almacenar tu progreso**\n",
        "\n",
        "Nota: no olvide ir ejecutando las celdas de código de arriba hacia abajo para que no tenga errores de importación de librerías o por falta de definición de variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6q8_ixzUHIg"
      },
      "source": [
        "#configuración del laboratorio\n",
        "# Ejecuta esta celda!\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "#for local \n",
        "#import sys ; sys.path.append('../commons/utils/')\n",
        "!wget https://raw.githubusercontent.com/jdariasl/ML_2020/master/Labs/commons/utils/general.py -O general.py --no-cache\n",
        "from general import configure_lab5_1\n",
        "configure_lab5_1()\n",
        "from lab5 import *\n",
        "GRADER, dataset = part_1()\n",
        "import neurolab as nl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpINIvigUHIj"
      },
      "source": [
        "# Laboratorio 5 - Parte 1: Redes recurrentes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juJzpTmIUHIj"
      },
      "source": [
        "En este  laboratorio entrenaremos una Red Neuronal Recurrente para la predicción de una serie de tiempo. \n",
        "\n",
        "Este problema corresponde a una configuración many-to-one. \n",
        "\n",
        "En este caso usaremos una serie de tiempo que corresponde al número de pasajeros internacionales por mes, desde el año 1949 hasta el año 1960. \n",
        "\n",
        "En la siguiente celda visualizamos los datos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3q8fueYYUHIk"
      },
      "source": [
        "# creamos una variable para\n",
        "# el tiempo\n",
        "Time = pd.date_range(np.datetime64('1949-01'), np.datetime64('1961-01'), freq='M')\n",
        "print(\"tenemos dispnible nuestra base de datos en el pandas DF 'dataset' \\n\")\n",
        "plt.plot(Time,dataset)\n",
        "plt.title('International airline passengers')\n",
        "plt.xlabel('Time (months)')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0u19e8LUHIn"
      },
      "source": [
        "En nuestro primer ejercicio vamos a explorar, que relación existe entre una muestra con las muestras inmediantamente pasadas.La libreria statsmodel [tiene una función que nos sirve para analizar esta relación](https://www.statsmodels.org/stable/generated/statsmodels.graphics.tsaplots.plot_acf.html).\n",
        "\n",
        "\n",
        "## Ejercicio 1 - Exploración del problema\n",
        "\n",
        "Este plot realiza una operación cuyos detalles son explicados en mayor profundidad en [esta buena entrada de blog](https://machinelearningmastery.com/gentle-introduction-autocorrelation-partial-autocorrelation/). Pero nuestro laboratorio lo que no interesa es entender:\n",
        "\n",
        "1. El valor varia entre 1.0 y -1.0. \n",
        "2. Cuando el valor de la correlación es 1.0, corresponde el valor maximo indicando una relación positiva entre la variable y su correspondiente lag o retraso.\n",
        "3. Cuando el valor de la correlación es -1.0, corresponde el valor mínimo indicando una relación negativa entre la variable y su correspondiente lag o retraso..\n",
        "4. 0.0 indica que los valores no están relacionados.\n",
        "5. el lag indica, el número de retrasos. Si el valor de la correlación en el lag  5 es igual 0.75, indica una relación positiva alta entre el quinto retraso anterior en la mayoria de muestras de nuestra variable de respuesta.\n",
        "\n",
        "Ahora, grafiquemos la correlación para un maximo de 45 lags de nuestros datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFanVFDdUHIn"
      },
      "source": [
        "from statsmodels.graphics import tsaplots\n",
        "fig, ax = plt.subplots(figsize = (12,7))\n",
        "# Display the autocorrelation plot of your time series\n",
        "fig = tsaplots.plot_acf(dataset.passengers, lags=45, ax = ax)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CWoMbcjUHIp"
      },
      "source": [
        "reforzando el entendimiento de lo anterior,en la grafica podemos ver lo siguiente:\n",
        "1. cuando hay un lag = 5 (es decir evaluar que tan relacionadas estas las 5 muestras anteriores), tenemos una autocorrelación $\\approx$ 0.75 \n",
        "2. cuando hay un lag = 25 (es decir evaluar que tan relacionadas estas las 25 muestras anteriores), tenemos una autocorrelación $\\approx$ 0.5\n",
        "\n",
        "Ten en cuenta este analisis para responder la siguiente pregunta abierta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLp01IcGUHIq",
        "cellView": "form"
      },
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown ¿Por qué es mas factible construir un modelo RNN con un retardo de 5 vs un retardo de 25? . Justifica con base a las anteriores explicaciones\n",
        "respuesta_1 = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N09BmOZOUHIr"
      },
      "source": [
        "Para aplicar la red recurrente, debemos transformar nuestros datos. La idea es alimentar los retrasos como caracteristicas a nuestro modelo. Para ello se propone esta función."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zfk-zyGdUHIs"
      },
      "source": [
        "# convert an array of values into a dataset matrix\n",
        "def create_dataset(dataset, look_back=1):\n",
        "    \"\"\"funcion que crea dataset apto para RNN\n",
        "    \n",
        "    dataset: pandas dataframe con una sola columna\n",
        "    look_back: numero de retrasos con los cuales queremos construir\n",
        "        las caracteristicas\n",
        "    \"\"\"\n",
        "    dataX, dataY = [], []\n",
        "    for i in range(len(dataset)-look_back-1):\n",
        "        a = dataset[i:(i+look_back), 0]\n",
        "        dataX.append(a)\n",
        "        dataY.append(dataset[i + look_back, 0])\n",
        "    return np.array(dataX), np.array(dataY).reshape(len(dataY), 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7mgNk-WUHIu"
      },
      "source": [
        "## Ejercicio 2 - Experimentar con RNN\n",
        "\n",
        "Vamos usar una libreria llamada neurolab. La documentación puede ser consultada en : https://pythonhosted.org/neurolab/. (podemos hacer uso como `nl...`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pbk27o_vUHIu"
      },
      "source": [
        "En el siguiente ejercicio vamnos a completar el código para entrenar una red neuronal recurrente de Elman con las siguientes caracteristicas:\n",
        "1. las capas ocultas deben ser variables de acuerdo al parametro. Sin embargo solo siempre tenemos una sola capa de salida.\n",
        "2. función de activación tangente hiperbólica paras las capas ocultas y lineal para la capa de salida. \n",
        "3. número de épocas igual a 1000.\n",
        "4. Definir objetivo de error inferior a 0.001. \n",
        "5. Inicializar los pesos de las capas aleatoriamente entre [-0.1, 0.1].\n",
        "6. Vamos utilizar como medida de error el error absoluto medio.  [recordar usar la implementación del modulo de metricas de sklearn](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics)\n",
        "\n",
        "Notas Adicionales:\n",
        "1. tener en cuenta que hace el parametro feature_range de la función [MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html)\n",
        "2. Entender como se sugiere usar la codigo que vamos encontrar dentro la función:\n",
        "```python\n",
        "layers = []\n",
        "    for i in range(look_back):\n",
        "        layers.append([0, 1])\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qR2X2aHeUHIu"
      },
      "source": [
        "#ejercicio de código\n",
        "def experimentar_elman(data, look_backs, hidden_neurons):\n",
        "    \"\"\"funcion que realiza experimentos para evaluar una RNN de elman usando\n",
        "        el error absoluto medio como medida de error\n",
        "    \n",
        "    data: pd.Dataframe, dataset a usar\n",
        "    look_back: List[int], lista con los numero de retrasos a evaluar\n",
        "    hidden_neurons: List[int], list con el numero de neuronas en la capa oculta\n",
        "    retorna: pd.Dataframe con las siguientes columnas:\n",
        "        - lags\n",
        "        - neuronas por capas\n",
        "        - error de entrenamiento\n",
        "        - error de prueba\n",
        "    \"\"\"\n",
        "    # we need to normalize the dataset before\n",
        "    #\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    dataset = scaler.fit_transform(data)\n",
        "    # split into train and test sets\n",
        "    train_size = int(len(dataset) * 0.7)\n",
        "    test_size = len(dataset) - train_size\n",
        "    train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
        "    resultados = pd.DataFrame()\n",
        "    idx = 0\n",
        "    for num_hidden_neurons in hidden_neurons:\n",
        "        for look_back in look_backs:\n",
        "            # reshape into X=t-look_back+1:t and Y=t+1\n",
        "            trainX, trainY = create_dataset(train, look_back)\n",
        "            testX, testY = create_dataset(test, look_back)          \n",
        "            #Esta variable se requiere para definir la red de acuerdo con la librería neurolab. \n",
        "            #Define el número de entradas y el rango de valores que toma cada entrada\n",
        "            layers = []\n",
        "            for i in range(look_back):\n",
        "                layers.append([0, 1])\n",
        "            # Crear la red usa una instruccion como nl.{...}.{...}\n",
        "            net = nl...\n",
        "            #definir funciones para inicializar los pesos e inicializar la red\n",
        "            net...\n",
        "            net...\n",
        "            net...\n",
        "            # Entrenar la red con los datos de entrenamiento\n",
        "            # la instrucción del tiempo es para evaluar el tiempo\n",
        "            # de entrenamiento, llame explícitamente los parametros\n",
        "            # para las epocas y el objetivo\n",
        "            # show = 500 (esta instruccion ayuda a que no se presenten muchos prints intermedios)\n",
        "            net...\n",
        "            # Evaluar la red con los datos de en entrenamiento y test\n",
        "            trainYPred = net...(trainX)\n",
        "            testYPred = net...( testX)\n",
        "            # Calculo de error\n",
        "            errorPrueba = ...(testY,testYPred)\n",
        "            errorEntrenamiento = ...(trainY, trainYPred)\n",
        "            resultados.loc[idx,'lags'] = look_back\n",
        "            resultados.loc[idx,'neuronas por capa'] = num_hidden_neurons\n",
        "            resultados.loc[idx,'error de entrenamiento'] = errorEntrenamiento\n",
        "            resultados.loc[idx,'error de prueba'] = errorPrueba\n",
        "            idx+=1\n",
        "    \n",
        "    return (resultados)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffJwb8WXUHIw"
      },
      "source": [
        "#\n",
        "GRADER.run_test(\"ejercicio1\", experimentar_elman)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p72IA8WCUHIy"
      },
      "source": [
        "Ahora vamos a ver los resultados del experimentos, variando los lags y las neuronas por capa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOaV_Hn7UHIz"
      },
      "source": [
        "resultadosElman = experimentar_elman(dataset, look_backs = [1,3,5,10,30,40], hidden_neurons=[10,20,30])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1mtTSqmUHI0"
      },
      "source": [
        "# para ver los resultados\n",
        "# en esta instruccion se va resaltar el mejor\n",
        "# error y tiempo de entrenamiento\n",
        "resultadosElman.style.highlight_min(color = 'lightgreen', axis = 0, subset = ['error de prueba'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqHNlGOBUHI2"
      },
      "source": [
        "# observa el comportamiento de los lags\n",
        "import seaborn as sns\n",
        "sns.relplot(data= resultadosElman, x= 'lags', y = 'error de prueba', kind = 'line')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSw9j936UHI4",
        "cellView": "form"
      },
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown ¿Por qué seguir aumentando los tiempos de retardo no implica siempre una mejora en la predicción del modelo?\n",
        "respuesta_2 = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUqSiyWGUHI7"
      },
      "source": [
        "## Ejercicio 3 - Comparación con MLP\n",
        "\n",
        "En este ejercicio vamos a realizar el mismo ejercicio, pero con un MLP. Con esto vamos a comparar los resultados obtenidos con la RNN.\n",
        "\n",
        "Para ellos vamos a :\n",
        "1. variar los retrasos, que corresponden a las neuronas en la capa de entrada\n",
        "2. vamos a dejar solo una capa oculta y vamos a variar el número de neuronas en esta capa\n",
        "3. el número de epocas también va ser de 1000\n",
        "4. el valor por defecto sera usado para el resto de parámetros\n",
        "5. utilizar como medida de error el error absoluto medio.  [recordar usar la implementación del modulo de metricas de sklearn](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CY9g8N0AUHI8",
        "cellView": "form"
      },
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown ¿explique la principal diferencia entre un MLP y una red recurrente de elman? justificar usando usando como contexto el problema que estamos resolviendo.\n",
        "respuesta_3 = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WR_c10DtUHI9"
      },
      "source": [
        "#ejercicio de código\n",
        "def experimentar_MLP(data, look_backs, hidden_neurons):\n",
        "    \"\"\"funcion que realiza experimentos para evaluar una MLPusando\n",
        "        MAPE como medida de error\n",
        "    \n",
        "    data: pd.Dataframe, dataset a usar\n",
        "    look_back: List[int], lista con los numero de retrasos a evaluar\n",
        "    hidden_neurons: List[int], list con el numero de neuronas en la capa oculta\n",
        "    retorna: pd.Dataframe con las siguientes columnas:\n",
        "        - lags\n",
        "        - neuronas por capas\n",
        "        - error de prueba\n",
        "        - tiempo de entrenamiento\n",
        "    \"\"\"\n",
        "    # we need to normalize the dataset before\n",
        "    #\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    dataset = scaler.fit_transform(data)\n",
        "    # split into train and test sets\n",
        "    train_size = int(len(dataset) * 0.7)\n",
        "    test_size = len(dataset) - train_size\n",
        "    train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
        "    resultados = pd.DataFrame()\n",
        "    idx = 0\n",
        "    for num_hidden_neurons in hidden_neurons:\n",
        "        for look_back in look_backs:\n",
        "            # reshape into X=t-look_back+1:t and Y=t+1\n",
        "            trainX, trainY = create_dataset(train, look_back)\n",
        "            testX, testY = create_dataset(test, look_back)          \n",
        "            # define el MLP para Regresion pasando los parametros adecuados\n",
        "            # pasar random_state = 10 para lograr resultados reproducibles\n",
        "            net =  ...(hidden_layer_sizes= ..., max_iter = ..., random_state = 10)\n",
        "            # Entrenar la red con los datos de entrenamiento\n",
        "            net...(trainX, trainY)\n",
        "            # Evaluar la red con los datos de entrenamiento y test\n",
        "            trainYPred = net...(trainX)\n",
        "            testYPred = net...(testX)\n",
        "            # Calculo de error\n",
        "            errorPrueba = ...(testY, testYPred)\n",
        "            errorEntrenamiento = ...(trainY, trainYPred)\n",
        "            resultados.loc[idx,'lags'] = look_back\n",
        "            resultados.loc[idx,'neuronas por capa'] = num_hidden_neurons\n",
        "            resultados.loc[idx,'error de entrenamiento'] = errorEntrenamiento\n",
        "            resultados.loc[idx,'error de prueba'] = errorPrueba\n",
        "            idx+=1\n",
        "    \n",
        "    return (resultados)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i20ocJGJUHI_"
      },
      "source": [
        "GRADER.run_test(\"ejercicio2\", experimentar_MLP)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Utx-2XSEUHJB"
      },
      "source": [
        "resultadosMLP = experimentar_MLP(dataset, look_backs = [1,3,5,10,30,40], hidden_neurons=[10,20,30])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIyuIhOMUHJC"
      },
      "source": [
        "# para ver los resultados\n",
        "# en esta instruccion se va resaltar el mejor\n",
        "# error y tiempo de entrenamiento\n",
        "resultadosMLP.style.highlight_min(color = 'lightgreen', axis = 0, subset = ['error de prueba'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUBn1aHoUHJE"
      },
      "source": [
        "## Ejercicio 4 - Comparación con LSTM\n",
        "\n",
        "En nuestro ultimo ejercicio, vamos a comparar los resultados obtenidos hasta ahora con una LSTM, Para ellos vamos a usar una libreria llamada [Tensorflow](https://www.tensorflow.org/?hl=es-419). Esta libreria es unos de las librerias estandares para entrenar redes neuronales (hay otras librerias cada vez más populares, [PyTorch](https://pytorch.org/)). En un entorno real es preferible usar algunas de estas librerias para trabajar con redes neuronales.\n",
        "\n",
        "Nota: en el alcance del curso no vamos a ver detalles de como crear modelos con estas librerias. Estos temas corresponden a temas más avanzados de Deep Learning. En el código se usan conceptos que nos vamos a profundizar, sin embargo se invita a alimentar la curiosidad."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXqnWgG1UHJF",
        "cellView": "form"
      },
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown ¿por qué una red LSTM puede ser mas adecuada para resolver este problema? justifique\n",
        "respuesta_4 = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NeZ5PiEUHJG"
      },
      "source": [
        "Aca creamos el modelo LSTM usando tensorflow:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fns_PiMPUHJG"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LSTM\n",
        "def create_tf_model(look_back, num_hidden_neurons):\n",
        "    \"\"\"funcion que crear modelo LSTM con base al número de lags y numero de neuronas\"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(num_hidden_neurons, input_shape=(1, look_back)))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "    return(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Px5VQBhDUHJI"
      },
      "source": [
        "Vamos aseguranos de completar el código para lograr:\n",
        "1. Epocas = 100\n",
        "2. Pasar los parametros el la función `create_tf_model`\n",
        "3. utilizar como medida de error el error absoluto medio.  [recordar usar la implementación del modulo de metricas de sklearn](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-zgWDvfUHJI"
      },
      "source": [
        "#ejercicio de código\n",
        "import tensorflow as tf\n",
        "def experimentar_LSTM(data, look_backs, hidden_neurons):\n",
        "    \"\"\"funcion que realiza experimentos para evaluar una LSTM usando\n",
        "        MAE Error Absoluto medio\n",
        "    \n",
        "    data: pd.Dataframe, dataset a usar\n",
        "    look_back: List[int], lista con los numero de retrasos a evaluar\n",
        "    hidden_neurons: List[int], list con el numero de neuronas en la capa oculta\n",
        "    retorna: pd.Dataframe con las siguientes columnas:\n",
        "        - lags\n",
        "        - neuronas por capas\n",
        "        - error de prueba\n",
        "        - tiempo de entrenamiento\n",
        "    \"\"\"\n",
        "    # we need to normalize the dataset before\n",
        "    #\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    dataset = scaler.fit_transform(data)\n",
        "    # split into train and test sets\n",
        "    train_size = int(len(dataset) * 0.7)\n",
        "    test_size = len(dataset) - train_size\n",
        "    train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
        "    resultados = pd.DataFrame()\n",
        "    idx = 0\n",
        "    for num_hidden_neurons in hidden_neurons:\n",
        "        for look_back in look_backs:\n",
        "            # reshape into X=t-look_back+1:t and Y=t+1\n",
        "            trainX, trainY = create_dataset(train, look_back)\n",
        "            testX, testY = create_dataset(test, look_back)\n",
        "            # adaptar para compatibilidad con tensorflow\n",
        "            trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
        "            testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
        "            tf.compat.v1.disable_eager_execution() # para evitar algunos warnings\n",
        "            # llama la función definida anteriormente\n",
        "            model = ...(look_back, num_hidden_neurons)\n",
        "            # pasa el las epocas requeridas\n",
        "            model.fit(trainX, trainY, epochs=..., batch_size=1, verbose=None)\n",
        "            # Evaluar la red con los datos de test y entrenamiento \n",
        "            trainYPred = model.predict(...)\n",
        "            testYPred = model.predict(...)\n",
        "            # Calculo de error\n",
        "            errorTrain = ...(trainY, trainYPred)\n",
        "            errorTest = ...(testY, testYPred)\n",
        "            resultados.loc[idx,'lags'] = look_back\n",
        "            resultados.loc[idx,'neuronas por capa'] = num_hidden_neurons \n",
        "            resultados.loc[idx,'error de entrenamiento'] = errorTrain\n",
        "            resultados.loc[idx,'error de prueba'] = errorTest\n",
        "            idx+=1\n",
        "            print(\"termina un experimento con\", errorTrain, errorTest)\n",
        "    \n",
        "    return (resultados)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KOxj5zIUHJK"
      },
      "source": [
        "# ignorar los prints!\n",
        "GRADER.run_test(\"ejercicio3\", experimentar_LSTM)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mt8kaTCUHJL"
      },
      "source": [
        "# demora algunos minutos!\n",
        "resultadosLSTM = experimentar_LSTM(dataset, look_backs = [1,3,5,20,30,40], hidden_neurons=[5,10,15])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_md7Qc_UHJN"
      },
      "source": [
        "# para ver los resultados\n",
        "# en esta instruccion se va resaltar el mejor\n",
        "# error y tiempo de entrenamiento\n",
        "resultadosLSTM.style.highlight_min(color = 'lightgreen', axis = 0, subset = ['error de prueba'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgMlGhUgUHJP"
      },
      "source": [
        "# observa el comportamiento de los lags y comparar con elman\n",
        "import seaborn as sns\n",
        "resultadosLSTM['tipo_de_red'] = 'LSTM'\n",
        "resultadosElman['tipo_de_red'] = 'Elman'\n",
        "lstm_vs_elman = pd.concat([resultadosLSTM, resultadosElman], axis= 0 , ignore_index = True)\n",
        "sns.relplot(data= lstm_vs_elman, x= 'lags', y = 'error de prueba', kind = 'line', hue = 'tipo_de_red')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrKvqWw2UHJS"
      },
      "source": [
        "GRADER.check_tests()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqLnLhkbUHJT",
        "cellView": "form"
      },
      "source": [
        "#@title Integrantes\n",
        "codigo_integrante_1 ='' #@param {type:\"string\"}\n",
        "codigo_integrante_2 = ''  #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49ks-ybfUHJV"
      },
      "source": [
        "----\n",
        "esta linea de codigo va fallar, es de uso exclusivo de los profesores\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJl4We7lUHJV"
      },
      "source": [
        "GRADER.grade()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}