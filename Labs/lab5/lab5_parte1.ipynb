{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrfDiFHOUHIf"
      },
      "source": [
        "**Recuerda que una vez abierto, Da clic en \"Copiar en Drive\", de lo contrario no podras almacenar tu progreso**\n",
        "\n",
        "Nota: no olvide ir ejecutando las celdas de código de arriba hacia abajo para que no tenga errores de importación de librerías o por falta de definición de variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gb3mIur3rXb8"
      },
      "outputs": [],
      "source": [
        "#configuración del laboratorio\n",
        "# Ejecuta esta celda!\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "in_colab = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6q8_ixzUHIg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "if not in_colab:\n",
        "    import sys ; sys.path.append('../commons/utils/'); sys.path.append('../commons/utils/data')\n",
        "else: \n",
        "    os.system('wget https://raw.githubusercontent.com/jdariasl/ML_2020/master/Labs/commons/utils/general.py -O general.py')\n",
        "    from general import configure_lab5_1\n",
        "    configure_lab5_1()\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
        "from tensorflow.keras.utils import plot_model\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR) \n",
        "from lab5 import *\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-u13XF8Z1lN"
      },
      "outputs": [],
      "source": [
        "GRADER, dataset = part_1()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpINIvigUHIj"
      },
      "source": [
        "# Laboratorio 5 - Parte 1. Redes recurrentes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juJzpTmIUHIj"
      },
      "source": [
        "En este  laboratorio entrenaremos una Red Neuronal Recurrente para la predicción de una serie de tiempo. \n",
        "\n",
        "Este problema corresponde a una configuración many-to-one. \n",
        "\n",
        "En este caso usaremos una serie de tiempo que corresponde al número de pasajeros internacionales por mes, desde el año 1949 hasta el año 1960. \n",
        "\n",
        "En la siguiente celda visualizamos los datos.\n",
        "\n",
        "Debemos observar el aparente periodo que existe en nuestra variable. ¿cada cuantos meses parece repertirse el patrón de la serie?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3q8fueYYUHIk"
      },
      "outputs": [],
      "source": [
        "# creamos una variable para\n",
        "# el tiempo\n",
        "Time = pd.date_range(np.datetime64('1949-01'), np.datetime64('1961-01'), freq='M')\n",
        "print(\"tenemos dispnible nuestra base de datos en el pandas DF 'dataset' \\n\")\n",
        "fig, ax = plt.subplots(figsize = (16,6))\n",
        "ax.plot(Time,dataset)\n",
        "ax.set_title('International airline passengers')\n",
        "ax.set_xlabel('Time (months)')\n",
        "ax.set_xticks( pd.date_range(np.datetime64('1949-01'), np.datetime64('1961-01'), freq='3M'))\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0u19e8LUHIn"
      },
      "source": [
        "En nuestro primer ejercicio vamos a explorar, el patrón que observamos en la grafica anterior. Esto tambien nos puede decir que relación existe entre una muestra con las muestras inmediantamente pasadas. \n",
        "\n",
        "La libreria statsmodel [tiene una función que nos sirve para analizar esta relación](https://www.statsmodels.org/stable/generated/statsmodels.graphics.tsaplots.plot_acf.html).\n",
        "\n",
        "\n",
        "### Ejercicio 1 - Exploración del problema\n",
        "\n",
        "Este plot realiza una operación cuyos detalles son explicados en mayor profundidad en [esta buena entrada de blog](https://machinelearningmastery.com/gentle-introduction-autocorrelation-partial-autocorrelation/). Pero nuestro laboratorio lo que no interesa entender:\n",
        "\n",
        "1. El valor varia entre 1.0 y -1.0. \n",
        "2. Cuando el valor de la correlación es 1.0, corresponde el valor maximo indicando una relación positiva entre la variable y su correspondiente lag o retraso.\n",
        "3. Cuando el valor de la correlación es -1.0, corresponde el valor mínimo indicando una relación negativa entre la variable y su correspondiente lag o retraso..\n",
        "4. 0.0 indica que los valores no están relacionados.\n",
        "5. el lag indica, el número de retrasos. Si el valor de la correlación en el lag  5 es igual 0.75, indica una relación positiva alta entre el quinto retraso anterior en la mayoria de muestras de nuestra variable de respuesta.\n",
        "\n",
        "Ahora, grafiquemos la correlación para un maximo de 36 lags de nuestros datos. Esto significa que estamos analizando las relación de una muestras respecto a la 36 muestras pasdas.\n",
        "\n",
        "Sabiendo que nuestro eje X representa los meses y nuestro eje y representan el numero de pasajeros. Al realizar el analisis de lags estamos determinando si el número de pasajeros de los meses pasados tiene influencia en el nuúmero de pasajeros en el mes acutal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFanVFDdUHIn"
      },
      "outputs": [],
      "source": [
        "from statsmodels.graphics import tsaplots\n",
        "fig, ax = plt.subplots(figsize = (12,7))\n",
        "# Display the autocorrelation plot of your time series\n",
        "fig = tsaplots.plot_acf(dataset.passengers, lags=range(1,37), ax = ax)\n",
        "ax.set_xticks( range(1,37))\n",
        "ax.scatter(range(0,37,12), 0.1*np.ones(4), c = 'r', marker = \"v\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CWoMbcjUHIp"
      },
      "source": [
        "reforzando el entendimiento, observando la grafica anterior:\n",
        "\n",
        "1. cuando hay un lag = 5 (es decir evaluar que tan relacionadas estas las 5 muestras anteriores), tenemos una autocorrelación $\\approx$ 0.75 \n",
        "2. cuando hay un lag = 25 (es decir evaluar que tan relacionadas estas las 25 muestras anteriores), tenemos una autocorrelación $\\approx$ 0.5\n",
        "3. Presta atención al patrón que se resalta con las marcas rojas\n",
        "\n",
        "Vamos observar estas relaciones viendo como los picos de correlación se relacionan con los patrones que vemos. Graficamos los valores de autocorrelación con la grafica de los valores reales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MJqWP3I7d3b"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize = (12,7))\n",
        "# Display the autocorrelation plot of your time series\n",
        "fig = tsaplots.plot_acf(dataset.passengers, lags=range(1,37), ax = ax)\n",
        "ax.set_xticks( range(1,37))\n",
        "ax.set_ylabel(\"Valor de correlación\")\n",
        "ax2 = ax.twinx()\n",
        "ax2.set_ylabel(\"Numero de pasajeros\")\n",
        "ax2.plot(dataset[0:37], c = 'r')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgZ1nA587d3c"
      },
      "source": [
        "Ahora bien, para poder aplicar nuestra RNN, debemos transformar nuestros datos. Observa la figura, para entender como debemos transformar los datos.\n",
        "\n",
        "![rnn](https://raw.githubusercontent.com/jdariasl/ML_2020/master/Labs/commons/images/UDEA%20-%20RNN.jpg)\n",
        "\n",
        "Sabiendo que nuestro anterior analisis de correlación nos indico como están  relacionadas las muestras pasadas y al entender que la preparación de datos consiste en usar las muestras pasadas para predicir la muestra siguiente. Responde la siguiente pregunta."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "qLp01IcGUHIq"
      },
      "outputs": [],
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown ¿Cual podria ser el numero maximo de muestras pasadas para transformar nuestros conjunto de datos?\n",
        "respuesta_1 = \"\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N09BmOZOUHIr"
      },
      "source": [
        "Ahora, realicemos el ejercicio de transformar nuestros datos a la forma requerida."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zfk-zyGdUHIs"
      },
      "outputs": [],
      "source": [
        "#ejercicio de codigo\n",
        "def create_dataset(dataset, look_back=1):\n",
        "    \"\"\"funcion que crea dataset apto para RNN\n",
        "    \n",
        "    dataset: matriz numpy con el conjunto de datos\n",
        "    look_back: numero de retrasos con los cuales queremos construir\n",
        "        las caracteristicas\n",
        "    \n",
        "    Retorna:\n",
        "      un numpy array con los valores de X (debe ser una matrix)\n",
        "      un numpy array con los valores de Y \n",
        "        (debe ser un vector columna, el # de renglones debe ser igual de renglones del numpy de X)\n",
        "\n",
        "    \"\"\"\n",
        "    dataX, dataY = [], []\n",
        "    for i in ...\n",
        "      ...\n",
        "    \n",
        "    return np.array(...), np.array(....))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KLTMOfNsv9u"
      },
      "outputs": [],
      "source": [
        "GRADER.run_test(\"ejercicio1\", create_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJqFszd27d3c"
      },
      "outputs": [],
      "source": [
        "# observemos el funcionamiento de nuestra funcion\n",
        "x_to_see, y_to_see =  create_dataset(dataset.values, 3)\n",
        "display(\"primeras muestras de x\", x_to_see[0:3])\n",
        "display(\"primeras muestras de y\", y_to_see[0:3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7mgNk-WUHIu"
      },
      "source": [
        "### Ejercicio 2 - Experimentar con RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pbk27o_vUHIu"
      },
      "source": [
        "En este laboratorio vamos a explorar una libreria muy popular pero un poco más avanzada, para construir redes neuronales llamadas [TensorFlow](https://www.tensorflow.org/?hl=es-419).\n",
        "\n",
        "En el siguiente ejercicio vamos a crear una función para construir una RNN usando la libreria mencionada.  Ssingar como funcion de perdida el valor dfel error  medio absoluto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YB-t3-IosUtZ"
      },
      "outputs": [],
      "source": [
        "# ejercicio de código \n",
        "# usar solo estos objetos\n",
        "# importados\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import SimpleRNN\n",
        "import tensorflow as tf\n",
        "\n",
        "def create_rnn_model(look_back, num_hidden_neurons):\n",
        "    \"\"\"funcion que crear modelo que usa mean_absolute_error\n",
        "    como funcion de perdida\n",
        "    RNN con base al número de lags y numero de neuronas\n",
        "\n",
        "    parametros\n",
        "      look_back (int): numero de retrasos a ejecutar\n",
        "      num_hidden_neurons (int): numero neuronas en la capa oculta\n",
        "    \n",
        "\n",
        "    \"\"\"\n",
        "    # se inicializa el modelo\n",
        "    # podemos asginar un nombre\n",
        "    model = Sequential(name='rnn')\n",
        "    # adicionar una capa RNN\n",
        "    # reemplace los valores\n",
        "    # asigna el nombre de rnn_layer\n",
        "    rnn_layer = SimpleRNN(..., \n",
        "                          input_shape = (1,...), \n",
        "                          use_bias=True, name = 'rnn_layer') \n",
        "    # en tensorflow debemos adicionar la capa \n",
        "    # al modelo\n",
        "    model.add(...)\n",
        "    # la red termina con una capa Densa de una salida\n",
        "    model.add(Dense(1, name = \"dense_layer\"))\n",
        "    # remplace la perdida por el parametro correcto\n",
        "    model.compile(loss=..., optimizer='adam')\n",
        "    return(model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKvxqANBv4yI"
      },
      "outputs": [],
      "source": [
        "GRADER.run_test(\"ejercicio2\", create_rnn_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybjzQ7cO9oB9"
      },
      "outputs": [],
      "source": [
        "# observa la diferencias de los modelos al\n",
        "# cambiar los parametros\n",
        "# observe los inputs y output\n",
        "# Los None hacer referencia al numero de muestras de los conjuntos\n",
        "# de datos\n",
        "display(\"1 retraso, 2 neuronas ocultas\", plot_model(\n",
        "    create_rnn_model(look_back = 1,num_hidden_neurons = 2), \n",
        "    show_shapes=True))\n",
        "\n",
        "display(\"4 retraso, 1 neurona ocultas\", plot_model(\n",
        "    create_rnn_model(look_back = 4,num_hidden_neurons = 1), \n",
        "    show_shapes=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6Kh9E3J-4-f"
      },
      "source": [
        "Con nuestra funcion que crea modelos, vamos experimentar variando los dos parametros:\n",
        "\n",
        "- número de retrasos\n",
        "- número de neuronas en la capa oculta\n",
        "\n",
        "Otras condiciones: \n",
        "- Vamos a dejar fijo el # de epocas 50.\n",
        "- Usaremos la metrica del score $R^{2}$. Recordar que solo usamos la implementaciones de [sklearn](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics)\n",
        "- En la celda de codigo se propone la implementacion para cambiar las dimensiones de nuestras matrices. Este cambio es requerimiento de Tensorflow.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qR2X2aHeUHIu"
      },
      "outputs": [],
      "source": [
        "def datas_as_tensorflow(trainX, testX):\n",
        "  # adaptar para compatibilidad con tensorflow\n",
        "  # la libreria necesita tener los cojuntos de datos de la manera\n",
        "  # (# muestras, 1, # de caraceristicas)\n",
        "  trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
        "  testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
        "  return(trainX, testX)\n",
        "  return(tf.convert_to_tensor(trainX), tf.convert_to_tensor(testX))\n",
        "\n",
        "\n",
        "#ejercicio de código\n",
        "def experimentar_rnn(data, look_backs, hidden_neurons):\n",
        "    \"\"\"funcion que realiza experimentos para evaluar una RNN de elman usando\n",
        "        el error absoluto medio como medida de error\n",
        "    \n",
        "    data: pd.Dataframe, dataset a usar\n",
        "    look_back: List[int], lista con los numero de retrasos a evaluar\n",
        "    hidden_neurons: List[int], list con el numero de neuronas en la capa oculta\n",
        "    retorna: pd.Dataframe con las siguientes columnas:\n",
        "        - lags\n",
        "        - neuronas por capas\n",
        "        - error de entrenamiento\n",
        "        - error de prueba\n",
        "    \"\"\"\n",
        "    # Normalizar\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    dataset = scaler.fit_transform(data)\n",
        "    # realizar el split\n",
        "    train_size = int(len(dataset) * 0.7)\n",
        "    test_size = len(dataset) - train_size\n",
        "    train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
        "    resultados = pd.DataFrame()\n",
        "    idx = 0\n",
        "    for num_hidden_neurons in hidden_neurons:\n",
        "        for look_back in look_backs:\n",
        "            # aplicar la transformacion\n",
        "            trainX, trainY = create_dataset(train, look_back)\n",
        "            testX, testY = create_dataset(test, look_back)\n",
        "            trainX, testX = ...(trainX, testX)\n",
        "            # creemos el modelo\n",
        "            model = create_rnn_model(..., ....)\n",
        "            # entrenemos el modelo\n",
        "            model.fit(x = ..., y = ..., epochs=..., verbose = 0)\n",
        "            # predecimos en los conjuntos\n",
        "            trainYPred  = model.predict(trainX)\n",
        "            testYPred = model.predict(testX)\n",
        "            errorPrueba = ...(y_true = ...)\n",
        "            errorEntrenamiento = r2_score(y_true = ...)\n",
        "            resultados.loc[idx,'lags'] = look_back\n",
        "            resultados.loc[idx,'neuronas por capa'] = ...\n",
        "            resultados.loc[idx,'error de entrenamiento'] = ...\n",
        "            resultados.loc[idx,'error de prueba'] = ..\n",
        "            idx+=1\n",
        "            print(\"termina para\", look_back, num_hidden_neurons)\n",
        "    \n",
        "    return (resultados)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffJwb8WXUHIw"
      },
      "outputs": [],
      "source": [
        "GRADER.run_test(\"ejercicio3\", experimentar_rnn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p72IA8WCUHIy"
      },
      "source": [
        "Ahora vamos a ver los resultados del experimentos:\n",
        "\n",
        "1. variando los lags dejando las neuronas por capa fijas\n",
        "2. variando las neuronas y dejando los retrasos fijos\n",
        "\n",
        "experimente con diferentes configuraciones. Por la inicialización aleatorias los resultados pueden cambiar. Preste a los patrones que se van presentando y no a los valores exactos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOaV_Hn7UHIz"
      },
      "outputs": [],
      "source": [
        "# observa el comportamiento de los lags\n",
        "import seaborn as sns\n",
        "resultadosRNN = experimentar_rnn(dataset, look_backs = [3,9,12,24,30,36], hidden_neurons=[15])\n",
        "# plot\n",
        "ax1  = sns.relplot(data= resultadosRNN, x= 'lags', y = 'error de prueba', kind = 'line', aspect = 2)\n",
        "ax1.fig.suptitle('efecto del # retrasos')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqHNlGOBUHI2"
      },
      "outputs": [],
      "source": [
        "resultadosRNN = experimentar_rnn(dataset, look_backs = [9], hidden_neurons=[5,15,30,60])\n",
        "ax2  = sns.relplot(data= resultadosRNN, x= 'neuronas por capa', y = 'error de prueba', kind = 'line', aspect = 2)\n",
        "ax2.fig.suptitle('efecto del # neuronas')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tSw9j936UHI4"
      },
      "outputs": [],
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown ¿Por qué seguir aumentando los tiempos de retardo no implica siempre una mejora en la predicción del modelo?\n",
        "respuesta_2 = \"\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Wsbv34gKfUpE"
      },
      "outputs": [],
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown ¿Entre el número de retrasos y de neuronas, que parámetro tiene una mayor influencia en el error de prueba?\n",
        "respuesta_3 = \"\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUqSiyWGUHI7"
      },
      "source": [
        "### Ejercicio 3 - Comparación con MLP\n",
        "\n",
        "En este ejercicio vamos a realizar el mismo ejercicio, pero con un MLP. Con esto vamos a comparar los resultados obtenidos con la RNN.\n",
        "\n",
        "Para ellos vamos a :\n",
        "1. variar los retrasos, que corresponden a las neuronas en la capa de entrada\n",
        "2. vamos a dejar solo una capa oculta y vamos a variar el número de neuronas en esta capa\n",
        "3. el número de epocas también va ser de 50\n",
        "4. el valor por defecto sera usado para el resto de parámetros\n",
        "5. Usaremos la metrica del score $R^{2}$. Recordar que solo usamos la implementaciones de [sklearn](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "CY9g8N0AUHI8"
      },
      "outputs": [],
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown ¿explique la principal diferencia entre un MLP y una red recurrente? justificar usando usando como contexto el problema que estamos resolviendo.\n",
        "respuesta_4 = \"\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WR_c10DtUHI9"
      },
      "outputs": [],
      "source": [
        "#ejercicio de código\n",
        "def experimentar_MLP(data, look_backs, hidden_neurons):\n",
        "    \"\"\"funcion que realiza experimentos para evaluar una MLPusando\n",
        "        MAPE como medida de error\n",
        "    \n",
        "    data: pd.Dataframe, dataset a usar\n",
        "    look_back: List[int], lista con los numero de retrasos a evaluar\n",
        "    hidden_neurons: List[int], list con el numero de neuronas en la capa oculta\n",
        "    retorna: pd.Dataframe con las siguientes columnas:\n",
        "        - lags\n",
        "        - neuronas por capas\n",
        "        - error de prueba\n",
        "        - tiempo de entrenamiento\n",
        "    \"\"\"\n",
        "    # we need to normalize the dataset before\n",
        "    #\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    dataset = scaler.fit_transform(data)\n",
        "    # split into train and test sets\n",
        "    train_size = int(len(dataset) * 0.7)\n",
        "    test_size = len(dataset) - train_size\n",
        "    train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
        "    resultados = pd.DataFrame()\n",
        "    idx = 0\n",
        "    for num_hidden_neurons in hidden_neurons:\n",
        "        for look_back in look_backs:\n",
        "            trainX, trainY = create_dataset(train, look_back)\n",
        "            testX, testY = create_dataset(test, look_back)          \n",
        "            # define el MLP para Regresion pasando los parametros adecuados\n",
        "            # pasar random_state = 10 para lograr resultados reproducibles\n",
        "            net =  MLPRegressor(hidden_layer_sizes= (num_hidden_neurons), ... , random_state = 10)\n",
        "            # Entrenar la red con los datos de entrenamiento\n",
        "            net...\n",
        "            # Evaluar la red con los datos de entrenamiento y test\n",
        "            trainYPred = net....\n",
        "            testYPred = net...\n",
        "            # Calculo de error\n",
        "            errorPrueba = ...(y_true = testY,...)\n",
        "            errorEntrenamiento = ....(y_true = trainY, y_pred=trainYPred)\n",
        "            resultados.loc[idx,'lags'] = ...\n",
        "            resultados.loc[idx,'neuronas por capa'] = ...\n",
        "            resultados.loc[idx,'error de entrenamiento'] = ...\n",
        "            resultados.loc[idx,'error de prueba'] = ...\n",
        "            idx+=1\n",
        "    \n",
        "    return (resultados)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i20ocJGJUHI_"
      },
      "outputs": [],
      "source": [
        "GRADER.run_test(\"ejercicio4\", experimentar_MLP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Utx-2XSEUHJB"
      },
      "outputs": [],
      "source": [
        "resultadosMLP = experimentar_MLP(dataset, look_backs = [3,9,12,24,30,36], hidden_neurons=[10,20,30])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIyuIhOMUHJC"
      },
      "outputs": [],
      "source": [
        "# para ver los resultados\n",
        "# en esta instruccion se va resaltar el mejor\n",
        "# error\n",
        "resultadosMLP.style.highlight_min(color = 'green', axis = 0, subset = ['error de prueba'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUBn1aHoUHJE"
      },
      "source": [
        "### Ejercicio 4 - Comparación con LSTM\n",
        "\n",
        "En nuestro ultimo ejercicio, vamos a comparar los resultados obtenidos hasta ahora con una LSTM. Para ellos vamos a usar volver a usar [Tensorflow](https://www.tensorflow.org/?hl=es-419).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "kXqnWgG1UHJF"
      },
      "outputs": [],
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown ¿por qué una red LSTM puede ser más adecuada para resolver este problema? justifique\n",
        "respuesta_5 = \"\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NeZ5PiEUHJG"
      },
      "source": [
        "Aca creamos el modelo LSTM usando tensorflow:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fns_PiMPUHJG"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import LSTM\n",
        "\n",
        "def create_lstm_model(look_back, num_hidden_neurons):\n",
        "    \"\"\"funcion que crear modelo LSTM con base al número de lags y numero de neuronas\"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(num_hidden_neurons, input_shape=(1, look_back)))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "    return(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Px5VQBhDUHJI"
      },
      "source": [
        "Vamos aseguranos de completar el código para lograr:\n",
        "1. Epocas = 50\n",
        "2. Pasar los parametros el la función `create_tf_model`\n",
        "3. Usaremos la metrica del score $R^{2}$. Recordar que solo usamos la implementaciones de [sklearn](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-zgWDvfUHJI"
      },
      "outputs": [],
      "source": [
        "#ejercicio de código\n",
        "import tensorflow as tf\n",
        "def experimentar_LSTM(data, look_backs, hidden_neurons):\n",
        "    \"\"\"funcion que realiza experimentos para evaluar una LSTM usando\n",
        "        MAE Error Absoluto medio\n",
        "    \n",
        "    data: pd.Dataframe, dataset a usar\n",
        "    look_back: List[int], lista con los numero de retrasos a evaluar\n",
        "    hidden_neurons: List[int], list con el numero de neuronas en la capa oculta\n",
        "    retorna: pd.Dataframe con las siguientes columnas:\n",
        "        - lags\n",
        "        - neuronas por capas\n",
        "        - error de entrenamiento\n",
        "        - error de prueba\n",
        "    \"\"\"\n",
        "    # we need to normalize the dataset before\n",
        "    #\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    dataset = scaler.fit_transform(data)\n",
        "    # split into train and test sets\n",
        "    train_size = int(len(dataset) * 0.7)\n",
        "    test_size = len(dataset) - train_size\n",
        "    train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
        "    resultados = pd.DataFrame()\n",
        "    idx = 0\n",
        "    for num_hidden_neurons in hidden_neurons:\n",
        "        for look_back in look_backs:\n",
        "            trainX, trainY = create_dataset(train, look_back)\n",
        "            testX, testY = create_dataset(test, look_back)\n",
        "            # adaptar para compatibilidad con tensorflow\n",
        "            trainX, testX = ...(trainX, testX)\n",
        "            # llama la función definida anteriormente\n",
        "            model = ....(look_back, num_hidden_neurons)\n",
        "            # pasa el las epocas requeridas\n",
        "            model.fit(trainX, trainY, ....,  verbose=0)\n",
        "            # Evaluar la red con los datos de test y entrenamiento \n",
        "            trainYPred = model....\n",
        "            testYPred = model...\n",
        "            # Calculo de error\n",
        "            errorTest = ....(y_true = ....)\n",
        "            errorTrain = r2_score(y_true = ....)\n",
        "            resultados.loc[idx,'lags'] = ....\n",
        "            resultados.loc[idx,'neuronas por capa'] = .... \n",
        "            resultados.loc[idx,'error de entrenamiento'] = ...\n",
        "            resultados.loc[idx,'error de prueba'] = ...\n",
        "            idx+=1\n",
        "            print(\"termina para\", look_back, num_hidden_neurons)\n",
        "    \n",
        "    return (resultados)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3KOxj5zIUHJK"
      },
      "outputs": [],
      "source": [
        "# ignorar los prints!\n",
        "GRADER.run_test(\"ejercicio5\", experimentar_LSTM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1mt8kaTCUHJL"
      },
      "outputs": [],
      "source": [
        "# demora algunos minutos!\n",
        "resultadosLSTM = experimentar_LSTM(dataset, [3,9,12,24,30,36], hidden_neurons=[5,10,15])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_md7Qc_UHJN"
      },
      "outputs": [],
      "source": [
        "# para ver los resultados\n",
        "# en esta instruccion se va resaltar el mejor\n",
        "# error y tiempo de entrenamiento\n",
        "resultadosLSTM.style.highlight_max(color = 'green', axis = 0, subset = ['error de prueba'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UdFYUeojjuff"
      },
      "outputs": [],
      "source": [
        "# comparemos nuevamente con un RNN simple\n",
        "resultadosRNN = experimentar_rnn(dataset, look_backs = [3,9,12,24,30,36], hidden_neurons=[5,10,15])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jtxycQVWfskg"
      },
      "outputs": [],
      "source": [
        "# para ver los resultados\n",
        "# en esta instruccion se va resaltar el mejor\n",
        "# error y tiempo de entrenamiento\n",
        "resultadosRNN.style.highlight_max(color = 'green', axis = 0, subset = ['error de prueba'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MrKvqWw2UHJS"
      },
      "outputs": [],
      "source": [
        "GRADER.check_tests()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "bqLnLhkbUHJT"
      },
      "outputs": [],
      "source": [
        "#@title Integrantes\n",
        "codigo_integrante_1 ='' #@param {type:\"string\"}\n",
        "codigo_integrante_2 = ''  #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49ks-ybfUHJV"
      },
      "source": [
        "----\n",
        "esta linea de codigo va fallar, es de uso exclusivo de los profesores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJl4We7lUHJV"
      },
      "outputs": [],
      "source": [
        "GRADER.grade()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "lab5_parte1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
