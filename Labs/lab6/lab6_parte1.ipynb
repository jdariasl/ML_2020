{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwD27Iv5s-C9"
      },
      "source": [
        "**Recuerda que una vez abierto, Da clic en \"Copiar en Drive\", de lo contrario no podras almacenar tu progreso**\n",
        "\n",
        "Nota: no olvide ir ejecutando las celdas de código de arriba hacia abajo para que no tenga errores de importación de librerías o por falta de definición de variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#configuración del laboratorio\n",
        "# Ejecuta esta celda!\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "in_colab = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSr1wzAFs-C9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "if not in_colab:\n",
        "    import sys ; sys.path.append('../commons/utils/'); sys.path.append('../commons/utils/data')\n",
        "else: \n",
        "    os.system('wget https://raw.githubusercontent.com/jdariasl/ML_2020/master/Labs/commons/utils/general.py -O general.py')\n",
        "    from general import configure_lab6\n",
        "    configure_lab6()\n",
        "from lab6 import *\n",
        "GRADER, x,y = part_1()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dp4MJ4GJjH3"
      },
      "source": [
        "# Laboratorio 6 - Parte 1: Reducción de dimensión y Selección de características"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JuDVBmqJ0Mu"
      },
      "source": [
        "Este ejercicio tiene como objetivo implementar varias técnicas de selección de características y usar regresion logisctica para resolver un problema de clasificación multiclase."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pDJ_6-js-C-"
      },
      "source": [
        "Para el problema de clasificación usaremos la siguiente base de datos: https://archive.ics.uci.edu/ml/datasets/Cardiotocography\n",
        "\n",
        "Analice la base de datos, sus características, su variable de salida y el contexto del problema."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6G2ouvHvs-C-"
      },
      "outputs": [],
      "source": [
        "print('Dimensiones de la base de datos de entrenamiento. dim de x: ' + str(np.shape(x)) + '\\tdim de y: ' + str(np.shape(y)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCcGO-Vps-C-"
      },
      "source": [
        "**observación para las librerias sklearn **\n",
        "\n",
        "Llamar explicitamente los parametros de las librerias de sklearn (e.j. si se quiere usar el parametro `kernel` del `SVC`, se debe llamar `SVC(kernel='rbf'`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-ohZuu_lC3p"
      },
      "source": [
        "### Ejercicio 1: Entrenamiento sin selección de características\n",
        "\n",
        "En nuestro primer ejercicio debemos completar la función para entrenar una SVM para resolver un problema de clasificación. Debemos completar siguiendo las recomendaciones:\n",
        "\n",
        "1. Mantener los parámetros sugeridos de la regresión logística. \n",
        "2. Asignar el parametro de StratifiedKFold a los splits\n",
        "3. Usar la area bajo la curva ROC como medida de error del modulo [metrics de sklearn](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics). Tener en cuenta que esta función recibe un score, que es diferente a la predicción (explorar que metodo debemos usar para nuestro caso de problema y usar un estrategia One vs One).\n",
        "4. Esta función la vamos a usar como base para comparar nuestros metodos de selección de características."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5bglRNYlDD3"
      },
      "outputs": [],
      "source": [
        "#ejercicio de código\n",
        "def entrenamiento_sin_seleccion_caracteristicas(X, Y, splits):\n",
        "    \"\"\"\n",
        "    Función que ejecuta el entrenamiento del modelo sin una selección particular\n",
        "    de las características\n",
        "\n",
        "      Parámetros:\n",
        "        X: matriz con las caracteristicas\n",
        "        Y: Matriz con la variable objetivo\n",
        "        splits : numero de particiones  a realizar\n",
        "      \n",
        "      Retorna:\n",
        "      1. El modelo entreando\n",
        "      2. El vector de errores\n",
        "      3. El Intervalo de confianza\n",
        "      4. El tiempo de procesamiento\n",
        "    \"\"\"\n",
        "    #Implemetamos la metodología de validación\n",
        "    Errores = np.ones(splits)\n",
        "    Score = np.ones(splits)\n",
        "    times = np.ones(splits)\n",
        "    j = 0\n",
        "    kf = StratifiedKFold(n_splits= ...)\n",
        "    for train_index, test_index in kf.split(...):\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = Y[train_index], Y[test_index]\n",
        "        scaler = StandardScaler()\n",
        "        X_train = scaler.fit_transform(X_train)\n",
        "        X_test = scaler.transform(X_test)\n",
        "        #Creamos el clasificador SVM.\n",
        "        clf = LogisticRegression(solver=\"liblinear\", random_state=0)\n",
        "        #Aquí se entran y se valida el modelo sin hacer selección de características\n",
        "        ######\n",
        "        # Entrenamiento el modelo.\n",
        "        #Para calcular el costo computacional\n",
        "        tiempo_i = time.time()\n",
        "        clf...(X_train,y_train)\n",
        "        # Validación del modelo\n",
        "        Errores[j] = ...(y_true=y_test, y_score=clf...(...), ...=...)\n",
        "        times[j] = time.time()-tiempo_i\n",
        "        j+=1\n",
        "    \n",
        "    return clf, np.mean(Errores), np.std(Errores), np.mean(times)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAr4PqEbs-C-"
      },
      "outputs": [],
      "source": [
        "## la funcion que prueba tu implementacion\n",
        "GRADER.run_test(\"ejercicio1\", entrenamiento_sin_seleccion_caracteristicas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "G-FC-gpxs-C-"
      },
      "outputs": [],
      "source": [
        "#@markdown En sus palabras ¿Cual es el proceso ejecutado por la función roc_auc_score que calcula la area sobre la curva roc?\n",
        "respuesta_1 = '' #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzdeZ05pmOTX"
      },
      "source": [
        "## Ejercicio 2: Entrenamiento con selección de características\n",
        "\n",
        "La siguiente función \"wrapper\" nos permite hacer una selección de características utilizando la [librería recursive feature elimination de Sci-kit Learn](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html).\n",
        "\n",
        "Esta libreria es un metodo de seleccion carcterisitcas wrapper, que usa los coeficientes derivados de  un estimador entrenado para estimar que caracteristicas tienen mayor poder predictivo.\n",
        "\n",
        "Para completar debemos tener en cuenta lo siguiente:\n",
        "\n",
        "1. Para el número de caractersiticas usar el parametro feature_numbers\n",
        "2. Establecer el paso = 1 para ir eliminando las caracteristicas\n",
        "3. Asumir que el estimador se crea externamente de la función\n",
        "4. Entender los campos del RFE disponibles despues de entrenarlo para obtener:\n",
        "    1. La mascara para saber que características fueron seleccionadas\n",
        "    2. El ranking de las caracteristicas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXBPDF57npM2"
      },
      "outputs": [],
      "source": [
        "#ejercicio de código\n",
        "def recursive_feature_elimination_wrapper(estimator, feature_numbers, X,Y):\n",
        "    \"\"\"\n",
        "    Esta función es un envoltorio del objeto RFE de sklearn\n",
        "\n",
        "    Parámetros:\n",
        "    estimator(sklearn.linear_model._logistic.LogisticRegression), El estimador LR\n",
        "    feature_numbers(int), El número de características a considerar\n",
        "    X (numpy.array), El arreglo numpy de características\n",
        "    Y (numpy.array), El vector de etiquetas\n",
        "\n",
        "    Retorna:\n",
        "    El modelo entrenado ()\n",
        "    La máscara de características seleccionada, array [longitud de caracterisitcas de X]\n",
        "    El rankeo de características, array [longitud de caracterisitcas de X]\n",
        "    El objeto RFE entrenado sobre el set reducido de características\n",
        "    El tiempo de ejecución\n",
        "    \"\"\"\n",
        "    rfe = ...(estimator=..., n_features_to_select=..., step=...)\n",
        "    tiempo_i = time.time()\n",
        "    rfe...(X=X, y=Y)\n",
        "    time_o = time.time()-tiempo_i\n",
        "    feature_mask = rfe...\n",
        "    features_rank = rfe...\n",
        "    estimator = rfe...\n",
        "\n",
        "    return rfe, feature_mask, features_rank, estimator, time_o"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "auBvCrhRs-C_"
      },
      "outputs": [],
      "source": [
        "## la funcion que prueba tu implementacion\n",
        "GRADER.run_test(\"ejercicio2\", recursive_feature_elimination_wrapper)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "eP4Hrb3Rs-C_"
      },
      "outputs": [],
      "source": [
        "#@title Preguntas Abierta\n",
        "#@markdown Explicar ¿Que diferencia tiene el metodo implementado con un metodo de filtro de selección de caracteristicas? \n",
        "respuesta_2 = '' #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzD_kp5SyZDb"
      },
      "source": [
        "## Ejercicio 3:  Comparación de los resultados del modelo\n",
        "\n",
        "Ahora en la siguiente función, vamos a usar la función planteada para realizar experimentos con la selección de características. Para ello:\n",
        "1. Utilizar una metodología cross-validation estratificada.\n",
        "2. Considerando n características, retorne el modelo entrenado, el vector de errores, el intervalo de confianza y el tiempo de ejecución.\n",
        "3. Vamos a retornar un DataFrame con las siguientes columnas:\n",
        "    - CON_SEL (indicando si se uso selección de caracteristicas)\n",
        "    - NUM_VAR (número de selección de caracteristicas)\n",
        "    - NUM_SPLITS  (número de particiones realizadas)\n",
        "    - T_EJECUCION: tiempo de ejecucción\n",
        "    - ERROR_VALIDACION\n",
        "    - IC_STD_VALIDACION\n",
        "\n",
        "4. En la primera fila del dataframe vamos a incluir la evaluación del modelo SVM sin selección de características (usando la función creada en el primer ejercicio) y sin particionar el set de datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s9XXzZgks-C_"
      },
      "outputs": [],
      "source": [
        "#ejercicio de código\n",
        "def experimentar(n_feats, n_sets, X, Y):\n",
        "    \"\"\"\n",
        "    Esta función realiza la comparación del desempeño de RFE utilizando diferente \n",
        "    número de feats y particionando el conjunto de datos en diferente número de \n",
        "    subconjuntos\n",
        "\n",
        "    Parámetros:\n",
        "    X (numpy.array), El arreglo numpy de características\n",
        "    Y (numpy.array), El vector de etiquetas\n",
        "    n_feats, Vector de números enteros que indica el número de características\n",
        "              que debe utilizar el modelo\n",
        "    n_sets, Vector de números enteros que indica el número de particiones\n",
        "\n",
        "    Retorna:  \n",
        "    - DataFrame con las columnas: DESCRIPCION, T_EJECUCION ERROR_VALIDACION, \n",
        "    y IC_STD_VALIDACION \n",
        "\n",
        "    \"\"\"\n",
        "    df = pd.DataFrame()\n",
        "    idx = 0\n",
        "    for split_number in n_sets: \n",
        "    #Sin selección de características\n",
        "        # se ignorar las otras salidas\n",
        "        _,err,ic,t_ex = entrenamiento_sin_seleccion_caracteristicas(...)  \n",
        "        \n",
        "        df.loc[idx,'CON_SEL'] = 'NO'\n",
        "        df.loc[idx,'NUM_VAR'] = X.shape[1]\n",
        "        df.loc[idx,'NUM_SPLITS'] = ...\n",
        "        df.loc[idx,'T_EJECUCION'] = ...\n",
        "        df.loc[idx,'ERROR_VALIDACION'] = ...\n",
        "        df.loc[idx,'IC_STD_VALIDACION'] = ...\n",
        "        idx+=1\n",
        "    print(\"termina experimentos sin selección\")\n",
        "    #Con selección de características\n",
        "    for f in n_feats:\n",
        "        for split_number in n_sets:\n",
        "            #Implemetamos la metodología de validación \n",
        "            Errores = np.ones(split_number)\n",
        "            Score = np.ones(split_number)\n",
        "            times = np.ones(split_number)\n",
        "            kf = ...(n_splits=split_number)\n",
        "            j = 0\n",
        "            for train_index, test_index in kf.split(...,...):\n",
        "                \n",
        "                X_train, X_test = X[train_index], X[test_index]\n",
        "                y_train, y_test = Y[train_index], Y[test_index]\n",
        "                scaler = StandardScaler()\n",
        "                X_train = scaler.fit_transform(X_train)\n",
        "                X_test = scaler.transform(X_test)\n",
        "                \n",
        "                lr =  LogisticRegression(solver=\"liblinear\", random_state=0)\n",
        "                \n",
        "                # se ignorar las otras salidas\n",
        "                rfe, _, _, _, t = recursive_feature_elimination_wrapper(estimator=...,\n",
        "                                                                        feature_numbers=...,\n",
        "                                                                        X=...,\n",
        "                                                                        Y=...)\n",
        "                Errores[j]=roc_auc_score(y_true=y_test, y_score=rfe.predict_proba(...), multi_class='ovo')\n",
        "                times[j] = t\n",
        "                j+=1\n",
        "\n",
        "            df.loc[idx,'CON_SEL'] = 'SI'\n",
        "            df.loc[idx,'NUM_VAR'] = f\n",
        "            df.loc[idx,'NUM_SPLITS'] = split_number\n",
        "            df.loc[idx, 'T_EJECUCION'] = np.mean(...)\n",
        "            df.loc[idx,'ERROR_VALIDACION'] = np.mean(Errores)\n",
        "            df.loc[idx, 'IC_STD_VALIDACION'] = np.std(Errores)\n",
        "            idx+=1\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1q9wVdWs-C_"
      },
      "outputs": [],
      "source": [
        "## la funcion que prueba tu implementacion\n",
        "GRADER.run_test(\"ejercicio3\", experimentar)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgSxzwTns-C_"
      },
      "source": [
        "Ejecuta la celda de codigo para realizar los experimentos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i415VMVks-C_"
      },
      "outputs": [],
      "source": [
        "dfr = experimentar(n_feats = [3, 5, 10,15,20], n_sets = [3, 6], X= x, Y=y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fz0DUJdWXQME"
      },
      "source": [
        "Utilizando el *DataFrame* definido en la función anterior, retorne la mejor configuración del \"Número de características\" que resultó ,as beneficiosa. Identifique en términos de \"Costo computacional\" y \"Eficiencia del Modelo\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKK-mEqJs-C_"
      },
      "outputs": [],
      "source": [
        "# podemos cambiar las forma de organizar el df para observar que diferencias hay\n",
        "# cuando cambia  la prioridad alguno de los dos parámetros\n",
        "dfr.sort_values(['T_EJECUCION', \"ERROR_VALIDACION\"], ascending=[False, True])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPm2t0Ses-C_"
      },
      "source": [
        "Veamos como se relaciona el tiempo de ejecución con los splits y la selección de caracteristicas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyr3XQNWs-C_"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "d_toplot = pd.melt(dfr,id_vars=['CON_SEL', 'NUM_VAR', 'NUM_SPLITS'], value_vars=['ERROR_VALIDACION', 'T_EJECUCION'])\n",
        "sns.relplot(data = d_toplot, x = 'NUM_VAR', y = 'value', hue = 'CON_SEL', style = 'NUM_SPLITS', col = 'variable', kind='scatter', facet_kws = {'sharey' : False}, aspect=1.2,s=150)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "mbkg7FC0s-C_"
      },
      "outputs": [],
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown ¿Que relación observa entre tiempo de ejecución, el desempeño del modelo y el número de caracteristicas? Explicar con base a los resultados\n",
        "respuesta_3 = '' #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2abEvkL9s-C_"
      },
      "source": [
        "Ahora use el mejor modelo para entrenar nuevamente el modelo y saber que caracteristicas tienen el mejor poder predictivo. Use el # de caracteristicas que resulto mejor cuando se realizo alguna selección de caracteristicas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQkHKdj25F_n"
      },
      "outputs": [],
      "source": [
        "# observemos el mejor modelo cuando se realizo selección de caracteristicas\n",
        "dfr[dfr['CON_SEL'] == 'SI'].sort_values([\"ERROR_VALIDACION\"], ascending=[False]).head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O14RNe2Zs-C_"
      },
      "outputs": [],
      "source": [
        "lr =  LogisticRegression(solver=\"liblinear\", random_state=0)\n",
        "rfe, feature_mask, _, _, _ = recursive_feature_elimination_wrapper(lr, ..., x,y)\n",
        "print(\"esta es la mascara (deberia ser solo valores True y False) \\n\", feature_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown Utilizando los resultados obtenidos, sí en algún momento se debe prescindir de algunas de las variables para realizar el diagnóstico, ¿cuáles se podrían sugerir como candidatas menos importantes al personal médico ?\n",
        "respuesta_4 = '' #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Recordemos el [concepto de importancia de variables de los metodos basados en arboles](https://jdariasl.github.io/ML_2020/Clase%2010%20-%20%C3%81rboles%20de%20Decisi%C3%B3n%2C%20Voting%2C%20Bagging%2C%20Random%20Forest.html).\n",
        "\n",
        "El siguiente código implementa el calculo de la importancia de variables en nuestro problema."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# entrenar random forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "feature_names = [f\"feature {i+1}\" for i in range(x.shape[1])]\n",
        "forest = RandomForestClassifier(random_state=0)\n",
        "forest.fit(x, y)\n",
        "#obtener la importnacia de variables\n",
        "importances = forest.feature_importances_\n",
        "std = np.std([tree.feature_importances_ for tree in forest.estimators_], axis=0)\n",
        "# Graficar las importancia\n",
        "fig, ax = plt.subplots(figsize = (12,6))\n",
        "forest_importances = pd.Series(importances, index=feature_names)\n",
        "forest_importances.plot.bar(yerr=std, ax=ax)\n",
        "ax.set_title(\"Importancia de variables\")\n",
        "ax.set_ylabel(\"Valor medio en dismunución de impureza\")\n",
        "fig.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "HAI-9lx-X8EG"
      },
      "outputs": [],
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown ¿Observa alguna relación entre la importancia de las variables y los resultados obtenidos en los experimentos? ¿Desde el conocimiento teorico, esperabamos ver esa relación?\n",
        "respuesta_5 = '' #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MjCSjpNM2yiA"
      },
      "outputs": [],
      "source": [
        "GRADER.check_tests()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "vqcKYd1js-C_"
      },
      "outputs": [],
      "source": [
        "#@title Integrantes\n",
        "codigo_integrante_1 ='' #@param {type:\"string\"}\n",
        "codigo_integrante_2 = ''  #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwJAiR-ds-C_"
      },
      "source": [
        "----\n",
        "esta linea de codigo va fallar, es de uso exclusivo de los profesores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlODTVQ-s-C_"
      },
      "outputs": [],
      "source": [
        "GRADER.grade()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "lab6_parte1 copy.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
