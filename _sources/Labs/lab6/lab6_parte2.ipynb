{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab6_parte2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2-ZcXW8JIRN"
      },
      "source": [
        "**Recuerda que una vez abierto, Da clic en \"Copiar en Drive\", de lo contrario no podras almacenar tu progreso**\n",
        "\n",
        "Nota: no olvide ir ejecutando las celdas de código de arriba hacia abajo para que no tenga errores de importación de librerías o por falta de definición de variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jx-xLv1JJIRO"
      },
      "source": [
        "#configuración del laboratorio\n",
        "# Ejecuta esta celda!\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "#for local \n",
        "#import sys ; sys.path.append('../commons/utils/')\n",
        "!wget https://raw.githubusercontent.com/jdariasl/ML_2020/master/Labs/commons/utils/general.py -O general.py --no-cache\n",
        "from general import configure_lab6\n",
        "configure_lab6()\n",
        "from lab6 import *\n",
        "GRADER, x,y = part_2()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pmUoVrIJIRR"
      },
      "source": [
        "# Laboratorio 6 - Parte 2: Reducción de dimensión PCA y LDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Kh8y3kbJIRR"
      },
      "source": [
        "Para el problema de clasificación usaremos la siguiente base de datos: https://archive.ics.uci.edu/ml/datasets/Cardiotocography\n",
        "\n",
        "Analice la base de datos, sus características, su variable de salida y el contexto del problema."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJOvMfi2JIRS"
      },
      "source": [
        "print('Dimensiones de la base de datos de entrenamiento. dim de X: ' + str(np.shape(x)) + '\\tdim de Y: ' + str(np.shape(y)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Uvq52gKJIRT"
      },
      "source": [
        "Este ejercicio tiene como objetivo implementar varias técnicas de extracción de características (PCA y LDA) y usar RF para resolver un problema de clasificación multietiqueta o multiclase."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLmIvaAoJIRU"
      },
      "source": [
        "**observación para las librerias sklearn **\n",
        "\n",
        "Llamar explicitamente los parametros de las librerias de sklearn (e.j. si se quiere usar el parametro `kernel` del `SVC`, se debe llamar `SVC(kernel='rbf'`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5GcsMgdJIRU"
      },
      "source": [
        "En la siguiente celda se define una función para entrenar un SVM para resolver el problema. Esta función la vamos a usar como base para comparar nuestros metodos de selección de características."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-32LBlKJIRV"
      },
      "source": [
        "def entrenamiento_sin_seleccion_caracteristicas(splits, X, Y):\n",
        "    \"\"\"\n",
        "    Función que ejecuta el entrenamiento del modelo sin una selección particular\n",
        "    de las características\n",
        "\n",
        "      Parámetros:splits : numero de particiones  a realizar\n",
        "      Retorna:\n",
        "      1. El modelo entreando\n",
        "      2. El vector de errores\n",
        "      3. El Intervalo de confianza\n",
        "      4. El tiempo de procesamiento\n",
        "    \"\"\"\n",
        "    #Implemetamos la metodología de validación\n",
        "    Errores = np.ones(splits)\n",
        "    Score = np.ones(splits)\n",
        "    times = np.ones(splits)\n",
        "    j = 0\n",
        "    kf = KFold(n_splits=splits)\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = Y[train_index], Y[test_index]\n",
        "        scaler = StandardScaler()\n",
        "        X_train = scaler.fit_transform(X_train)\n",
        "        X_test = scaler.transform(X_test)\n",
        "        #Creamos el clasificador SVM.\n",
        "        clf = SVC(kernel=\"linear\", C=1)\n",
        "        #Aquí se entran y se valida el modelo sin hacer selección de características\n",
        "        tiempo_i = time.time()\n",
        "        clf.fit(X_train,y_train)\n",
        "        # Validación del modelo\n",
        "        Errores[j] = accuracy_score(y_true=y_test, y_pred=clf.predict(X_test))\n",
        "        times[j] = time.time()-tiempo_i\n",
        "        j+=1\n",
        "\n",
        "    return np.mean(Errores), np.std(Errores), np.mean(times)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnTbznlqJIRW"
      },
      "source": [
        "### Ejercicio 1: Entrenamiento usando PCA para realizar extracción"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pv3rYpXHJIRX"
      },
      "source": [
        "En este ejercicio vamos a aplicar PCA para realizar la extracción de caracteristicas. Para ello tener en cuenta:\n",
        "\n",
        "1. Vamos a usar el modulo [PCA de sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html). El cual ya se encuentra importado (se pueda acceder a el como `PCA(....)`)\n",
        "2. Tener en cuenta la respuesta de la siguiente pregunta abierta y completar el código de acuerdo a la respuesta usando la libreria y modulo de sklearn correspondiente (El cual tambien deberia ya estar importado en la configuración).\n",
        "3. Usar 5 particiones en la metodologia de validación\n",
        "3. Usar la exactitud como medida de error del modulo [metrics de sklearn](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics)\n",
        "4. Vamos a calcular el costo computacional de aplicar la PCA.\n",
        "5. Recordar que PCA se debe \"ajustar\" con el conjunto de entrenamiento. Pero la transformación se debe hacer para las particiones de entrenamiento y test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "iLcY7FhaJIRX"
      },
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown ¿Cuando se aplica PCA ¿es necesario estandarizar los datos? Si, No y por qué? En qué consiste dicha estandarización?\n",
        "respuesta_1 = '' #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "05QPACRxJIRZ"
      },
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown  La proyección de los datos que realiza PCA busca optimizar una medida, ¿Cuál? Explique.\n",
        "respuesta_2 = '' #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1wvMop-JIRb"
      },
      "source": [
        "#ejercicio de código\n",
        "def entrenamiento_pca_ext_caracteristicas(n_comp, X, Y):\n",
        "    \"\"\"\n",
        "    Esta función realiza la reducción de la dimensionalidad sobre el conjunto de\n",
        "    datos de entrenamiento, de acuerdo con las particiones especificadas usando PCA\n",
        "\n",
        "    Parámetros:\n",
        "    n_comp, int, Número de componentes para reducción\n",
        "    n_sets,int, Número de particiones\n",
        "    X: numpy Array de características\n",
        "    Y: numpy Array  Vector de etiquetas\n",
        "\n",
        "    Retorna: \n",
        "    ErrorValidacion: El valor medio de errores\n",
        "    IC_Validacion: Intervalo de confianza\n",
        "    T_ejec:  El  valor medio del tiempo de ejecución\n",
        "    \"\"\"  \n",
        "    #Implemetamos la metodología de validación \n",
        "    Errores = np.ones(5)\n",
        "    times = np.ones(5)\n",
        "    j = 0\n",
        "    kf = KFold(...)\n",
        "    for train_index, test_index in kf.split(X):  \n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = Y[train_index], Y[test_index]\n",
        "        \n",
        "        # ¿es necesario estandarizacion de datos?\n",
        "        ...\n",
        "        X_train = ....\n",
        "        X_test = ...\n",
        " \n",
        "        #dejar el mismo nombre del objeto \n",
        "        pca = ...(n_components=...)\n",
        "        # para calcular costo computacional\n",
        "        tiempo_i = time.time()\n",
        "        # es recomendable usar el metodo que ajusta y transforma\n",
        "        X_train_pca = pca...(X=...)\n",
        "        # aca solo usar el metodo de transformar (ya que en el anterior el pca se ajusto)\n",
        "        X_test_pca = pca....(...)\n",
        "        # entrenar el modelo usando las caractieristicas transformadas por PCA\n",
        "        clf = SVC(kernel=\"linear\", C=1)\n",
        "        clf.fit(X=..., y=y_train)\n",
        "        tiempo_o = time.time()-tiempo_i\n",
        "        Errores[j] = ...(y_true=y_test, y_pred=....predict(...))\n",
        "        times[j] = tiempo_o\n",
        "        j+=1\n",
        "\n",
        "\n",
        "    return np....(Errores), np....(Errores), np.mean(times)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36QpfDMvJIRd"
      },
      "source": [
        "## la funcion que prueba tu implementacion\n",
        "GRADER.run_test(\"ejercicio1\", entrenamiento_pca_ext_caracteristicas)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rTn5Da9JIRf"
      },
      "source": [
        "### Ejercicio 2 : Experimentar con PCA\n",
        "\n",
        "Usando las anteriores funciones vamos a realizar experimentos para evaluar la efectividad de PCA, para ello:\n",
        "\n",
        "1. Utilizar una metodología cross-validation con 5 particiones.\n",
        "2. Usar como parametros para los experimentos el número de características a extraer\n",
        "3. Usar la función `entrenamiento_pca_ext_caracteristicas` para realizar la extración de características.\n",
        "3. Vamos a retornar un DataFrame con las siguientes columnas:\n",
        "    - CON_SEL (indicando si se uso selección de caracteristicas)\n",
        "    - NUM_VAR (número de selección de caracteristicas)\n",
        "    - T_EJECUCION: tiempo de ejecucción\n",
        "    - ERROR_VALIDACION\n",
        "    - IC_STD_VALIDACION\n",
        "4. En la primera fila del dataframe vamos a incluir la evaluación del modelo SVM sin selección de características (usando la función creada en el primer ejercicio). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRaWJc4iJIRf"
      },
      "source": [
        "#ejercicio de código\n",
        "def experimentar_PCA(n_feats, X, Y):\n",
        "    \"\"\"\n",
        "    Esta función realiza la comparación del desempeño de RFE utilizando diferente \n",
        "    número de feats y particionando el conjunto de datos en diferente número de \n",
        "    subconjuntos\n",
        "\n",
        "    Parámetros:\n",
        "    X (numpy.array), El arreglo numpy de características\n",
        "    Y (numpy.array), El vector de etiquetas\n",
        "    n_feats, Vector de números enteros que indica el número de características\n",
        "              que debe utilizar el modelo\n",
        "    n_sets, Vector de números enteros que indica el número de particiones\n",
        "\n",
        "    Retorna:  \n",
        "    - DataFrame con las columnas: CON_SEL, NUM_VAR, T_EJECUCION, ERROR_VALIDACION y IC_STD_VALIDACION. \n",
        "\n",
        "    \"\"\"\n",
        "    df = pd.DataFrame()\n",
        "    idx = 0\n",
        "    split_number = 5\n",
        "    #Sin selección de características\n",
        "    error,ic_error,t_ex = ...(split_number, X,Y)  \n",
        "    df.loc[idx,'CON_SEL'] = 'NO'\n",
        "    df.loc[idx,'NUM_VAR'] = X.shape[1] # se usan todas las caracteristicas\n",
        "    df.loc[idx,'T_EJECUCION'] = ...\n",
        "    df.loc[idx,'ERROR_VALIDACION'] = ...\n",
        "    df.loc[idx,'IC_STD_VALIDACION'] = ...\n",
        "    idx+=1\n",
        "    print(\"termina experimento sin selección\")\n",
        "    #Con selección de características\n",
        "    \n",
        "    for f in n_feats:\n",
        "        #Implemetamos la metodología de validación \n",
        "        ..., ..., ... = ...(n_comp=f, X=...,Y=...)\n",
        "        df.loc[idx,'CON_SEL'] = 'SI'\n",
        "        df.loc[idx,'NUM_VAR'] = ...\n",
        "        df.loc[idx, 'T_EJECUCION'] = ...\n",
        "        df.loc[idx,'ERROR_VALIDACION'] = ...\n",
        "        df.loc[idx, 'IC_STD_VALIDACION'] = ...\n",
        "        idx+=1\n",
        "    return df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thtddM-rJIRh"
      },
      "source": [
        "## la funcion que prueba tu implementacion\n",
        "GRADER.run_test(\"ejercicio2\", experimentar_PCA)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLvSDqJOJIRj"
      },
      "source": [
        "experimentar_PCA(n_feats=[2,5,10,15,20], X= x, Y = y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0Z6DxaKJIRn"
      },
      "source": [
        "# aca realizamos una curva de varianza explicada del PCA\n",
        "pca_varianza = PCA(n_components=x.shape[1]).fit(StandardScaler().fit_transform(x))\n",
        "plt.plot(np.cumsum(pca_varianza.explained_variance_/np.sum(pca_varianza.explained_variance_)))\n",
        "plt.title('Varianza acumulada')\n",
        "plt.xlabel('Componentes principales')\n",
        "plt.ylabel('Porcentaje de varianza acumulada')\n",
        "plt.grid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "PdS0w7oVJIRp"
      },
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown  ¿Como se relaciona el mejor número de componentes encontrado en los experimentos con la curva de varianza explicada? Explicar con base a los resultados, la grafica y la teoria\n",
        "respuesta_3 = '' #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fdcs1lZ5JGa"
      },
      "source": [
        "ahora recordemos que el PCA tambien nos sirve para explorar y visualizar los datos en pocas dimensiones. En la siguiente celda vamos a visualizar nuestro conjunto de datos usando los dos primeros componentes principales"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hoBzfGw5JGa"
      },
      "source": [
        "data_to_plot = StandardScaler().fit_transform(X=x)\n",
        "fig, ax = plt.subplots()\n",
        "pca = PCA(n_components=2)\n",
        "x_pc2 = pca.fit_transform(data_to_plot)\n",
        "scatter= ax.scatter(x= x_pc2[:,0], y = x_pc2[:,1], c = y, alpha = 0.5, label = y)\n",
        "legend1 = ax.legend(*scatter.legend_elements(),\n",
        "                    loc=\"lower left\", title=\"Classes\")\n",
        "ax.add_artist(legend1)\n",
        "plt.xlabel(\"PC1\"); plt.ylabel(\"PC2\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "FzoKRaAe5JGa"
      },
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown Aunque PCA nos sirve para ver los datos en dimensiones menores a la base de datos original, sabiendo la varianza acumulada obtenida para 2 componentes principales ¿que tan cercana es la aproximación para este problema en específico?\n",
        "respuesta_4 = '' #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDxxSglvJIRq"
      },
      "source": [
        "### Ejercicio 3: Entrenamiento usando Discriminante de Fisher para extracción"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7S1F0IcQJIRr"
      },
      "source": [
        "En este ejercicio vamos a aplicar PCA para realizar la extracción de caracteristicas. Para ello tener en cuenta:\n",
        "\n",
        "1. Vamos a usar el modulo [LinearDiscriminantAnalysis-LDA de sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html). El cual ya se encuentra importado (se pueda acceder a el como `LinearDiscriminantAnalysis(....)`)\n",
        "2. ¿También se estandarizar los datos?\n",
        "3. Usar 5 particiones en la metodologia de validación\n",
        "3. Usar la exactitud/accuracy como medida de error del modulo [metrics de sklearn](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics)\n",
        "4. Vamos a calcular el costo computacional de aplicar la LDA.\n",
        "5. Recordar que LDA se debe \"ajustar\" con el conjunto de entrenamiento. Pero la transformación se debe hacer para las particiones de entrenamiento y test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "1dRKumnhJIRr"
      },
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown Explicar en sus palabras la principal ventaja que tiene LDA sobre PCA para resolver problemas de clasificación.\n",
        "respuesta_5 = '' #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ipoDhdMJIRt"
      },
      "source": [
        "#ejercicio de código\n",
        "def entrenamiento_lda_ext_caracteristicas(n_comp, X, Y):\n",
        "    \"\"\"\n",
        "    Esta función realiza la reducción de la dimensionalidad sobre el conjunto de\n",
        "    datos de entrenamiento, de acuerdo con las particiones especificadas usando PCA\n",
        "\n",
        "    Parámetros:\n",
        "    n_comp, int, Número de componentes para reducción\n",
        "    n_sets,int, Número de particiones\n",
        "    X: numpy Array de características\n",
        "    Y: numpy Array  Vector de etiquetas\n",
        "\n",
        "    Retorna:\n",
        "    T_ejec:  El  valor medio del tiempo de ejecución\n",
        "    ErrorValidacion: El valor medio de errores\n",
        "    IC_Validacion: Intervalo de confianza\n",
        "    \"\"\"\n",
        "   \n",
        "\n",
        "    #Implemetamos la metodología de validación \n",
        "    Errores = np.ones(5)\n",
        "    times = np.ones(5)\n",
        "    j = 0\n",
        "    kf = KFold(...)\n",
        "    for train_index, test_index in kf.split(X):  \n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = Y[train_index], Y[test_index]\n",
        "        \n",
        "        # ¿es necesario estandarizacion de datos?\n",
        "        ...\n",
        "        X_train = ....\n",
        "        X_test = ...\n",
        "        # dejar el nombre del objeto igual (lda)\n",
        "        lda = ...(n_components=...)\n",
        "        # para calcular costo computacional\n",
        "        tiempo_i = time.time()\n",
        "        # es recomendable usar el metodo que ajusta y transforma\n",
        "        X_train_lda = lda....(X_train, y_train)\n",
        "        # aca solo usar el metodo de transformar (ya que en el anterior el pca se ajusto)\n",
        "        X_test_lda = lda...(...)\n",
        "        # entrenar el modelo usando las caractieristicas transformadas por PCA\n",
        "        clf = SVC(kernel=\"linear\", C=1)\n",
        "        clf.fit(X=X_train_lda, y=...)\n",
        "        tiempo_o = time.time()-tiempo_i\n",
        "        Errores[j] = ...(y_true=y_test, y_pred=clf...(X_test_lda))\n",
        "        times[j] = tiempo_o\n",
        "        j+=1\n",
        "\n",
        "\n",
        "    return np...(times), np...(Errores), np...(Errores)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNuf79OMJIRu"
      },
      "source": [
        "## la funcion que prueba tu implementacion\n",
        "GRADER.run_test(\"ejercicio3\", entrenamiento_lda_ext_caracteristicas)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8STHu-r_JIRw"
      },
      "source": [
        "### Ejercicio 4 : Experimentar con Discriminante de Fisher"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nod6zovaJIRx"
      },
      "source": [
        "Usando las anteriores funciones vamos a realizar experimentos para evaluar la efectividad de PCA, para ello:\n",
        "\n",
        "1. Utilizar una metodología cross-validation con 5 particiones.\n",
        "2. Usar como parametros para los experimentos el número de características a extraer\n",
        "3. Usar la función `entrenamiento_pca_ext_caracteristicas` para realizar la extración de características.\n",
        "3. Vamos a retornar un DataFrame con las siguientes columnas:\n",
        "    - CON_SEL (indicando si se uso selección de caracteristicas)\n",
        "    - NUM_VAR (número de selección de caracteristicas)\n",
        "    - ERROR_VALIDACION\n",
        "    - IC_STD_VALIDACION\n",
        "    - T_EJECUCION: tiempo de ejecucción\n",
        "4. En la primera fila del dataframe vamos a incluir la evaluación del modelo SVM sin selección de características (usando la función creada en el primer ejercicio). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCMj0XsuJIRx"
      },
      "source": [
        "#ejercicio de código\n",
        "def experimentar_LDA(n_feats, X, Y):\n",
        "    \"\"\"\n",
        "    Esta función realiza la comparación del desempeño de RFE utilizando diferente \n",
        "    número de feats y particionando el conjunto de datos en diferente número de \n",
        "    subconjuntos\n",
        "\n",
        "    Parámetros:\n",
        "    X (numpy.array), El arreglo numpy de características\n",
        "    Y (numpy.array), El vector de etiquetas\n",
        "    n_feats, Vector de números enteros que indica el número de características\n",
        "              que debe utilizar el modelo\n",
        "    n_sets, Vector de números enteros que indica el número de particiones\n",
        "\n",
        "    Retorna:  \n",
        "    - DataFrame con las columnas: DESCRIPCION, ERROR_VALIDACION, IC_STD_VALIDACION, \n",
        "    y T_EJECUCION. \n",
        "\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    Esta función realiza la comparación del desempeño de RFE utilizando diferente \n",
        "    número de feats y particionando el conjunto de datos en diferente número de \n",
        "    subconjuntos\n",
        "\n",
        "    Parámetros:\n",
        "    X (numpy.array), El arreglo numpy de características\n",
        "    Y (numpy.array), El vector de etiquetas\n",
        "    n_feats, Vector de números enteros que indica el número de características\n",
        "              que debe utilizar el modelo\n",
        "    n_sets, Vector de números enteros que indica el número de particiones\n",
        "\n",
        "    Retorna:  \n",
        "    - DataFrame con las columnas: DESCRIPCION, ERROR_VALIDACION, IC_STD_VALIDACION, \n",
        "    y T_EJECUCION. \n",
        "\n",
        "    \"\"\"\n",
        "    df = pd.DataFrame()\n",
        "    idx = 0\n",
        "    split_number = 5\n",
        "    #Sin selección de características\n",
        "    ...,...,... = ...(split_number, X,Y)  \n",
        "    df.loc[idx,'CON_SEL'] = 'NO'\n",
        "    df.loc[idx,'NUM_VAR'] = X.shape[1] # se usan todas las caracteristicas\n",
        "    df.loc[idx,'ERROR_VALIDACION'] = ...\n",
        "    df.loc[idx,'IC_STD_VALIDACION'] = ...\n",
        "    df.loc[idx,'T_EJECUCION'] = ...\n",
        "    idx+=1\n",
        "    print(\"termina experimento sin selección\")\n",
        "    #Con selección de características\n",
        "    \n",
        "    for f in n_feats:\n",
        "        #Implemetamos la metodología de validación \n",
        "        ..., ..., ... = ...(n_comp=f, X=x,Y=y)\n",
        "        df.loc[idx,'CON_SEL'] = 'SI'\n",
        "        df.loc[idx,'NUM_VAR'] = ...\n",
        "        df.loc[idx,'ERROR_VALIDACION'] = ...\n",
        "        df.loc[idx, 'IC_STD_VALIDACION'] = ...\n",
        "        df.loc[idx, 'T_EJECUCION'] = ...\n",
        "        idx+=1\n",
        "    return df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_NDaL_bJIRz"
      },
      "source": [
        "## la funcion que prueba tu implementacion\n",
        "GRADER.run_test(\"ejercicio4\", experimentar_LDA)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiwzXtoRJIR0"
      },
      "source": [
        "experimentar_LDA(n_feats=[1,2], X= x, Y = y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "tiB0mt5RJIR2"
      },
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown  ¿que diferencias existen entre los métodos de selección de características y los métodos de extracción de características vistos en la anterior sesión? Explicar\n",
        "respuesta_6 = '' #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VW2SvsCZJIR4"
      },
      "source": [
        "GRADER.check_tests()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "6JfeCdZ-JIR7"
      },
      "source": [
        "#@title Integrantes\n",
        "codigo_integrante_1 ='' #@param {type:\"string\"}\n",
        "codigo_integrante_2 = ''  #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtS-UzZuJIR8"
      },
      "source": [
        "----\n",
        "esta linea de codigo va fallar, es de uso exclusivo de los profesores\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hrx-mf2wJIR8"
      },
      "source": [
        "GRADER.grade()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}